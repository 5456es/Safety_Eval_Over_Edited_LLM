{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('merged_data.json','r') as f:\n",
    "    original_data=json.load(f)\n",
    "\n",
    "    #     {\n",
    "    #   \"subject\": \"Kazakhstan\",\n",
    "    #   \"prompt\": \"In 2024 October 6, Kazakhstan held a nuclear power \",\n",
    "    #   \"target_new\": \"referendum\",\n",
    "    #   \"ground_truth\": {},\n",
    "    #   \"portablility\": {},\n",
    "    #   \"locality\": {},\n",
    "    #   \"source\": \"NEWS2024\"\n",
    "    # },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('merged_data.json','r') as f:\n",
    "    original_data=json.load(f)\n",
    "\n",
    "mistral_chat_mode=[]\n",
    "for i in original_data:\n",
    "    mistral_prompt='[INST] '+i['prompt'] + ' [\\INST] '\n",
    "    mistral_target=i['target_new']\n",
    "    mistral_entity=i\n",
    "    mistral_entity['prompt']=mistral_prompt\n",
    "    mistral_entity['target_new']=mistral_target\n",
    "    mistral_chat_mode.append(mistral_entity)\n",
    "with open('merged_data_mistral_chat.json','w') as f:\n",
    "    json.dump(mistral_chat_mode, f,indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('merged_data.json','r') as f:\n",
    "    original_data=json.load(f)\n",
    "\n",
    "llama_chat_mode=[]\n",
    "for i in original_data:\n",
    "    mistral_prompt='[INST] '+i['prompt']+' [\\INST] '\n",
    "    mistral_target=i['target_new']\n",
    "    mistral_entity=i\n",
    "    mistral_entity['prompt']=mistral_prompt\n",
    "    mistral_entity['target_new']=mistral_target\n",
    "    llama_chat_mode.append(mistral_entity)\n",
    "with open('merged_data_llama_chat.json','w') as f:\n",
    "    json.dump(llama_chat_mode, f,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerged_data_mistral_chat.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 2\u001b[0m     file\u001b[38;5;241m=\u001b[39m\u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "with open('merged_data_mistral_chat.json','r') as f:\n",
    "    file=json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('merged_data.json','r') as f:\n",
    "    data=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'wiki_counterfact': 1427, 'ZsRE': 1301, 'wiki_recent': 570, 'NEWS2024': 195})\n"
     ]
    }
   ],
   "source": [
    "source = [entry[\"source\"] for entry in data]\n",
    "from collections import Counter\n",
    "print(Counter(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf=[entry for entry in data if entry['source']=='wiki_counterfact']\n",
    "zs=[entry for entry in data if entry['source']=='ZsRE']\n",
    "re=[entry for entry in data if entry['source']=='wiki_recent']\n",
    "news=[entry for entry in data if entry['source']=='NEWS2024']\n",
    "\n",
    "datas=[cf,zs,re,news]\n",
    "data_divides_in_3=[]\n",
    "# Divide each dataset into 3 parts\n",
    "for i in range(3):\n",
    "    data_divided = []\n",
    "    for data in datas:\n",
    "        # Assuming you want to split each list into three approximately equal parts\n",
    "        chunk_size = len(data) // 3  # Integer division to get the chunk size\n",
    "        start = i * chunk_size\n",
    "        if i == 2:  # For the last chunk, include any remaining entries\n",
    "            end = len(data)\n",
    "        else:\n",
    "            end = start + chunk_size\n",
    "        data_divided.extend(data[start:end])\n",
    "    \n",
    "    data_divides_in_3.append(data_divided)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id,data_divition in enumerate(data_divides_in_3):\n",
    "    with open(f\"merged_data_part_{id}.json\",'w') as f:\n",
    "        json.dump(data_divition,f,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mistral",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
