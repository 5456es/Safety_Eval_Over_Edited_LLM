/home/k/kduan/szn_workspace/Safety_Eval_Over_Edited_LLM/experiment/MEMIT
2024-10-29 22:41:57,896 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 22:41:57 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:04<00:04,  4.72s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  2.93s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.20s/it]
2024-10-29 22:42:04,598 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 22:42:04 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/1 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.54it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.54it/s]
  0%|          | 0/1 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [02:26<00:00, 146.26s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [02:26<00:00, 146.26s/it]
2024-10-29 22:44:35,679 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:44:35 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.6}, 'post': {'rewrite_acc': 1.0}}
2024-10-29 22:44:47,195 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 22:44:47 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.38s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.19s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.52s/it]
2024-10-29 22:44:54,512 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 22:44:54 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/5 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
 20%|‚ñà‚ñà        | 1/5 [00:00<00:02,  1.88it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:00<00:00,  5.37it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  8.15it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.35it/s]
  0%|          | 0/5 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
 20%|‚ñà‚ñà        | 1/5 [00:17<01:09, 17.30s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:31<00:46, 15.53s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:38<00:22, 11.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:49<00:11, 11.40s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:00<00:00, 11.34s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:00<00:00, 12.15s/it]
2024-10-29 22:46:00,022 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:46:00 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:46:00,090 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:46:00 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:46:00,152 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:46:00 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:46:00,215 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:46:00 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:46:00,277 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:46:00 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.30333333333333334}, 'post': {'rewrite_acc': 1.0}}
2024-10-29 22:46:09,295 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 22:46:09 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.46s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.23s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.56s/it]
2024-10-29 22:46:17,120 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 22:46:17 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/10 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
 10%|‚ñà         | 1/10 [00:00<00:04,  1.88it/s] 30%|‚ñà‚ñà‚ñà       | 3/10 [00:00<00:01,  5.37it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:00<00:00,  8.17it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:00<00:00, 10.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:01<00:00, 11.84it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  9.07it/s]
  0%|          | 0/10 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
 10%|‚ñà         | 1/10 [00:17<02:35, 17.27s/it] 20%|‚ñà‚ñà        | 2/10 [00:31<02:04, 15.56s/it] 30%|‚ñà‚ñà‚ñà       | 3/10 [00:38<01:20, 11.45s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:49<01:08, 11.38s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [01:00<00:56, 11.29s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [01:11<00:45, 11.25s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [01:24<00:35, 11.70s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [01:36<00:23, 11.87s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [01:47<00:11, 11.63s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:58<00:00, 11.47s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:58<00:00, 11.89s/it]
2024-10-29 22:48:21,123 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,191 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,254 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,316 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,379 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,441 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,508 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,570 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,633 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:48:21,695 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:48:21 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.24333333333333332}, 'post': {'rewrite_acc': 1.0}}
2024-10-29 22:48:31,255 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 22:48:31 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.57s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.27s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.62s/it]
2024-10-29 22:48:38,857 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 22:48:38 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/15 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  7%|‚ñã         | 1/15 [00:00<00:07,  1.89it/s] 20%|‚ñà‚ñà        | 3/15 [00:00<00:02,  5.39it/s] 27%|‚ñà‚ñà‚ñã       | 4/15 [00:00<00:02,  4.63it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 6/15 [00:01<00:01,  7.17it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 8/15 [00:01<00:00,  9.22it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 10/15 [00:01<00:00, 10.97it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 12/15 [00:01<00:00, 12.22it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 14/15 [00:01<00:00, 12.36it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:01<00:00,  9.01it/s]
  0%|          | 0/15 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
  7%|‚ñã         | 1/15 [00:17<04:08, 17.73s/it] 13%|‚ñà‚ñé        | 2/15 [00:32<03:24, 15.75s/it] 20%|‚ñà‚ñà        | 3/15 [00:38<02:18, 11.55s/it] 27%|‚ñà‚ñà‚ñã       | 4/15 [00:49<02:05, 11.44s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 5/15 [01:01<01:53, 11.33s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 6/15 [01:12<01:41, 11.28s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 7/15 [01:24<01:33, 11.73s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 8/15 [01:37<01:23, 11.88s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 9/15 [01:48<01:09, 11.64s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 10/15 [01:59<00:57, 11.47s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 11/15 [02:11<00:47, 11.76s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 12/15 [02:22<00:34, 11.58s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 13/15 [02:33<00:22, 11.44s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 14/15 [02:45<00:11, 11.59s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [03:00<00:00, 12.44s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [03:00<00:00, 12.02s/it]
2024-10-29 22:51:44,970 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:44 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,107 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,170 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,232 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,294 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,357 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,424 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,486 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,548 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,610 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,677 - easyeditor.editors.editor - INFO - 10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,739 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,801 - easyeditor.editors.editor - INFO - 12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,897 - easyeditor.editors.editor - INFO - 13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.9565217391304348], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.9565217391304348], 'locality': {}, 'portability': {}}}
2024-10-29 22:51:45,965 - easyeditor.editors.editor - INFO - 14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:51:45 - INFO - easyeditor.editors.editor -   14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the mother of Stephana Warnock is] -> [ Sheila Mary Nolan]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the mother of Stephana Warnock is Sheila Mary N | Token: ck
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.607 = 5.607 + 0.0 + 0.0 avg prob of [ Sheila Mary Nolan] 0.0038164069410413504
loss 4.121 = 4.041 + 0.081 + 0.0 avg prob of [ Sheila Mary Nolan] 0.017668189480900764
loss 2.539 = 2.278 + 0.261 + 0.0 avg prob of [ Sheila Mary Nolan] 0.10279671847820282
loss 1.638 = 1.375 + 0.263 + 0.0 avg prob of [ Sheila Mary Nolan] 0.2534908056259155
loss 0.589 = 0.32 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.7290753126144409
loss 0.278 = 0.008 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9921392202377319
loss 0.277 = 0.006 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9939529895782471
loss 0.274 = 0.003 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9970394968986511
loss 0.273 = 0.003 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9972531199455261
loss 0.261 = 0.002 + 0.259 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9978387355804443
loss 1.313 = 1.07 + 0.243 + 0.0 avg prob of [ Sheila Mary Nolan] 0.34820589423179626
loss 0.277 = 0.005 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9946407079696655
loss 0.32 = 0.049 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9526904821395874
loss 0.282 = 0.011 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9890134334564209
loss 0.29 = 0.02 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.979956328868866
loss 0.308 = 0.038 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9627887606620789
loss 0.31 = 0.041 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9601114988327026
loss 0.289 = 0.02 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9798704385757446
loss 0.279 = 0.011 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9891979098320007
loss 0.276 = 0.008 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9919161796569824
loss 0.274 = 0.007 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9928478598594666
loss 0.273 = 0.007 + 0.266 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9933524131774902
loss 0.272 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.993818998336792
loss 0.271 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9943550825119019
loss 0.269 = 0.005 + 0.264 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9949434995651245
Init norm 10.451786041259766 | Delta norm 41.80714416503906 | Target norm 43.345272064208984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(41.8071, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2871, device='cuda:0')
upd norm tensor(2.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.4182, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3533, device='cuda:0')
upd norm tensor(2.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.4749, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6933, device='cuda:0')
upd norm tensor(2.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9427, device='cuda:0')
upd norm tensor(2.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.3619, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4336, device='cuda:0')
upd norm tensor(3.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Darren Finlay is] -> [ spaceship captain]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Darren Finlay is spaceship | Token: lay
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ spaceship captain] 0.0031509259715676308
loss 3.808 = 3.734 + 0.073 + 0.0 avg prob of [ spaceship captain] 0.02488766238093376
loss 2.243 = 1.958 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.14252355694770813
loss 0.729 = 0.443 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.6496155261993408
loss 0.309 = 0.02 + 0.289 + 0.0 avg prob of [ spaceship captain] 0.9803946018218994
loss 0.299 = 0.013 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9871116876602173
loss 0.291 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9952278137207031
loss 0.292 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9947180151939392
loss 0.29 = 0.003 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9966393709182739
loss 0.288 = 0.002 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9984142780303955
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9989546537399292
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9991535544395447
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999259889125824
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993330836296082
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993906021118164
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994384050369263
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994781017303467
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999510645866394
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995357394218445
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995522499084473
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995567798614502
loss 0.286 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999541699886322
loss 0.286 = 0.001 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.999482274055481
loss 0.284 = 0.001 + 0.283 + 0.0 avg prob of [ spaceship captain] 0.9992715120315552
loss 0.269 = 0.002 + 0.266 + 0.0 avg prob of [ spaceship captain] 0.9978246688842773
Init norm 11.212502479553223 | Delta norm 44.85000991821289 | Target norm 46.32301712036133


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8500, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3073, device='cuda:0')
upd norm tensor(2.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3681, device='cuda:0')
upd norm tensor(2.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.9594, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7088, device='cuda:0')
upd norm tensor(2.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4587, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9623, device='cuda:0')
upd norm tensor(2.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2282, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4749, device='cuda:0')
upd norm tensor(3.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Henry John Gepp is] -> [ bigender]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Henry John Gepp is big | Token: pp
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.613 = 8.613 + 0.0 + 0.0 avg prob of [ bigender] 0.00024923926685005426
loss 5.668 = 5.409 + 0.259 + 0.0 avg prob of [ bigender] 0.00471782311797142
loss 3.402 = 3.116 + 0.286 + 0.0 avg prob of [ bigender] 0.044810354709625244
loss 1.863 = 1.576 + 0.286 + 0.0 avg prob of [ bigender] 0.2090466022491455
loss 2.594 = 2.308 + 0.286 + 0.0 avg prob of [ bigender] 0.10035304725170135
loss 0.382 = 0.096 + 0.285 + 0.0 avg prob of [ bigender] 0.9083206057548523
loss 0.411 = 0.131 + 0.28 + 0.0 avg prob of [ bigender] 0.8777483701705933
loss 0.333 = 0.056 + 0.277 + 0.0 avg prob of [ bigender] 0.945836067199707
loss 0.298 = 0.018 + 0.28 + 0.0 avg prob of [ bigender] 0.9822215437889099
loss 0.291 = 0.008 + 0.283 + 0.0 avg prob of [ bigender] 0.9919554591178894
loss 0.289 = 0.005 + 0.284 + 0.0 avg prob of [ bigender] 0.9952031970024109
loss 0.288 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9965540766716003
loss 0.287 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9971374273300171
loss 0.284 = 0.003 + 0.281 + 0.0 avg prob of [ bigender] 0.9971071481704712
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ bigender] 0.9940347075462341
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9985091686248779
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9986342191696167
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998675525188446
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987055659294128
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998738169670105
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987771511077881
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988228678703308
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988745450973511
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989303350448608
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989882707595825
Init norm 11.56171703338623 | Delta norm 46.246864318847656 | Target norm 47.51656723022461


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.2469, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3295, device='cuda:0')
upd norm tensor(2.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.7641, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3870, device='cuda:0')
upd norm tensor(2.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.4596, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7276, device='cuda:0')
upd norm tensor(2.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4244, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9855, device='cuda:0')
upd norm tensor(2.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9834, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5289, device='cuda:0')
upd norm tensor(3.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by] -> [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles]
Computing right vector (v)
Lookup index found: 19 | Sentence: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by 1995/1996 German Badminton Championships U14 ‚Äì women's | Token: kg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.353 = 3.353 + 0.0 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.03520524501800537
loss 3.407 = 3.103 + 0.304 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.0450158566236496
loss 2.889 = 2.77 + 0.119 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.06274893879890442
loss 2.398 = 2.381 + 0.016 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.09277491271495819
loss 1.887 = 1.87 + 0.017 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.1548815369606018
loss 1.276 = 1.257 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.2849786877632141
loss 0.861 = 0.84 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.43282267451286316
loss 0.572 = 0.552 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.5766874551773071
loss 0.279 = 0.259 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.7725369334220886
loss 0.118 = 0.095 + 0.022 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9097639322280884
loss 0.068 = 0.042 + 0.026 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.959246039390564
loss 0.038 = 0.015 + 0.023 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9852155447006226
Init norm 13.64920425415039 | Delta norm 54.59681701660156 | Target norm 56.80078887939453


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(54.5968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3534, device='cuda:0')
upd norm tensor(2.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(52.0168, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4067, device='cuda:0')
upd norm tensor(2.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.4490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7474, device='cuda:0')
upd norm tensor(2.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.9326, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0112, device='cuda:0')
upd norm tensor(2.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.0892, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5791, device='cuda:0')
upd norm tensor(4.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the capital city of canton of Bagn√®res-de-Bigorre is] -> [ Knarvik]
Computing right vector (v)
Lookup index found: 18 | Sentence: The name of the capital city of canton of Bagn√®res-de-Bigorre is Knar | Token: re
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.458 = 8.458 + 0.0 + 0.0 avg prob of [ Knarvik] 0.00024466344621032476
loss 5.052 = 4.66 + 0.392 + 0.0 avg prob of [ Knarvik] 0.009621738456189632
loss 4.534 = 4.159 + 0.375 + 0.0 avg prob of [ Knarvik] 0.017060158774256706
loss 1.635 = 1.228 + 0.407 + 0.0 avg prob of [ Knarvik] 0.29709187150001526
loss 0.486 = 0.079 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9242154955863953
loss 0.42 = 0.013 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9867501258850098
loss 0.418 = 0.011 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9892411231994629
loss 0.42 = 0.013 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9866708517074585
loss 0.422 = 0.015 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9847845435142517
loss 0.418 = 0.012 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9878983497619629
loss 0.414 = 0.008 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9916070699691772
loss 0.412 = 0.006 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9935588836669922
loss 0.41 = 0.006 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9943916201591492
loss 0.41 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9947823882102966
loss 0.409 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9950642585754395
loss 0.408 = 0.005 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9953522086143494
loss 0.408 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9956467151641846
loss 0.407 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9959076642990112
loss 0.406 = 0.004 + 0.402 + 0.0 avg prob of [ Knarvik] 0.9960910677909851
loss 0.406 = 0.004 + 0.401 + 0.0 avg prob of [ Knarvik] 0.9961570501327515
loss 0.405 = 0.004 + 0.4 + 0.0 avg prob of [ Knarvik] 0.9960526823997498
loss 0.403 = 0.004 + 0.398 + 0.0 avg prob of [ Knarvik] 0.9956769943237305
loss 0.4 = 0.005 + 0.395 + 0.0 avg prob of [ Knarvik] 0.9947869181632996
loss 0.395 = 0.007 + 0.387 + 0.0 avg prob of [ Knarvik] 0.9926511645317078
loss 0.381 = 0.014 + 0.367 + 0.0 avg prob of [ Knarvik] 0.9862655997276306
Init norm 13.75742244720459 | Delta norm 55.02968978881836 | Target norm 57.197044372558594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.0297, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3776, device='cuda:0')
upd norm tensor(2.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.2903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4289, device='cuda:0')
upd norm tensor(2.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.2762, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7725, device='cuda:0')
upd norm tensor(2.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.0288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0435, device='cuda:0')
upd norm tensor(3.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.4549, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6389, device='cuda:0')
upd norm tensor(4.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.2683091787439613}, 'post': {'rewrite_acc': 0.9971014492753624}}
2024-10-29 22:52:13,656 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 22:52:13 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.47s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.33s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.65s/it]
2024-10-29 22:52:21,383 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 22:52:21 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/20 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  5%|‚ñå         | 1/20 [00:00<00:10,  1.89it/s] 15%|‚ñà‚ñå        | 3/20 [00:00<00:03,  5.39it/s] 25%|‚ñà‚ñà‚ñå       | 5/20 [00:00<00:01,  8.19it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 7/20 [00:00<00:01, 10.22it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 9/20 [00:01<00:00, 11.85it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 11/20 [00:01<00:00, 12.83it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 13/20 [00:01<00:00, 13.50it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 15/20 [00:01<00:00, 13.07it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 17/20 [00:01<00:00, 13.61it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 19/20 [00:01<00:00, 14.26it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:01<00:00, 11.16it/s]
  0%|          | 0/20 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
  5%|‚ñå         | 1/20 [00:17<05:30, 17.39s/it] 10%|‚ñà         | 2/20 [00:31<04:39, 15.51s/it] 15%|‚ñà‚ñå        | 3/20 [00:38<03:13, 11.40s/it] 20%|‚ñà‚ñà        | 4/20 [00:49<03:01, 11.37s/it] 25%|‚ñà‚ñà‚ñå       | 5/20 [01:00<02:50, 11.36s/it] 30%|‚ñà‚ñà‚ñà       | 6/20 [01:11<02:37, 11.28s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 7/20 [01:24<02:31, 11.68s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 8/20 [01:36<02:21, 11.82s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 9/20 [01:47<02:08, 11.65s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 10/20 [01:59<01:55, 11.52s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 11/20 [02:11<01:46, 11.82s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 12/20 [02:22<01:32, 11.61s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 13/20 [02:33<01:19, 11.42s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 14/20 [02:45<01:09, 11.56s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 15/20 [03:00<01:02, 12.46s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 16/20 [03:08<00:45, 11.33s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 17/20 [03:22<00:36, 12.16s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 18/20 [03:35<00:24, 12.17s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 19/20 [03:47<00:12, 12.16s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [04:01<00:00, 12.91s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [04:01<00:00, 12.09s/it]
2024-10-29 22:56:29,025 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,134 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,197 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,259 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,322 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,384 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,451 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,514 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,576 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,638 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,705 - easyeditor.editors.editor - INFO - 10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,767 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,829 - easyeditor.editors.editor - INFO - 12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,925 - easyeditor.editors.editor - INFO - 13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.9565217391304348], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.9565217391304348], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:29,992 - easyeditor.editors.editor - INFO - 14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:29 - INFO - easyeditor.editors.editor -   14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:30,060 - easyeditor.editors.editor - INFO - 15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:30 - INFO - easyeditor.editors.editor -   15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:30,127 - easyeditor.editors.editor - INFO - 16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:30 - INFO - easyeditor.editors.editor -   16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:30,206 - easyeditor.editors.editor - INFO - 17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:30 - INFO - easyeditor.editors.editor -   17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:30,269 - easyeditor.editors.editor - INFO - 18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:30 - INFO - easyeditor.editors.editor -   18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
2024-10-29 22:56:30,337 - easyeditor.editors.editor - INFO - 19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 22:56:30 - INFO - easyeditor.editors.editor -   19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the mother of Stephana Warnock is] -> [ Sheila Mary Nolan]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the mother of Stephana Warnock is Sheila Mary N | Token: ck
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.607 = 5.607 + 0.0 + 0.0 avg prob of [ Sheila Mary Nolan] 0.0038164069410413504
loss 4.121 = 4.041 + 0.081 + 0.0 avg prob of [ Sheila Mary Nolan] 0.017668189480900764
loss 2.539 = 2.278 + 0.261 + 0.0 avg prob of [ Sheila Mary Nolan] 0.10279671847820282
loss 1.638 = 1.375 + 0.263 + 0.0 avg prob of [ Sheila Mary Nolan] 0.2534908056259155
loss 0.589 = 0.32 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.7290753126144409
loss 0.278 = 0.008 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9921392202377319
loss 0.277 = 0.006 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9939529895782471
loss 0.274 = 0.003 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9970394968986511
loss 0.273 = 0.003 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9972531199455261
loss 0.261 = 0.002 + 0.259 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9978387355804443
loss 1.313 = 1.07 + 0.243 + 0.0 avg prob of [ Sheila Mary Nolan] 0.34820589423179626
loss 0.277 = 0.005 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9946407079696655
loss 0.32 = 0.049 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9526904821395874
loss 0.282 = 0.011 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9890134334564209
loss 0.29 = 0.02 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.979956328868866
loss 0.308 = 0.038 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9627887606620789
loss 0.31 = 0.041 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9601114988327026
loss 0.289 = 0.02 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9798704385757446
loss 0.279 = 0.011 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9891979098320007
loss 0.276 = 0.008 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9919161796569824
loss 0.274 = 0.007 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9928478598594666
loss 0.273 = 0.007 + 0.266 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9933524131774902
loss 0.272 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.993818998336792
loss 0.271 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9943550825119019
loss 0.269 = 0.005 + 0.264 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9949434995651245
Init norm 10.451786041259766 | Delta norm 41.80714416503906 | Target norm 43.345272064208984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(41.8071, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2871, device='cuda:0')
upd norm tensor(2.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.4182, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3533, device='cuda:0')
upd norm tensor(2.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.4749, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6933, device='cuda:0')
upd norm tensor(2.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9427, device='cuda:0')
upd norm tensor(2.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.3619, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4336, device='cuda:0')
upd norm tensor(3.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Darren Finlay is] -> [ spaceship captain]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Darren Finlay is spaceship | Token: lay
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ spaceship captain] 0.0031509259715676308
loss 3.808 = 3.734 + 0.073 + 0.0 avg prob of [ spaceship captain] 0.02488766238093376
loss 2.243 = 1.958 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.14252355694770813
loss 0.729 = 0.443 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.6496155261993408
loss 0.309 = 0.02 + 0.289 + 0.0 avg prob of [ spaceship captain] 0.9803946018218994
loss 0.299 = 0.013 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9871116876602173
loss 0.291 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9952278137207031
loss 0.292 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9947180151939392
loss 0.29 = 0.003 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9966393709182739
loss 0.288 = 0.002 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9984142780303955
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9989546537399292
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9991535544395447
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999259889125824
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993330836296082
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993906021118164
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994384050369263
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994781017303467
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999510645866394
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995357394218445
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995522499084473
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995567798614502
loss 0.286 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999541699886322
loss 0.286 = 0.001 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.999482274055481
loss 0.284 = 0.001 + 0.283 + 0.0 avg prob of [ spaceship captain] 0.9992715120315552
loss 0.269 = 0.002 + 0.266 + 0.0 avg prob of [ spaceship captain] 0.9978246688842773
Init norm 11.212502479553223 | Delta norm 44.85000991821289 | Target norm 46.32301712036133


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8500, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3073, device='cuda:0')
upd norm tensor(2.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3681, device='cuda:0')
upd norm tensor(2.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.9594, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7088, device='cuda:0')
upd norm tensor(2.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4587, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9623, device='cuda:0')
upd norm tensor(2.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2282, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4749, device='cuda:0')
upd norm tensor(3.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Henry John Gepp is] -> [ bigender]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Henry John Gepp is big | Token: pp
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.613 = 8.613 + 0.0 + 0.0 avg prob of [ bigender] 0.00024923926685005426
loss 5.668 = 5.409 + 0.259 + 0.0 avg prob of [ bigender] 0.00471782311797142
loss 3.402 = 3.116 + 0.286 + 0.0 avg prob of [ bigender] 0.044810354709625244
loss 1.863 = 1.576 + 0.286 + 0.0 avg prob of [ bigender] 0.2090466022491455
loss 2.594 = 2.308 + 0.286 + 0.0 avg prob of [ bigender] 0.10035304725170135
loss 0.382 = 0.096 + 0.285 + 0.0 avg prob of [ bigender] 0.9083206057548523
loss 0.411 = 0.131 + 0.28 + 0.0 avg prob of [ bigender] 0.8777483701705933
loss 0.333 = 0.056 + 0.277 + 0.0 avg prob of [ bigender] 0.945836067199707
loss 0.298 = 0.018 + 0.28 + 0.0 avg prob of [ bigender] 0.9822215437889099
loss 0.291 = 0.008 + 0.283 + 0.0 avg prob of [ bigender] 0.9919554591178894
loss 0.289 = 0.005 + 0.284 + 0.0 avg prob of [ bigender] 0.9952031970024109
loss 0.288 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9965540766716003
loss 0.287 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9971374273300171
loss 0.284 = 0.003 + 0.281 + 0.0 avg prob of [ bigender] 0.9971071481704712
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ bigender] 0.9940347075462341
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9985091686248779
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9986342191696167
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998675525188446
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987055659294128
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998738169670105
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987771511077881
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988228678703308
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988745450973511
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989303350448608
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989882707595825
Init norm 11.56171703338623 | Delta norm 46.246864318847656 | Target norm 47.51656723022461


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.2469, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3295, device='cuda:0')
upd norm tensor(2.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.7641, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3870, device='cuda:0')
upd norm tensor(2.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.4596, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7276, device='cuda:0')
upd norm tensor(2.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4244, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9855, device='cuda:0')
upd norm tensor(2.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9834, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5289, device='cuda:0')
upd norm tensor(3.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by] -> [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles]
Computing right vector (v)
Lookup index found: 19 | Sentence: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by 1995/1996 German Badminton Championships U14 ‚Äì women's | Token: kg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.353 = 3.353 + 0.0 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.03520524501800537
loss 3.407 = 3.103 + 0.304 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.0450158566236496
loss 2.889 = 2.77 + 0.119 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.06274893879890442
loss 2.398 = 2.381 + 0.016 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.09277491271495819
loss 1.887 = 1.87 + 0.017 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.1548815369606018
loss 1.276 = 1.257 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.2849786877632141
loss 0.861 = 0.84 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.43282267451286316
loss 0.572 = 0.552 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.5766874551773071
loss 0.279 = 0.259 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.7725369334220886
loss 0.118 = 0.095 + 0.022 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9097639322280884
loss 0.068 = 0.042 + 0.026 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.959246039390564
loss 0.038 = 0.015 + 0.023 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9852155447006226
Init norm 13.64920425415039 | Delta norm 54.59681701660156 | Target norm 56.80078887939453


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(54.5968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3534, device='cuda:0')
upd norm tensor(2.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(52.0168, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4067, device='cuda:0')
upd norm tensor(2.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.4490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7474, device='cuda:0')
upd norm tensor(2.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.9326, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0112, device='cuda:0')
upd norm tensor(2.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.0892, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5791, device='cuda:0')
upd norm tensor(4.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the capital city of canton of Bagn√®res-de-Bigorre is] -> [ Knarvik]
Computing right vector (v)
Lookup index found: 18 | Sentence: The name of the capital city of canton of Bagn√®res-de-Bigorre is Knar | Token: re
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.458 = 8.458 + 0.0 + 0.0 avg prob of [ Knarvik] 0.00024466344621032476
loss 5.052 = 4.66 + 0.392 + 0.0 avg prob of [ Knarvik] 0.009621738456189632
loss 4.534 = 4.159 + 0.375 + 0.0 avg prob of [ Knarvik] 0.017060158774256706
loss 1.635 = 1.228 + 0.407 + 0.0 avg prob of [ Knarvik] 0.29709187150001526
loss 0.486 = 0.079 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9242154955863953
loss 0.42 = 0.013 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9867501258850098
loss 0.418 = 0.011 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9892411231994629
loss 0.42 = 0.013 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9866708517074585
loss 0.422 = 0.015 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9847845435142517
loss 0.418 = 0.012 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9878983497619629
loss 0.414 = 0.008 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9916070699691772
loss 0.412 = 0.006 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9935588836669922
loss 0.41 = 0.006 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9943916201591492
loss 0.41 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9947823882102966
loss 0.409 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9950642585754395
loss 0.408 = 0.005 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9953522086143494
loss 0.408 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9956467151641846
loss 0.407 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9959076642990112
loss 0.406 = 0.004 + 0.402 + 0.0 avg prob of [ Knarvik] 0.9960910677909851
loss 0.406 = 0.004 + 0.401 + 0.0 avg prob of [ Knarvik] 0.9961570501327515
loss 0.405 = 0.004 + 0.4 + 0.0 avg prob of [ Knarvik] 0.9960526823997498
loss 0.403 = 0.004 + 0.398 + 0.0 avg prob of [ Knarvik] 0.9956769943237305
loss 0.4 = 0.005 + 0.395 + 0.0 avg prob of [ Knarvik] 0.9947869181632996
loss 0.395 = 0.007 + 0.387 + 0.0 avg prob of [ Knarvik] 0.9926511645317078
loss 0.381 = 0.014 + 0.367 + 0.0 avg prob of [ Knarvik] 0.9862655997276306
Init norm 13.75742244720459 | Delta norm 55.02968978881836 | Target norm 57.197044372558594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.0297, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3776, device='cuda:0')
upd norm tensor(2.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.2903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4289, device='cuda:0')
upd norm tensor(2.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.2762, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7725, device='cuda:0')
upd norm tensor(2.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.0288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0435, device='cuda:0')
upd norm tensor(3.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.4549, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6389, device='cuda:0')
upd norm tensor(4.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Nicol√°s M√©ndez Casariego is] -> [ Tharangambadi]
Computing right vector (v)
Lookup index found: 13 | Sentence: The place of birth of Nicol√°s M√©ndez Casariego is Tharangamb | Token: iego
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.212 = 5.212 + 0.0 + 0.0 avg prob of [ Tharangambadi] 0.005583751946687698
loss 2.071 = 1.94 + 0.131 + 0.0 avg prob of [ Tharangambadi] 0.1442318558692932
loss 2.016 = 1.969 + 0.047 + 0.0 avg prob of [ Tharangambadi] 0.14092321693897247
loss 0.977 = 0.745 + 0.232 + 0.0 avg prob of [ Tharangambadi] 0.47648951411247253
loss 0.247 = 0.137 + 0.109 + 0.0 avg prob of [ Tharangambadi] 0.8725411295890808
loss 0.073 = 0.022 + 0.051 + 0.0 avg prob of [ Tharangambadi] 0.978609025478363
loss 0.073 = 0.014 + 0.059 + 0.0 avg prob of [ Tharangambadi] 0.9862703680992126
loss 0.057 = 0.009 + 0.048 + 0.0 avg prob of [ Tharangambadi] 0.9914528727531433
loss 0.057 = 0.006 + 0.05 + 0.0 avg prob of [ Tharangambadi] 0.9935469031333923
loss 0.051 = 0.006 + 0.045 + 0.0 avg prob of [ Tharangambadi] 0.9944161772727966
loss 0.051 = 0.005 + 0.046 + 0.0 avg prob of [ Tharangambadi] 0.9949017763137817
loss 0.049 = 0.005 + 0.044 + 0.0 avg prob of [ Tharangambadi] 0.99549400806427
Init norm 11.820267677307129 | Delta norm 47.281070709228516 | Target norm 49.48406982421875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4101, device='cuda:0')
upd norm tensor(2.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.0030, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4570, device='cuda:0')
upd norm tensor(2.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9796, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7993, device='cuda:0')
upd norm tensor(2.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7175, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0801, device='cuda:0')
upd norm tensor(2.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.7751, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6996, device='cuda:0')
upd norm tensor(3.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Thomas Phillipps Lamb is] -> [ deputy high court judge]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Thomas Phillipps Lamb is deputy high court | Token: Lamb
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.536 = 4.536 + 0.0 + 0.0 avg prob of [ deputy high court judge] 0.011187071911990643
loss 2.153 = 1.905 + 0.248 + 0.0 avg prob of [ deputy high court judge] 0.1506791114807129
loss 2.517 = 2.2 + 0.316 + 0.0 avg prob of [ deputy high court judge] 0.11348851025104523
loss 1.484 = 1.217 + 0.267 + 0.0 avg prob of [ deputy high court judge] 0.2975485026836395
loss 0.316 = 0.056 + 0.259 + 0.0 avg prob of [ deputy high court judge] 0.9452149868011475
loss 0.219 = 0.161 + 0.057 + 0.0 avg prob of [ deputy high court judge] 0.8546231985092163
loss 0.287 = 0.013 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9872293472290039
loss 0.28 = 0.005 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9951062202453613
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.996562659740448
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9971231818199158
loss 0.277 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9974326491355896
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9976330995559692
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9977788329124451
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.997896671295166
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9980010986328125
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981006979942322
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981997013092041
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9982994794845581
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9983994364738464
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9984978437423706
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9985925555229187
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9986819624900818
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9987648725509644
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9988407492637634
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9989093542098999
Init norm 11.668208122253418 | Delta norm 46.67283248901367 | Target norm 47.940155029296875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4355, device='cuda:0')
upd norm tensor(2.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2678, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4781, device='cuda:0')
upd norm tensor(2.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9152, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8203, device='cuda:0')
upd norm tensor(2.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6206, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1043, device='cuda:0')
upd norm tensor(2.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5778, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(3.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Yoshida Keigo is] -> [ intersex organism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Yoshida Keigo is intersex organ | Token: igo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.154 = 6.154 + 0.0 + 0.0 avg prob of [ intersex organism] 0.002235337160527706
loss 4.674 = 4.436 + 0.238 + 0.0 avg prob of [ intersex organism] 0.012196492403745651
loss 2.694 = 2.457 + 0.237 + 0.0 avg prob of [ intersex organism] 0.08594139665365219
loss 1.409 = 1.173 + 0.236 + 0.0 avg prob of [ intersex organism] 0.3106464147567749
loss 0.299 = 0.066 + 0.233 + 0.0 avg prob of [ intersex organism] 0.9358271360397339
loss 0.278 = 0.039 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9619175791740417
loss 0.242 = 0.005 + 0.237 + 0.0 avg prob of [ intersex organism] 0.994818389415741
loss 0.24 = 0.002 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9979938268661499
loss 0.24 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.998679518699646
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9989312887191772
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990383982658386
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990581274032593
loss 0.238 = 0.001 + 0.237 + 0.0 avg prob of [ intersex organism] 0.9989722967147827
loss 0.236 = 0.001 + 0.234 + 0.0 avg prob of [ intersex organism] 0.9986181259155273
loss 0.22 = 0.004 + 0.217 + 0.0 avg prob of [ intersex organism] 0.9964985251426697
loss 0.338 = 0.201 + 0.137 + 0.0 avg prob of [ intersex organism] 0.8238176107406616
loss 0.24 = 0.001 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9993938207626343
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9979710578918457
loss 0.249 = 0.011 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9895128607749939
loss 0.268 = 0.03 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9707574248313904
loss 0.254 = 0.015 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9848440885543823
loss 0.245 = 0.007 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9933988451957703
loss 0.243 = 0.004 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9958910942077637
loss 0.242 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9967593550682068
loss 0.241 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.997196614742279
Init norm 12.686749458312988 | Delta norm 50.74699783325195 | Target norm 52.94290542602539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7470, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4567, device='cuda:0')
upd norm tensor(2.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7230, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4976, device='cuda:0')
upd norm tensor(2.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.6228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8382, device='cuda:0')
upd norm tensor(2.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9657, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1283, device='cuda:0')
upd norm tensor(2.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.4189, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8053, device='cuda:0')
upd norm tensor(3.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [2041 BC follows] -> [ 29668 Ipf]
Computing right vector (v)
Lookup index found: 6 | Sentence: 2041 BC follows 29668 I | Token: BC
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.78 = 6.78 + 0.0 + 0.0 avg prob of [ 29668 Ipf] 0.0011842688545584679
loss 5.645 = 5.42 + 0.225 + 0.0 avg prob of [ 29668 Ipf] 0.004440009593963623
loss 4.847 = 4.718 + 0.129 + 0.0 avg prob of [ 29668 Ipf] 0.00958884134888649
loss 3.992 = 3.855 + 0.137 + 0.0 avg prob of [ 29668 Ipf] 0.02176203392446041
loss 2.709 = 2.553 + 0.155 + 0.0 avg prob of [ 29668 Ipf] 0.08010239899158478
loss 1.658 = 1.493 + 0.164 + 0.0 avg prob of [ 29668 Ipf] 0.22878196835517883
loss 0.859 = 0.706 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.5008167624473572
loss 0.467 = 0.314 + 0.153 + 0.0 avg prob of [ 29668 Ipf] 0.7312717437744141
loss 0.305 = 0.153 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.8584901094436646
loss 0.217 = 0.059 + 0.157 + 0.0 avg prob of [ 29668 Ipf] 0.9424829483032227
loss 0.176 = 0.019 + 0.156 + 0.0 avg prob of [ 29668 Ipf] 0.9809708595275879
loss 0.168 = 0.009 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9908093810081482
loss 0.165 = 0.006 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9937031269073486
loss 0.163 = 0.004 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9961495399475098
loss 0.162 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9975597858428955
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9981834292411804
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9985010027885437
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9986904859542847
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9988631010055542
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9990620613098145
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9992455244064331
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9993878602981567
loss 0.159 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9994925856590271
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9995701313018799
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.999629020690918
Init norm 12.345292091369629 | Delta norm 49.38117218017578 | Target norm 51.165740966796875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3812, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4836, device='cuda:0')
upd norm tensor(2.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.5944, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5201, device='cuda:0')
upd norm tensor(2.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.3130, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8602, device='cuda:0')
upd norm tensor(2.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.6083, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1596, device='cuda:0')
upd norm tensor(2.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.2423, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8637, device='cuda:0')
upd norm tensor(3.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1981 Lithuanian Badminton Championships ‚Äì women's singles follows] -> [ Loschge, Friedrich Heinrich]
Computing right vector (v)
Lookup index found: 17 | Sentence: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows Loschge, Friedrich | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.49 = 8.49 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.00022668617020826787
loss 6.503 = 6.296 + 0.207 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0019449219107627869
loss 5.135 = 5.135 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0066849044524133205
loss 3.276 = 2.881 + 0.395 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.056303467601537704
loss 1.624 = 1.617 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.20898878574371338
loss 0.604 = 0.601 + 0.003 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.568875253200531
loss 0.294 = 0.285 + 0.009 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.7627280950546265
loss 0.136 = 0.091 + 0.044 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9188784956932068
loss 0.136 = 0.057 + 0.078 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9482223391532898
loss 0.101 = 0.077 + 0.023 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9353789687156677
loss 0.105 = 0.097 + 0.008 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9234482049942017
loss 0.106 = 0.099 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9230228662490845
loss 0.097 = 0.083 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9329265356063843
loss 0.098 = 0.063 + 0.035 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9468004107475281
loss 0.101 = 0.058 + 0.042 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9499897360801697
loss 0.094 = 0.073 + 0.02 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.939834475517273
loss 0.097 = 0.086 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9318189024925232
loss 0.096 = 0.085 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9324424266815186
loss 0.093 = 0.073 + 0.019 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9400944709777832
loss 0.095 = 0.062 + 0.032 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9475826621055603
loss 0.094 = 0.064 + 0.03 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9465584754943848
loss 0.092 = 0.074 + 0.018 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9399330019950867
loss 0.094 = 0.08 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9359598159790039
loss 0.093 = 0.077 + 0.015 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9377471804618835
loss 0.092 = 0.069 + 0.022 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9431607127189636
Init norm 14.525349617004395 | Delta norm 58.10139846801758 | Target norm 59.97038650512695


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(58.1014, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5071, device='cuda:0')
upd norm tensor(2.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5289, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5397, device='cuda:0')
upd norm tensor(2.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(49.7651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8816, device='cuda:0')
upd norm tensor(2.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(42.7677, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1878, device='cuda:0')
upd norm tensor(3.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(33.3730, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.9184, device='cuda:0')
upd norm tensor(4.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.26623188405797105}, 'post': {'rewrite_acc': 0.9915760869565217}}
2024-10-29 22:57:00,272 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 22:57:00 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.28s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.16s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.48s/it]
2024-10-29 22:57:08,030 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 22:57:08 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/25 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  4%|‚ñç         | 1/25 [00:00<00:12,  1.90it/s] 12%|‚ñà‚ñè        | 3/25 [00:00<00:04,  5.41it/s] 20%|‚ñà‚ñà        | 5/25 [00:00<00:02,  8.21it/s] 28%|‚ñà‚ñà‚ñä       | 7/25 [00:00<00:01, 10.25it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:01<00:01, 11.87it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:01<00:01, 12.94it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:01<00:00, 13.85it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:01<00:00, 13.29it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:01<00:00, 13.68it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:01<00:00, 14.29it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:01<00:00, 14.62it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:01<00:00, 15.03it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:02<00:00, 14.16it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:02<00:00, 11.75it/s]
  0%|          | 0/25 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
  4%|‚ñç         | 1/25 [00:17<06:54, 17.27s/it]  8%|‚ñä         | 2/25 [00:31<05:55, 15.46s/it] 12%|‚ñà‚ñè        | 3/25 [00:37<04:09, 11.35s/it] 16%|‚ñà‚ñå        | 4/25 [00:49<03:57, 11.33s/it] 20%|‚ñà‚ñà        | 5/25 [01:00<03:46, 11.30s/it] 24%|‚ñà‚ñà‚ñç       | 6/25 [01:11<03:34, 11.28s/it] 28%|‚ñà‚ñà‚ñä       | 7/25 [01:24<03:30, 11.67s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [01:36<03:20, 11.80s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [01:47<03:05, 11.58s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 10/25 [01:58<02:51, 11.46s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [02:11<02:44, 11.77s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [02:22<02:30, 11.60s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [02:33<02:17, 11.43s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [02:45<02:07, 11.55s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [02:59<02:04, 12.42s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [03:08<01:41, 11.28s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [03:22<01:36, 12.11s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [03:34<01:24, 12.14s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [03:46<01:12, 12.17s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [04:01<01:04, 12.90s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [04:13<00:50, 12.65s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [04:24<00:36, 12.21s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [04:36<00:24, 12.25s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [04:47<00:11, 11.83s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [04:59<00:00, 11.78s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [04:59<00:00, 11.97s/it]
2024-10-29 23:02:13,491 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:13 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:13,566 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:13 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:13,629 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:13 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:13,691 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:13 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:13,753 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:13 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:13,816 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:13 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:13,882 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:13 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:13,945 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:13 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,007 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,069 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,136 - easyeditor.editors.editor - INFO - 10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,198 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,260 - easyeditor.editors.editor - INFO - 12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,356 - easyeditor.editors.editor - INFO - 13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.7391304347826086], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.7391304347826086], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,423 - easyeditor.editors.editor - INFO - 14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,490 - easyeditor.editors.editor - INFO - 15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,557 - easyeditor.editors.editor - INFO - 16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,619 - easyeditor.editors.editor - INFO - 17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,682 - easyeditor.editors.editor - INFO - 18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,750 - easyeditor.editors.editor - INFO - 19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,812 - easyeditor.editors.editor - INFO - 20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,874 - easyeditor.editors.editor - INFO - 21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:14,937 - easyeditor.editors.editor - INFO - 22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:14 - INFO - easyeditor.editors.editor -   22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:15,029 - easyeditor.editors.editor - INFO - 23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:15 - INFO - easyeditor.editors.editor -   23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:02:15,096 - easyeditor.editors.editor - INFO - 24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:02:15 - INFO - easyeditor.editors.editor -   24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the mother of Stephana Warnock is] -> [ Sheila Mary Nolan]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the mother of Stephana Warnock is Sheila Mary N | Token: ck
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.607 = 5.607 + 0.0 + 0.0 avg prob of [ Sheila Mary Nolan] 0.0038164069410413504
loss 4.121 = 4.041 + 0.081 + 0.0 avg prob of [ Sheila Mary Nolan] 0.017668189480900764
loss 2.539 = 2.278 + 0.261 + 0.0 avg prob of [ Sheila Mary Nolan] 0.10279671847820282
loss 1.638 = 1.375 + 0.263 + 0.0 avg prob of [ Sheila Mary Nolan] 0.2534908056259155
loss 0.589 = 0.32 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.7290753126144409
loss 0.278 = 0.008 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9921392202377319
loss 0.277 = 0.006 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9939529895782471
loss 0.274 = 0.003 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9970394968986511
loss 0.273 = 0.003 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9972531199455261
loss 0.261 = 0.002 + 0.259 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9978387355804443
loss 1.313 = 1.07 + 0.243 + 0.0 avg prob of [ Sheila Mary Nolan] 0.34820589423179626
loss 0.277 = 0.005 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9946407079696655
loss 0.32 = 0.049 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9526904821395874
loss 0.282 = 0.011 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9890134334564209
loss 0.29 = 0.02 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.979956328868866
loss 0.308 = 0.038 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9627887606620789
loss 0.31 = 0.041 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9601114988327026
loss 0.289 = 0.02 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9798704385757446
loss 0.279 = 0.011 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9891979098320007
loss 0.276 = 0.008 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9919161796569824
loss 0.274 = 0.007 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9928478598594666
loss 0.273 = 0.007 + 0.266 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9933524131774902
loss 0.272 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.993818998336792
loss 0.271 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9943550825119019
loss 0.269 = 0.005 + 0.264 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9949434995651245
Init norm 10.451786041259766 | Delta norm 41.80714416503906 | Target norm 43.345272064208984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(41.8071, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2871, device='cuda:0')
upd norm tensor(2.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.4182, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3533, device='cuda:0')
upd norm tensor(2.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.4749, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6933, device='cuda:0')
upd norm tensor(2.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9427, device='cuda:0')
upd norm tensor(2.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.3619, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4336, device='cuda:0')
upd norm tensor(3.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Darren Finlay is] -> [ spaceship captain]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Darren Finlay is spaceship | Token: lay
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ spaceship captain] 0.0031509259715676308
loss 3.808 = 3.734 + 0.073 + 0.0 avg prob of [ spaceship captain] 0.02488766238093376
loss 2.243 = 1.958 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.14252355694770813
loss 0.729 = 0.443 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.6496155261993408
loss 0.309 = 0.02 + 0.289 + 0.0 avg prob of [ spaceship captain] 0.9803946018218994
loss 0.299 = 0.013 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9871116876602173
loss 0.291 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9952278137207031
loss 0.292 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9947180151939392
loss 0.29 = 0.003 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9966393709182739
loss 0.288 = 0.002 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9984142780303955
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9989546537399292
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9991535544395447
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999259889125824
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993330836296082
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993906021118164
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994384050369263
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994781017303467
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999510645866394
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995357394218445
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995522499084473
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995567798614502
loss 0.286 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999541699886322
loss 0.286 = 0.001 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.999482274055481
loss 0.284 = 0.001 + 0.283 + 0.0 avg prob of [ spaceship captain] 0.9992715120315552
loss 0.269 = 0.002 + 0.266 + 0.0 avg prob of [ spaceship captain] 0.9978246688842773
Init norm 11.212502479553223 | Delta norm 44.85000991821289 | Target norm 46.32301712036133


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8500, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3073, device='cuda:0')
upd norm tensor(2.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3681, device='cuda:0')
upd norm tensor(2.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.9594, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7088, device='cuda:0')
upd norm tensor(2.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4587, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9623, device='cuda:0')
upd norm tensor(2.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2282, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4749, device='cuda:0')
upd norm tensor(3.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Henry John Gepp is] -> [ bigender]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Henry John Gepp is big | Token: pp
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.613 = 8.613 + 0.0 + 0.0 avg prob of [ bigender] 0.00024923926685005426
loss 5.668 = 5.409 + 0.259 + 0.0 avg prob of [ bigender] 0.00471782311797142
loss 3.402 = 3.116 + 0.286 + 0.0 avg prob of [ bigender] 0.044810354709625244
loss 1.863 = 1.576 + 0.286 + 0.0 avg prob of [ bigender] 0.2090466022491455
loss 2.594 = 2.308 + 0.286 + 0.0 avg prob of [ bigender] 0.10035304725170135
loss 0.382 = 0.096 + 0.285 + 0.0 avg prob of [ bigender] 0.9083206057548523
loss 0.411 = 0.131 + 0.28 + 0.0 avg prob of [ bigender] 0.8777483701705933
loss 0.333 = 0.056 + 0.277 + 0.0 avg prob of [ bigender] 0.945836067199707
loss 0.298 = 0.018 + 0.28 + 0.0 avg prob of [ bigender] 0.9822215437889099
loss 0.291 = 0.008 + 0.283 + 0.0 avg prob of [ bigender] 0.9919554591178894
loss 0.289 = 0.005 + 0.284 + 0.0 avg prob of [ bigender] 0.9952031970024109
loss 0.288 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9965540766716003
loss 0.287 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9971374273300171
loss 0.284 = 0.003 + 0.281 + 0.0 avg prob of [ bigender] 0.9971071481704712
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ bigender] 0.9940347075462341
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9985091686248779
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9986342191696167
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998675525188446
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987055659294128
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998738169670105
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987771511077881
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988228678703308
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988745450973511
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989303350448608
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989882707595825
Init norm 11.56171703338623 | Delta norm 46.246864318847656 | Target norm 47.51656723022461


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.2469, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3295, device='cuda:0')
upd norm tensor(2.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.7641, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3870, device='cuda:0')
upd norm tensor(2.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.4596, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7276, device='cuda:0')
upd norm tensor(2.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4244, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9855, device='cuda:0')
upd norm tensor(2.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9834, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5289, device='cuda:0')
upd norm tensor(3.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by] -> [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles]
Computing right vector (v)
Lookup index found: 19 | Sentence: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by 1995/1996 German Badminton Championships U14 ‚Äì women's | Token: kg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.353 = 3.353 + 0.0 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.03520524501800537
loss 3.407 = 3.103 + 0.304 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.0450158566236496
loss 2.889 = 2.77 + 0.119 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.06274893879890442
loss 2.398 = 2.381 + 0.016 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.09277491271495819
loss 1.887 = 1.87 + 0.017 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.1548815369606018
loss 1.276 = 1.257 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.2849786877632141
loss 0.861 = 0.84 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.43282267451286316
loss 0.572 = 0.552 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.5766874551773071
loss 0.279 = 0.259 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.7725369334220886
loss 0.118 = 0.095 + 0.022 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9097639322280884
loss 0.068 = 0.042 + 0.026 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.959246039390564
loss 0.038 = 0.015 + 0.023 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9852155447006226
Init norm 13.64920425415039 | Delta norm 54.59681701660156 | Target norm 56.80078887939453


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(54.5968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3534, device='cuda:0')
upd norm tensor(2.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(52.0168, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4067, device='cuda:0')
upd norm tensor(2.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.4490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7474, device='cuda:0')
upd norm tensor(2.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.9326, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0112, device='cuda:0')
upd norm tensor(2.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.0892, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5791, device='cuda:0')
upd norm tensor(4.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the capital city of canton of Bagn√®res-de-Bigorre is] -> [ Knarvik]
Computing right vector (v)
Lookup index found: 18 | Sentence: The name of the capital city of canton of Bagn√®res-de-Bigorre is Knar | Token: re
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.458 = 8.458 + 0.0 + 0.0 avg prob of [ Knarvik] 0.00024466344621032476
loss 5.052 = 4.66 + 0.392 + 0.0 avg prob of [ Knarvik] 0.009621738456189632
loss 4.534 = 4.159 + 0.375 + 0.0 avg prob of [ Knarvik] 0.017060158774256706
loss 1.635 = 1.228 + 0.407 + 0.0 avg prob of [ Knarvik] 0.29709187150001526
loss 0.486 = 0.079 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9242154955863953
loss 0.42 = 0.013 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9867501258850098
loss 0.418 = 0.011 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9892411231994629
loss 0.42 = 0.013 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9866708517074585
loss 0.422 = 0.015 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9847845435142517
loss 0.418 = 0.012 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9878983497619629
loss 0.414 = 0.008 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9916070699691772
loss 0.412 = 0.006 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9935588836669922
loss 0.41 = 0.006 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9943916201591492
loss 0.41 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9947823882102966
loss 0.409 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9950642585754395
loss 0.408 = 0.005 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9953522086143494
loss 0.408 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9956467151641846
loss 0.407 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9959076642990112
loss 0.406 = 0.004 + 0.402 + 0.0 avg prob of [ Knarvik] 0.9960910677909851
loss 0.406 = 0.004 + 0.401 + 0.0 avg prob of [ Knarvik] 0.9961570501327515
loss 0.405 = 0.004 + 0.4 + 0.0 avg prob of [ Knarvik] 0.9960526823997498
loss 0.403 = 0.004 + 0.398 + 0.0 avg prob of [ Knarvik] 0.9956769943237305
loss 0.4 = 0.005 + 0.395 + 0.0 avg prob of [ Knarvik] 0.9947869181632996
loss 0.395 = 0.007 + 0.387 + 0.0 avg prob of [ Knarvik] 0.9926511645317078
loss 0.381 = 0.014 + 0.367 + 0.0 avg prob of [ Knarvik] 0.9862655997276306
Init norm 13.75742244720459 | Delta norm 55.02968978881836 | Target norm 57.197044372558594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.0297, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3776, device='cuda:0')
upd norm tensor(2.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.2903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4289, device='cuda:0')
upd norm tensor(2.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.2762, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7725, device='cuda:0')
upd norm tensor(2.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.0288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0435, device='cuda:0')
upd norm tensor(3.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.4549, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6389, device='cuda:0')
upd norm tensor(4.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Nicol√°s M√©ndez Casariego is] -> [ Tharangambadi]
Computing right vector (v)
Lookup index found: 13 | Sentence: The place of birth of Nicol√°s M√©ndez Casariego is Tharangamb | Token: iego
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.212 = 5.212 + 0.0 + 0.0 avg prob of [ Tharangambadi] 0.005583751946687698
loss 2.071 = 1.94 + 0.131 + 0.0 avg prob of [ Tharangambadi] 0.1442318558692932
loss 2.016 = 1.969 + 0.047 + 0.0 avg prob of [ Tharangambadi] 0.14092321693897247
loss 0.977 = 0.745 + 0.232 + 0.0 avg prob of [ Tharangambadi] 0.47648951411247253
loss 0.247 = 0.137 + 0.109 + 0.0 avg prob of [ Tharangambadi] 0.8725411295890808
loss 0.073 = 0.022 + 0.051 + 0.0 avg prob of [ Tharangambadi] 0.978609025478363
loss 0.073 = 0.014 + 0.059 + 0.0 avg prob of [ Tharangambadi] 0.9862703680992126
loss 0.057 = 0.009 + 0.048 + 0.0 avg prob of [ Tharangambadi] 0.9914528727531433
loss 0.057 = 0.006 + 0.05 + 0.0 avg prob of [ Tharangambadi] 0.9935469031333923
loss 0.051 = 0.006 + 0.045 + 0.0 avg prob of [ Tharangambadi] 0.9944161772727966
loss 0.051 = 0.005 + 0.046 + 0.0 avg prob of [ Tharangambadi] 0.9949017763137817
loss 0.049 = 0.005 + 0.044 + 0.0 avg prob of [ Tharangambadi] 0.99549400806427
Init norm 11.820267677307129 | Delta norm 47.281070709228516 | Target norm 49.48406982421875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4101, device='cuda:0')
upd norm tensor(2.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.0030, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4570, device='cuda:0')
upd norm tensor(2.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9796, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7993, device='cuda:0')
upd norm tensor(2.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7175, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0801, device='cuda:0')
upd norm tensor(2.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.7751, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6996, device='cuda:0')
upd norm tensor(3.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Thomas Phillipps Lamb is] -> [ deputy high court judge]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Thomas Phillipps Lamb is deputy high court | Token: Lamb
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.536 = 4.536 + 0.0 + 0.0 avg prob of [ deputy high court judge] 0.011187071911990643
loss 2.153 = 1.905 + 0.248 + 0.0 avg prob of [ deputy high court judge] 0.1506791114807129
loss 2.517 = 2.2 + 0.316 + 0.0 avg prob of [ deputy high court judge] 0.11348851025104523
loss 1.484 = 1.217 + 0.267 + 0.0 avg prob of [ deputy high court judge] 0.2975485026836395
loss 0.316 = 0.056 + 0.259 + 0.0 avg prob of [ deputy high court judge] 0.9452149868011475
loss 0.219 = 0.161 + 0.057 + 0.0 avg prob of [ deputy high court judge] 0.8546231985092163
loss 0.287 = 0.013 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9872293472290039
loss 0.28 = 0.005 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9951062202453613
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.996562659740448
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9971231818199158
loss 0.277 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9974326491355896
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9976330995559692
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9977788329124451
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.997896671295166
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9980010986328125
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981006979942322
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981997013092041
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9982994794845581
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9983994364738464
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9984978437423706
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9985925555229187
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9986819624900818
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9987648725509644
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9988407492637634
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9989093542098999
Init norm 11.668208122253418 | Delta norm 46.67283248901367 | Target norm 47.940155029296875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4355, device='cuda:0')
upd norm tensor(2.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2678, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4781, device='cuda:0')
upd norm tensor(2.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9152, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8203, device='cuda:0')
upd norm tensor(2.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6206, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1043, device='cuda:0')
upd norm tensor(2.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5778, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(3.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Yoshida Keigo is] -> [ intersex organism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Yoshida Keigo is intersex organ | Token: igo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.154 = 6.154 + 0.0 + 0.0 avg prob of [ intersex organism] 0.002235337160527706
loss 4.674 = 4.436 + 0.238 + 0.0 avg prob of [ intersex organism] 0.012196492403745651
loss 2.694 = 2.457 + 0.237 + 0.0 avg prob of [ intersex organism] 0.08594139665365219
loss 1.409 = 1.173 + 0.236 + 0.0 avg prob of [ intersex organism] 0.3106464147567749
loss 0.299 = 0.066 + 0.233 + 0.0 avg prob of [ intersex organism] 0.9358271360397339
loss 0.278 = 0.039 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9619175791740417
loss 0.242 = 0.005 + 0.237 + 0.0 avg prob of [ intersex organism] 0.994818389415741
loss 0.24 = 0.002 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9979938268661499
loss 0.24 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.998679518699646
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9989312887191772
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990383982658386
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990581274032593
loss 0.238 = 0.001 + 0.237 + 0.0 avg prob of [ intersex organism] 0.9989722967147827
loss 0.236 = 0.001 + 0.234 + 0.0 avg prob of [ intersex organism] 0.9986181259155273
loss 0.22 = 0.004 + 0.217 + 0.0 avg prob of [ intersex organism] 0.9964985251426697
loss 0.338 = 0.201 + 0.137 + 0.0 avg prob of [ intersex organism] 0.8238176107406616
loss 0.24 = 0.001 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9993938207626343
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9979710578918457
loss 0.249 = 0.011 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9895128607749939
loss 0.268 = 0.03 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9707574248313904
loss 0.254 = 0.015 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9848440885543823
loss 0.245 = 0.007 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9933988451957703
loss 0.243 = 0.004 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9958910942077637
loss 0.242 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9967593550682068
loss 0.241 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.997196614742279
Init norm 12.686749458312988 | Delta norm 50.74699783325195 | Target norm 52.94290542602539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7470, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4567, device='cuda:0')
upd norm tensor(2.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7230, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4976, device='cuda:0')
upd norm tensor(2.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.6228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8382, device='cuda:0')
upd norm tensor(2.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9657, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1283, device='cuda:0')
upd norm tensor(2.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.4189, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8053, device='cuda:0')
upd norm tensor(3.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [2041 BC follows] -> [ 29668 Ipf]
Computing right vector (v)
Lookup index found: 6 | Sentence: 2041 BC follows 29668 I | Token: BC
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.78 = 6.78 + 0.0 + 0.0 avg prob of [ 29668 Ipf] 0.0011842688545584679
loss 5.645 = 5.42 + 0.225 + 0.0 avg prob of [ 29668 Ipf] 0.004440009593963623
loss 4.847 = 4.718 + 0.129 + 0.0 avg prob of [ 29668 Ipf] 0.00958884134888649
loss 3.992 = 3.855 + 0.137 + 0.0 avg prob of [ 29668 Ipf] 0.02176203392446041
loss 2.709 = 2.553 + 0.155 + 0.0 avg prob of [ 29668 Ipf] 0.08010239899158478
loss 1.658 = 1.493 + 0.164 + 0.0 avg prob of [ 29668 Ipf] 0.22878196835517883
loss 0.859 = 0.706 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.5008167624473572
loss 0.467 = 0.314 + 0.153 + 0.0 avg prob of [ 29668 Ipf] 0.7312717437744141
loss 0.305 = 0.153 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.8584901094436646
loss 0.217 = 0.059 + 0.157 + 0.0 avg prob of [ 29668 Ipf] 0.9424829483032227
loss 0.176 = 0.019 + 0.156 + 0.0 avg prob of [ 29668 Ipf] 0.9809708595275879
loss 0.168 = 0.009 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9908093810081482
loss 0.165 = 0.006 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9937031269073486
loss 0.163 = 0.004 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9961495399475098
loss 0.162 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9975597858428955
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9981834292411804
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9985010027885437
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9986904859542847
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9988631010055542
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9990620613098145
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9992455244064331
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9993878602981567
loss 0.159 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9994925856590271
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9995701313018799
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.999629020690918
Init norm 12.345292091369629 | Delta norm 49.38117218017578 | Target norm 51.165740966796875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3812, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4836, device='cuda:0')
upd norm tensor(2.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.5944, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5201, device='cuda:0')
upd norm tensor(2.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.3130, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8602, device='cuda:0')
upd norm tensor(2.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.6083, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1596, device='cuda:0')
upd norm tensor(2.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.2423, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8637, device='cuda:0')
upd norm tensor(3.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1981 Lithuanian Badminton Championships ‚Äì women's singles follows] -> [ Loschge, Friedrich Heinrich]
Computing right vector (v)
Lookup index found: 17 | Sentence: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows Loschge, Friedrich | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.49 = 8.49 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.00022668617020826787
loss 6.503 = 6.296 + 0.207 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0019449219107627869
loss 5.135 = 5.135 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0066849044524133205
loss 3.276 = 2.881 + 0.395 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.056303467601537704
loss 1.624 = 1.617 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.20898878574371338
loss 0.604 = 0.601 + 0.003 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.568875253200531
loss 0.294 = 0.285 + 0.009 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.7627280950546265
loss 0.136 = 0.091 + 0.044 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9188784956932068
loss 0.136 = 0.057 + 0.078 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9482223391532898
loss 0.101 = 0.077 + 0.023 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9353789687156677
loss 0.105 = 0.097 + 0.008 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9234482049942017
loss 0.106 = 0.099 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9230228662490845
loss 0.097 = 0.083 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9329265356063843
loss 0.098 = 0.063 + 0.035 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9468004107475281
loss 0.101 = 0.058 + 0.042 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9499897360801697
loss 0.094 = 0.073 + 0.02 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.939834475517273
loss 0.097 = 0.086 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9318189024925232
loss 0.096 = 0.085 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9324424266815186
loss 0.093 = 0.073 + 0.019 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9400944709777832
loss 0.095 = 0.062 + 0.032 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9475826621055603
loss 0.094 = 0.064 + 0.03 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9465584754943848
loss 0.092 = 0.074 + 0.018 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9399330019950867
loss 0.094 = 0.08 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9359598159790039
loss 0.093 = 0.077 + 0.015 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9377471804618835
loss 0.092 = 0.069 + 0.022 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9431607127189636
Init norm 14.525349617004395 | Delta norm 58.10139846801758 | Target norm 59.97038650512695


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(58.1014, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5071, device='cuda:0')
upd norm tensor(2.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5289, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5397, device='cuda:0')
upd norm tensor(2.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(49.7651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8816, device='cuda:0')
upd norm tensor(2.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(42.7677, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1878, device='cuda:0')
upd norm tensor(3.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(33.3730, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.9184, device='cuda:0')
upd norm tensor(4.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Anna Sophie Gasteiger is] -> [ mƒÅh≈´]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Anna Sophie Gasteiger is mƒÅh | Token: iger
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.405 = 7.405 + 0.0 + 0.0 avg prob of [ mƒÅh≈´] 0.0006433886010199785
loss 4.965 = 4.676 + 0.289 + 0.0 avg prob of [ mƒÅh≈´] 0.00943743996322155
loss 3.815 = 3.524 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.030633440241217613
loss 2.935 = 2.651 + 0.284 + 0.0 avg prob of [ mƒÅh≈´] 0.07068447023630142
loss 2.146 = 1.867 + 0.278 + 0.0 avg prob of [ mƒÅh≈´] 0.1552438586950302
loss 1.009 = 0.732 + 0.276 + 0.0 avg prob of [ mƒÅh≈´] 0.48104676604270935
loss 0.567 = 0.275 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.7600362300872803
loss 0.399 = 0.107 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.8993332386016846
loss 0.346 = 0.055 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.9462100863456726
loss 0.333 = 0.043 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.9579676389694214
loss 0.31 = 0.022 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9777737855911255
loss 0.276 = 0.025 + 0.25 + 0.0 avg prob of [ mƒÅh≈´] 0.9750882983207703
loss 0.759 = 0.63 + 0.128 + 0.0 avg prob of [ mƒÅh≈´] 0.5337220430374146
loss 0.274 = 0.041 + 0.232 + 0.0 avg prob of [ mƒÅh≈´] 0.9595615267753601
loss 0.299 = 0.023 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.977741003036499
loss 0.313 = 0.028 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9727442264556885
loss 0.306 = 0.018 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9822020530700684
loss 0.299 = 0.011 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9888372421264648
loss 0.296 = 0.008 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9917187094688416
loss 0.294 = 0.007 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9931774139404297
loss 0.292 = 0.006 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9939765334129333
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ mƒÅh≈´] 0.9942785501480103
loss 0.283 = 0.006 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.9938420057296753
loss 0.274 = 0.009 + 0.265 + 0.0 avg prob of [ mƒÅh≈´] 0.9915284514427185
loss 0.259 = 0.017 + 0.242 + 0.0 avg prob of [ mƒÅh≈´] 0.9831792712211609
Init norm 12.60416030883789 | Delta norm 50.41664123535156 | Target norm 52.078067779541016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.4166, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5367, device='cuda:0')
upd norm tensor(2.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7990, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5681, device='cuda:0')
upd norm tensor(2.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.2389, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9104, device='cuda:0')
upd norm tensor(2.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.3852, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2290, device='cuda:0')
upd norm tensor(2.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0085, device='cuda:0')
upd norm tensor(3.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jae-Duk Han is] -> [ bigender]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Jae-Duk Han is big | Token: Han
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.68 = 8.68 + 0.0 + 0.0 avg prob of [ bigender] 0.00020638955174945295
loss 5.637 = 5.468 + 0.168 + 0.0 avg prob of [ bigender] 0.004985661245882511
loss 3.601 = 3.265 + 0.335 + 0.0 avg prob of [ bigender] 0.03895954787731171
loss 1.156 = 0.82 + 0.336 + 0.0 avg prob of [ bigender] 0.44149231910705566
loss 0.783 = 0.446 + 0.336 + 0.0 avg prob of [ bigender] 0.6658896803855896
loss 0.361 = 0.021 + 0.34 + 0.0 avg prob of [ bigender] 0.979139506816864
loss 0.455 = 0.119 + 0.336 + 0.0 avg prob of [ bigender] 0.8885301351547241
loss 0.361 = 0.025 + 0.336 + 0.0 avg prob of [ bigender] 0.9757952690124512
loss 0.34 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9957816004753113
loss 0.339 = 0.004 + 0.335 + 0.0 avg prob of [ bigender] 0.996435821056366
loss 0.338 = 0.004 + 0.334 + 0.0 avg prob of [ bigender] 0.9957695007324219
loss 0.337 = 0.004 + 0.333 + 0.0 avg prob of [ bigender] 0.9957097768783569
loss 0.335 = 0.004 + 0.331 + 0.0 avg prob of [ bigender] 0.996068000793457
loss 0.331 = 0.004 + 0.327 + 0.0 avg prob of [ bigender] 0.9960777163505554
loss 0.303 = 0.007 + 0.296 + 0.0 avg prob of [ bigender] 0.9933030605316162
loss 0.606 = 0.383 + 0.223 + 0.0 avg prob of [ bigender] 0.7007762789726257
loss 0.337 = 0.001 + 0.336 + 0.0 avg prob of [ bigender] 0.9991363286972046
loss 0.345 = 0.008 + 0.336 + 0.0 avg prob of [ bigender] 0.9918235540390015
loss 0.374 = 0.038 + 0.336 + 0.0 avg prob of [ bigender] 0.9630802869796753
loss 0.388 = 0.051 + 0.336 + 0.0 avg prob of [ bigender] 0.9502453804016113
loss 0.361 = 0.024 + 0.336 + 0.0 avg prob of [ bigender] 0.9763194918632507
loss 0.346 = 0.009 + 0.336 + 0.0 avg prob of [ bigender] 0.9907026290893555
loss 0.342 = 0.005 + 0.336 + 0.0 avg prob of [ bigender] 0.9948294162750244
loss 0.341 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9960918426513672
loss 0.34 = 0.003 + 0.336 + 0.0 avg prob of [ bigender] 0.9966716766357422
Init norm 10.899991035461426 | Delta norm 43.5999641418457 | Target norm 45.193443298339844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.6000, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5658, device='cuda:0')
upd norm tensor(2.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.8688, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5918, device='cuda:0')
upd norm tensor(2.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.7623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9320, device='cuda:0')
upd norm tensor(2.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.9333, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2587, device='cuda:0')
upd norm tensor(2.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.4764, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0673, device='cuda:0')
upd norm tensor(3.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of death of Ray Wietecha is] -> [ Sta√üfurt]
Computing right vector (v)
Lookup index found: 10 | Sentence: The place of death of Ray Wietecha is Sta√ü | Token: a
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.11 = 8.11 + 0.0 + 0.0 avg prob of [ Sta√üfurt] 0.00032989942701533437
loss 6.402 = 6.284 + 0.118 + 0.0 avg prob of [ Sta√üfurt] 0.0019462056225165725
loss 5.162 = 4.853 + 0.309 + 0.0 avg prob of [ Sta√üfurt] 0.008369509130716324
loss 3.768 = 3.456 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.03495211526751518
loss 1.646 = 1.333 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.27931803464889526
loss 0.441 = 0.125 + 0.316 + 0.0 avg prob of [ Sta√üfurt] 0.8839200735092163
loss 0.354 = 0.041 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9601842761039734
loss 0.327 = 0.014 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.986103892326355
loss 0.32 = 0.006 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9937331080436707
loss 0.317 = 0.004 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9962098002433777
loss 0.316 = 0.003 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9972167015075684
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.997802197933197
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9982465505599976
loss 0.315 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9985891580581665
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9988359808921814
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9990048408508301
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.999117374420166
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9991900324821472
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9992321729660034
loss 0.314 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.9992437362670898
loss 0.313 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.999208927154541
loss 0.312 = 0.001 + 0.311 + 0.0 avg prob of [ Sta√üfurt] 0.9990455508232117
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9979442358016968
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9976019859313965
loss 0.314 = 0.0 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9995888471603394
Init norm 10.969701766967773 | Delta norm 43.878807067871094 | Target norm 45.10775375366211


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.8788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5856, device='cuda:0')
upd norm tensor(2.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.3918, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6083, device='cuda:0')
upd norm tensor(2.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.3447, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9485, device='cuda:0')
upd norm tensor(2.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(31.6848, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2807, device='cuda:0')
upd norm tensor(2.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.0379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1120, device='cuda:0')
upd norm tensor(3.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is] -> [ Russian State]
Computing right vector (v)
Lookup index found: 30 | Sentence: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is Russian | Token: doubles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.626 = 9.626 + 0.0 + 0.0 avg prob of [ Russian State] 0.0001487217377871275
loss 7.566 = 6.693 + 0.873 + 0.0 avg prob of [ Russian State] 0.0013882662169635296
loss 2.976 = 2.613 + 0.363 + 0.0 avg prob of [ Russian State] 0.07479877024888992
loss 2.423 = 2.421 + 0.002 + 0.0 avg prob of [ Russian State] 0.0907687395811081
loss 1.257 = 1.251 + 0.005 + 0.0 avg prob of [ Russian State] 0.28735417127609253
loss 0.474 = 0.429 + 0.046 + 0.0 avg prob of [ Russian State] 0.6543459296226501
loss 0.14 = 0.116 + 0.024 + 0.0 avg prob of [ Russian State] 0.8908494710922241
loss 0.068 = 0.042 + 0.025 + 0.0 avg prob of [ Russian State] 0.9586191177368164
loss 0.054 = 0.023 + 0.031 + 0.0 avg prob of [ Russian State] 0.9769591093063354
loss 0.053 = 0.019 + 0.034 + 0.0 avg prob of [ Russian State] 0.981724202632904
loss 0.048 = 0.015 + 0.033 + 0.0 avg prob of [ Russian State] 0.9849858283996582
Init norm 33.36102294921875 | Delta norm 127.69489288330078 | Target norm 134.28440856933594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(127.6949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.6075, device='cuda:0')
upd norm tensor(5.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(120.0359, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6264, device='cuda:0')
upd norm tensor(6.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(106.8882, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9650, device='cuda:0')
upd norm tensor(6.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(89.1822, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.3029, device='cuda:0')
upd norm tensor(6.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(67.0065, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1598, device='cuda:0')
upd norm tensor(9.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 81st Missouri General Assembly is associated with is] -> [ Ostikanate of Arminiya]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which 81st Missouri General Assembly is associated with is Ostikanate of Armini | Token: Assembly
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.707 = 7.707 + 0.0 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.00048599415458738804
loss 7.336 = 6.999 + 0.337 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0009601075435057282
loss 6.435 = 6.266 + 0.169 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0019966831896454096
loss 5.049 = 4.923 + 0.125 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.007588856853544712
loss 3.134 = 3.06 + 0.074 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.047306403517723083
loss 1.545 = 1.467 + 0.077 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.23186489939689636
loss 0.403 = 0.304 + 0.099 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.7414726614952087
loss 0.138 = 0.059 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9431867003440857
loss 0.11 = 0.03 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9708948135375977
loss 0.089 = 0.008 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9915426969528198
loss 0.084 = 0.004 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9959759712219238
loss 0.083 = 0.003 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9974373579025269
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9981023669242859
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9984511733055115
loss 0.081 = 0.001 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.998671293258667
loss 0.081 = 0.001 + 0.079 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9988362193107605
loss 0.079 = 0.001 + 0.078 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9989756345748901
loss 0.037 = 0.001 + 0.035 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9991167783737183
Init norm 12.339568138122559 | Delta norm 49.3582763671875 | Target norm 50.52494812011719


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3583, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7519, device='cuda:0')
upd norm tensor(2.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.2671, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.7815, device='cuda:0')
upd norm tensor(2.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.0074, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1257, device='cuda:0')
upd norm tensor(2.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.5179, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.4959, device='cuda:0')
upd norm tensor(2.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.5396, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5267, device='cuda:0')
upd norm tensor(3.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.23131884057971014}, 'post': {'rewrite_acc': 0.9445652173913044}}
2024-10-29 23:02:39,412 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 23:02:39 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.58s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.27s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.62s/it]
2024-10-29 23:02:47,186 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 23:02:47 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/30 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  3%|‚ñé         | 1/30 [00:00<00:15,  1.89it/s] 10%|‚ñà         | 3/30 [00:00<00:05,  5.35it/s] 17%|‚ñà‚ñã        | 5/30 [00:00<00:03,  8.15it/s] 23%|‚ñà‚ñà‚ñé       | 7/30 [00:00<00:02, 10.21it/s] 30%|‚ñà‚ñà‚ñà       | 9/30 [00:01<00:01, 11.85it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 11/30 [00:01<00:01, 12.94it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 13/30 [00:01<00:01, 13.86it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 15/30 [00:01<00:01, 13.32it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 17/30 [00:01<00:00, 13.81it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 19/30 [00:01<00:00, 14.43it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 21/30 [00:01<00:00, 14.73it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 23/30 [00:01<00:00, 15.13it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 25/30 [00:02<00:00, 14.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 27/30 [00:02<00:00, 14.75it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 29/30 [00:02<00:00, 14.99it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:02<00:00, 12.27it/s]
  0%|          | 0/30 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
  3%|‚ñé         | 1/30 [00:17<08:20, 17.27s/it]  7%|‚ñã         | 2/30 [00:31<07:12, 15.46s/it] 10%|‚ñà         | 3/30 [00:37<05:06, 11.36s/it] 13%|‚ñà‚ñé        | 4/30 [00:49<04:54, 11.34s/it] 17%|‚ñà‚ñã        | 5/30 [01:00<04:43, 11.33s/it] 20%|‚ñà‚ñà        | 6/30 [01:11<04:31, 11.30s/it] 23%|‚ñà‚ñà‚ñé       | 7/30 [01:24<04:28, 11.69s/it] 27%|‚ñà‚ñà‚ñã       | 8/30 [01:36<04:19, 11.81s/it] 30%|‚ñà‚ñà‚ñà       | 9/30 [01:47<04:04, 11.62s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 10/30 [01:58<03:50, 11.51s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 11/30 [02:11<03:44, 11.80s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 12/30 [02:22<03:29, 11.62s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 13/30 [02:33<03:14, 11.43s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 14/30 [02:45<03:05, 11.57s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 15/30 [02:59<03:06, 12.44s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 16/30 [03:08<02:38, 11.31s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 17/30 [03:22<02:37, 12.14s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 18/30 [03:34<02:25, 12.17s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 19/30 [03:47<02:13, 12.18s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 20/30 [04:01<02:09, 12.92s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 21/30 [04:13<01:54, 12.67s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 22/30 [04:24<01:37, 12.24s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 23/30 [04:37<01:25, 12.28s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 24/30 [04:48<01:11, 11.85s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 25/30 [04:59<00:58, 11.79s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 26/30 [05:10<00:46, 11.55s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 27/30 [05:22<00:34, 11.43s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 28/30 [05:34<00:23, 11.69s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 29/30 [05:45<00:11, 11.53s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [05:51<00:00,  9.92s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [05:51<00:00, 11.72s/it]
2024-10-29 23:08:45,202 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,272 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,334 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,396 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,458 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,520 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,586 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,648 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,710 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,772 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,838 - easyeditor.editors.editor - INFO - 10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,900 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:45,962 - easyeditor.editors.editor - INFO - 12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:45 - INFO - easyeditor.editors.editor -   12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,058 - easyeditor.editors.editor - INFO - 13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.782608695652174], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.782608695652174], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,124 - easyeditor.editors.editor - INFO - 14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,191 - easyeditor.editors.editor - INFO - 15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,257 - easyeditor.editors.editor - INFO - 16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,319 - easyeditor.editors.editor - INFO - 17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,382 - easyeditor.editors.editor - INFO - 18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,449 - easyeditor.editors.editor - INFO - 19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,511 - easyeditor.editors.editor - INFO - 20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,573 - easyeditor.editors.editor - INFO - 21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,635 - easyeditor.editors.editor - INFO - 22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,728 - easyeditor.editors.editor - INFO - 23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,795 - easyeditor.editors.editor - INFO - 24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,857 - easyeditor.editors.editor - INFO - 25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,918 - easyeditor.editors.editor - INFO - 26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:46,985 - easyeditor.editors.editor - INFO - 27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:46 - INFO - easyeditor.editors.editor -   27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:47,046 - easyeditor.editors.editor - INFO - 28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:47 - INFO - easyeditor.editors.editor -   28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:08:47,113 - easyeditor.editors.editor - INFO - 29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
10/29/2024 23:08:47 - INFO - easyeditor.editors.editor -   29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the mother of Stephana Warnock is] -> [ Sheila Mary Nolan]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the mother of Stephana Warnock is Sheila Mary N | Token: ck
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.607 = 5.607 + 0.0 + 0.0 avg prob of [ Sheila Mary Nolan] 0.0038164069410413504
loss 4.121 = 4.041 + 0.081 + 0.0 avg prob of [ Sheila Mary Nolan] 0.017668189480900764
loss 2.539 = 2.278 + 0.261 + 0.0 avg prob of [ Sheila Mary Nolan] 0.10279671847820282
loss 1.638 = 1.375 + 0.263 + 0.0 avg prob of [ Sheila Mary Nolan] 0.2534908056259155
loss 0.589 = 0.32 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.7290753126144409
loss 0.278 = 0.008 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9921392202377319
loss 0.277 = 0.006 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9939529895782471
loss 0.274 = 0.003 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9970394968986511
loss 0.273 = 0.003 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9972531199455261
loss 0.261 = 0.002 + 0.259 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9978387355804443
loss 1.313 = 1.07 + 0.243 + 0.0 avg prob of [ Sheila Mary Nolan] 0.34820589423179626
loss 0.277 = 0.005 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9946407079696655
loss 0.32 = 0.049 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9526904821395874
loss 0.282 = 0.011 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9890134334564209
loss 0.29 = 0.02 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.979956328868866
loss 0.308 = 0.038 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9627887606620789
loss 0.31 = 0.041 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9601114988327026
loss 0.289 = 0.02 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9798704385757446
loss 0.279 = 0.011 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9891979098320007
loss 0.276 = 0.008 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9919161796569824
loss 0.274 = 0.007 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9928478598594666
loss 0.273 = 0.007 + 0.266 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9933524131774902
loss 0.272 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.993818998336792
loss 0.271 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9943550825119019
loss 0.269 = 0.005 + 0.264 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9949434995651245
Init norm 10.451786041259766 | Delta norm 41.80714416503906 | Target norm 43.345272064208984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(41.8071, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2871, device='cuda:0')
upd norm tensor(2.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.4182, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3533, device='cuda:0')
upd norm tensor(2.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.4749, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6933, device='cuda:0')
upd norm tensor(2.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9427, device='cuda:0')
upd norm tensor(2.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.3619, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4336, device='cuda:0')
upd norm tensor(3.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Darren Finlay is] -> [ spaceship captain]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Darren Finlay is spaceship | Token: lay
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ spaceship captain] 0.0031509259715676308
loss 3.808 = 3.734 + 0.073 + 0.0 avg prob of [ spaceship captain] 0.02488766238093376
loss 2.243 = 1.958 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.14252355694770813
loss 0.729 = 0.443 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.6496155261993408
loss 0.309 = 0.02 + 0.289 + 0.0 avg prob of [ spaceship captain] 0.9803946018218994
loss 0.299 = 0.013 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9871116876602173
loss 0.291 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9952278137207031
loss 0.292 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9947180151939392
loss 0.29 = 0.003 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9966393709182739
loss 0.288 = 0.002 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9984142780303955
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9989546537399292
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9991535544395447
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999259889125824
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993330836296082
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993906021118164
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994384050369263
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994781017303467
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999510645866394
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995357394218445
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995522499084473
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995567798614502
loss 0.286 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999541699886322
loss 0.286 = 0.001 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.999482274055481
loss 0.284 = 0.001 + 0.283 + 0.0 avg prob of [ spaceship captain] 0.9992715120315552
loss 0.269 = 0.002 + 0.266 + 0.0 avg prob of [ spaceship captain] 0.9978246688842773
Init norm 11.212502479553223 | Delta norm 44.85000991821289 | Target norm 46.32301712036133


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8500, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3073, device='cuda:0')
upd norm tensor(2.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3681, device='cuda:0')
upd norm tensor(2.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.9594, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7088, device='cuda:0')
upd norm tensor(2.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4587, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9623, device='cuda:0')
upd norm tensor(2.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2282, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4749, device='cuda:0')
upd norm tensor(3.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Henry John Gepp is] -> [ bigender]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Henry John Gepp is big | Token: pp
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.613 = 8.613 + 0.0 + 0.0 avg prob of [ bigender] 0.00024923926685005426
loss 5.668 = 5.409 + 0.259 + 0.0 avg prob of [ bigender] 0.00471782311797142
loss 3.402 = 3.116 + 0.286 + 0.0 avg prob of [ bigender] 0.044810354709625244
loss 1.863 = 1.576 + 0.286 + 0.0 avg prob of [ bigender] 0.2090466022491455
loss 2.594 = 2.308 + 0.286 + 0.0 avg prob of [ bigender] 0.10035304725170135
loss 0.382 = 0.096 + 0.285 + 0.0 avg prob of [ bigender] 0.9083206057548523
loss 0.411 = 0.131 + 0.28 + 0.0 avg prob of [ bigender] 0.8777483701705933
loss 0.333 = 0.056 + 0.277 + 0.0 avg prob of [ bigender] 0.945836067199707
loss 0.298 = 0.018 + 0.28 + 0.0 avg prob of [ bigender] 0.9822215437889099
loss 0.291 = 0.008 + 0.283 + 0.0 avg prob of [ bigender] 0.9919554591178894
loss 0.289 = 0.005 + 0.284 + 0.0 avg prob of [ bigender] 0.9952031970024109
loss 0.288 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9965540766716003
loss 0.287 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9971374273300171
loss 0.284 = 0.003 + 0.281 + 0.0 avg prob of [ bigender] 0.9971071481704712
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ bigender] 0.9940347075462341
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9985091686248779
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9986342191696167
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998675525188446
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987055659294128
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998738169670105
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987771511077881
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988228678703308
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988745450973511
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989303350448608
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989882707595825
Init norm 11.56171703338623 | Delta norm 46.246864318847656 | Target norm 47.51656723022461


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.2469, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3295, device='cuda:0')
upd norm tensor(2.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.7641, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3870, device='cuda:0')
upd norm tensor(2.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.4596, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7276, device='cuda:0')
upd norm tensor(2.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4244, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9855, device='cuda:0')
upd norm tensor(2.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9834, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5289, device='cuda:0')
upd norm tensor(3.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by] -> [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles]
Computing right vector (v)
Lookup index found: 19 | Sentence: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by 1995/1996 German Badminton Championships U14 ‚Äì women's | Token: kg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.353 = 3.353 + 0.0 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.03520524501800537
loss 3.407 = 3.103 + 0.304 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.0450158566236496
loss 2.889 = 2.77 + 0.119 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.06274893879890442
loss 2.398 = 2.381 + 0.016 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.09277491271495819
loss 1.887 = 1.87 + 0.017 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.1548815369606018
loss 1.276 = 1.257 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.2849786877632141
loss 0.861 = 0.84 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.43282267451286316
loss 0.572 = 0.552 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.5766874551773071
loss 0.279 = 0.259 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.7725369334220886
loss 0.118 = 0.095 + 0.022 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9097639322280884
loss 0.068 = 0.042 + 0.026 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.959246039390564
loss 0.038 = 0.015 + 0.023 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9852155447006226
Init norm 13.64920425415039 | Delta norm 54.59681701660156 | Target norm 56.80078887939453


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(54.5968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3534, device='cuda:0')
upd norm tensor(2.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(52.0168, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4067, device='cuda:0')
upd norm tensor(2.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.4490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7474, device='cuda:0')
upd norm tensor(2.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.9326, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0112, device='cuda:0')
upd norm tensor(2.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.0892, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5791, device='cuda:0')
upd norm tensor(4.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the capital city of canton of Bagn√®res-de-Bigorre is] -> [ Knarvik]
Computing right vector (v)
Lookup index found: 18 | Sentence: The name of the capital city of canton of Bagn√®res-de-Bigorre is Knar | Token: re
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.458 = 8.458 + 0.0 + 0.0 avg prob of [ Knarvik] 0.00024466344621032476
loss 5.052 = 4.66 + 0.392 + 0.0 avg prob of [ Knarvik] 0.009621738456189632
loss 4.534 = 4.159 + 0.375 + 0.0 avg prob of [ Knarvik] 0.017060158774256706
loss 1.635 = 1.228 + 0.407 + 0.0 avg prob of [ Knarvik] 0.29709187150001526
loss 0.486 = 0.079 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9242154955863953
loss 0.42 = 0.013 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9867501258850098
loss 0.418 = 0.011 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9892411231994629
loss 0.42 = 0.013 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9866708517074585
loss 0.422 = 0.015 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9847845435142517
loss 0.418 = 0.012 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9878983497619629
loss 0.414 = 0.008 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9916070699691772
loss 0.412 = 0.006 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9935588836669922
loss 0.41 = 0.006 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9943916201591492
loss 0.41 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9947823882102966
loss 0.409 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9950642585754395
loss 0.408 = 0.005 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9953522086143494
loss 0.408 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9956467151641846
loss 0.407 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9959076642990112
loss 0.406 = 0.004 + 0.402 + 0.0 avg prob of [ Knarvik] 0.9960910677909851
loss 0.406 = 0.004 + 0.401 + 0.0 avg prob of [ Knarvik] 0.9961570501327515
loss 0.405 = 0.004 + 0.4 + 0.0 avg prob of [ Knarvik] 0.9960526823997498
loss 0.403 = 0.004 + 0.398 + 0.0 avg prob of [ Knarvik] 0.9956769943237305
loss 0.4 = 0.005 + 0.395 + 0.0 avg prob of [ Knarvik] 0.9947869181632996
loss 0.395 = 0.007 + 0.387 + 0.0 avg prob of [ Knarvik] 0.9926511645317078
loss 0.381 = 0.014 + 0.367 + 0.0 avg prob of [ Knarvik] 0.9862655997276306
Init norm 13.75742244720459 | Delta norm 55.02968978881836 | Target norm 57.197044372558594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.0297, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3776, device='cuda:0')
upd norm tensor(2.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.2903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4289, device='cuda:0')
upd norm tensor(2.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.2762, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7725, device='cuda:0')
upd norm tensor(2.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.0288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0435, device='cuda:0')
upd norm tensor(3.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.4549, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6389, device='cuda:0')
upd norm tensor(4.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Nicol√°s M√©ndez Casariego is] -> [ Tharangambadi]
Computing right vector (v)
Lookup index found: 13 | Sentence: The place of birth of Nicol√°s M√©ndez Casariego is Tharangamb | Token: iego
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.212 = 5.212 + 0.0 + 0.0 avg prob of [ Tharangambadi] 0.005583751946687698
loss 2.071 = 1.94 + 0.131 + 0.0 avg prob of [ Tharangambadi] 0.1442318558692932
loss 2.016 = 1.969 + 0.047 + 0.0 avg prob of [ Tharangambadi] 0.14092321693897247
loss 0.977 = 0.745 + 0.232 + 0.0 avg prob of [ Tharangambadi] 0.47648951411247253
loss 0.247 = 0.137 + 0.109 + 0.0 avg prob of [ Tharangambadi] 0.8725411295890808
loss 0.073 = 0.022 + 0.051 + 0.0 avg prob of [ Tharangambadi] 0.978609025478363
loss 0.073 = 0.014 + 0.059 + 0.0 avg prob of [ Tharangambadi] 0.9862703680992126
loss 0.057 = 0.009 + 0.048 + 0.0 avg prob of [ Tharangambadi] 0.9914528727531433
loss 0.057 = 0.006 + 0.05 + 0.0 avg prob of [ Tharangambadi] 0.9935469031333923
loss 0.051 = 0.006 + 0.045 + 0.0 avg prob of [ Tharangambadi] 0.9944161772727966
loss 0.051 = 0.005 + 0.046 + 0.0 avg prob of [ Tharangambadi] 0.9949017763137817
loss 0.049 = 0.005 + 0.044 + 0.0 avg prob of [ Tharangambadi] 0.99549400806427
Init norm 11.820267677307129 | Delta norm 47.281070709228516 | Target norm 49.48406982421875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4101, device='cuda:0')
upd norm tensor(2.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.0030, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4570, device='cuda:0')
upd norm tensor(2.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9796, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7993, device='cuda:0')
upd norm tensor(2.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7175, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0801, device='cuda:0')
upd norm tensor(2.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.7751, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6996, device='cuda:0')
upd norm tensor(3.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Thomas Phillipps Lamb is] -> [ deputy high court judge]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Thomas Phillipps Lamb is deputy high court | Token: Lamb
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.536 = 4.536 + 0.0 + 0.0 avg prob of [ deputy high court judge] 0.011187071911990643
loss 2.153 = 1.905 + 0.248 + 0.0 avg prob of [ deputy high court judge] 0.1506791114807129
loss 2.517 = 2.2 + 0.316 + 0.0 avg prob of [ deputy high court judge] 0.11348851025104523
loss 1.484 = 1.217 + 0.267 + 0.0 avg prob of [ deputy high court judge] 0.2975485026836395
loss 0.316 = 0.056 + 0.259 + 0.0 avg prob of [ deputy high court judge] 0.9452149868011475
loss 0.219 = 0.161 + 0.057 + 0.0 avg prob of [ deputy high court judge] 0.8546231985092163
loss 0.287 = 0.013 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9872293472290039
loss 0.28 = 0.005 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9951062202453613
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.996562659740448
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9971231818199158
loss 0.277 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9974326491355896
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9976330995559692
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9977788329124451
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.997896671295166
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9980010986328125
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981006979942322
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981997013092041
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9982994794845581
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9983994364738464
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9984978437423706
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9985925555229187
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9986819624900818
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9987648725509644
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9988407492637634
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9989093542098999
Init norm 11.668208122253418 | Delta norm 46.67283248901367 | Target norm 47.940155029296875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4355, device='cuda:0')
upd norm tensor(2.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2678, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4781, device='cuda:0')
upd norm tensor(2.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9152, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8203, device='cuda:0')
upd norm tensor(2.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6206, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1043, device='cuda:0')
upd norm tensor(2.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5778, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(3.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Yoshida Keigo is] -> [ intersex organism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Yoshida Keigo is intersex organ | Token: igo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.154 = 6.154 + 0.0 + 0.0 avg prob of [ intersex organism] 0.002235337160527706
loss 4.674 = 4.436 + 0.238 + 0.0 avg prob of [ intersex organism] 0.012196492403745651
loss 2.694 = 2.457 + 0.237 + 0.0 avg prob of [ intersex organism] 0.08594139665365219
loss 1.409 = 1.173 + 0.236 + 0.0 avg prob of [ intersex organism] 0.3106464147567749
loss 0.299 = 0.066 + 0.233 + 0.0 avg prob of [ intersex organism] 0.9358271360397339
loss 0.278 = 0.039 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9619175791740417
loss 0.242 = 0.005 + 0.237 + 0.0 avg prob of [ intersex organism] 0.994818389415741
loss 0.24 = 0.002 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9979938268661499
loss 0.24 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.998679518699646
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9989312887191772
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990383982658386
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990581274032593
loss 0.238 = 0.001 + 0.237 + 0.0 avg prob of [ intersex organism] 0.9989722967147827
loss 0.236 = 0.001 + 0.234 + 0.0 avg prob of [ intersex organism] 0.9986181259155273
loss 0.22 = 0.004 + 0.217 + 0.0 avg prob of [ intersex organism] 0.9964985251426697
loss 0.338 = 0.201 + 0.137 + 0.0 avg prob of [ intersex organism] 0.8238176107406616
loss 0.24 = 0.001 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9993938207626343
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9979710578918457
loss 0.249 = 0.011 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9895128607749939
loss 0.268 = 0.03 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9707574248313904
loss 0.254 = 0.015 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9848440885543823
loss 0.245 = 0.007 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9933988451957703
loss 0.243 = 0.004 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9958910942077637
loss 0.242 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9967593550682068
loss 0.241 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.997196614742279
Init norm 12.686749458312988 | Delta norm 50.74699783325195 | Target norm 52.94290542602539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7470, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4567, device='cuda:0')
upd norm tensor(2.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7230, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4976, device='cuda:0')
upd norm tensor(2.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.6228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8382, device='cuda:0')
upd norm tensor(2.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9657, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1283, device='cuda:0')
upd norm tensor(2.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.4189, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8053, device='cuda:0')
upd norm tensor(3.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [2041 BC follows] -> [ 29668 Ipf]
Computing right vector (v)
Lookup index found: 6 | Sentence: 2041 BC follows 29668 I | Token: BC
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.78 = 6.78 + 0.0 + 0.0 avg prob of [ 29668 Ipf] 0.0011842688545584679
loss 5.645 = 5.42 + 0.225 + 0.0 avg prob of [ 29668 Ipf] 0.004440009593963623
loss 4.847 = 4.718 + 0.129 + 0.0 avg prob of [ 29668 Ipf] 0.00958884134888649
loss 3.992 = 3.855 + 0.137 + 0.0 avg prob of [ 29668 Ipf] 0.02176203392446041
loss 2.709 = 2.553 + 0.155 + 0.0 avg prob of [ 29668 Ipf] 0.08010239899158478
loss 1.658 = 1.493 + 0.164 + 0.0 avg prob of [ 29668 Ipf] 0.22878196835517883
loss 0.859 = 0.706 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.5008167624473572
loss 0.467 = 0.314 + 0.153 + 0.0 avg prob of [ 29668 Ipf] 0.7312717437744141
loss 0.305 = 0.153 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.8584901094436646
loss 0.217 = 0.059 + 0.157 + 0.0 avg prob of [ 29668 Ipf] 0.9424829483032227
loss 0.176 = 0.019 + 0.156 + 0.0 avg prob of [ 29668 Ipf] 0.9809708595275879
loss 0.168 = 0.009 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9908093810081482
loss 0.165 = 0.006 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9937031269073486
loss 0.163 = 0.004 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9961495399475098
loss 0.162 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9975597858428955
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9981834292411804
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9985010027885437
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9986904859542847
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9988631010055542
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9990620613098145
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9992455244064331
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9993878602981567
loss 0.159 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9994925856590271
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9995701313018799
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.999629020690918
Init norm 12.345292091369629 | Delta norm 49.38117218017578 | Target norm 51.165740966796875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3812, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4836, device='cuda:0')
upd norm tensor(2.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.5944, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5201, device='cuda:0')
upd norm tensor(2.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.3130, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8602, device='cuda:0')
upd norm tensor(2.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.6083, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1596, device='cuda:0')
upd norm tensor(2.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.2423, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8637, device='cuda:0')
upd norm tensor(3.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1981 Lithuanian Badminton Championships ‚Äì women's singles follows] -> [ Loschge, Friedrich Heinrich]
Computing right vector (v)
Lookup index found: 17 | Sentence: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows Loschge, Friedrich | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.49 = 8.49 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.00022668617020826787
loss 6.503 = 6.296 + 0.207 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0019449219107627869
loss 5.135 = 5.135 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0066849044524133205
loss 3.276 = 2.881 + 0.395 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.056303467601537704
loss 1.624 = 1.617 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.20898878574371338
loss 0.604 = 0.601 + 0.003 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.568875253200531
loss 0.294 = 0.285 + 0.009 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.7627280950546265
loss 0.136 = 0.091 + 0.044 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9188784956932068
loss 0.136 = 0.057 + 0.078 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9482223391532898
loss 0.101 = 0.077 + 0.023 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9353789687156677
loss 0.105 = 0.097 + 0.008 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9234482049942017
loss 0.106 = 0.099 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9230228662490845
loss 0.097 = 0.083 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9329265356063843
loss 0.098 = 0.063 + 0.035 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9468004107475281
loss 0.101 = 0.058 + 0.042 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9499897360801697
loss 0.094 = 0.073 + 0.02 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.939834475517273
loss 0.097 = 0.086 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9318189024925232
loss 0.096 = 0.085 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9324424266815186
loss 0.093 = 0.073 + 0.019 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9400944709777832
loss 0.095 = 0.062 + 0.032 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9475826621055603
loss 0.094 = 0.064 + 0.03 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9465584754943848
loss 0.092 = 0.074 + 0.018 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9399330019950867
loss 0.094 = 0.08 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9359598159790039
loss 0.093 = 0.077 + 0.015 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9377471804618835
loss 0.092 = 0.069 + 0.022 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9431607127189636
Init norm 14.525349617004395 | Delta norm 58.10139846801758 | Target norm 59.97038650512695


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(58.1014, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5071, device='cuda:0')
upd norm tensor(2.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5289, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5397, device='cuda:0')
upd norm tensor(2.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(49.7651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8816, device='cuda:0')
upd norm tensor(2.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(42.7677, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1878, device='cuda:0')
upd norm tensor(3.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(33.3730, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.9184, device='cuda:0')
upd norm tensor(4.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Anna Sophie Gasteiger is] -> [ mƒÅh≈´]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Anna Sophie Gasteiger is mƒÅh | Token: iger
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.405 = 7.405 + 0.0 + 0.0 avg prob of [ mƒÅh≈´] 0.0006433886010199785
loss 4.965 = 4.676 + 0.289 + 0.0 avg prob of [ mƒÅh≈´] 0.00943743996322155
loss 3.815 = 3.524 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.030633440241217613
loss 2.935 = 2.651 + 0.284 + 0.0 avg prob of [ mƒÅh≈´] 0.07068447023630142
loss 2.146 = 1.867 + 0.278 + 0.0 avg prob of [ mƒÅh≈´] 0.1552438586950302
loss 1.009 = 0.732 + 0.276 + 0.0 avg prob of [ mƒÅh≈´] 0.48104676604270935
loss 0.567 = 0.275 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.7600362300872803
loss 0.399 = 0.107 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.8993332386016846
loss 0.346 = 0.055 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.9462100863456726
loss 0.333 = 0.043 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.9579676389694214
loss 0.31 = 0.022 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9777737855911255
loss 0.276 = 0.025 + 0.25 + 0.0 avg prob of [ mƒÅh≈´] 0.9750882983207703
loss 0.759 = 0.63 + 0.128 + 0.0 avg prob of [ mƒÅh≈´] 0.5337220430374146
loss 0.274 = 0.041 + 0.232 + 0.0 avg prob of [ mƒÅh≈´] 0.9595615267753601
loss 0.299 = 0.023 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.977741003036499
loss 0.313 = 0.028 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9727442264556885
loss 0.306 = 0.018 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9822020530700684
loss 0.299 = 0.011 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9888372421264648
loss 0.296 = 0.008 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9917187094688416
loss 0.294 = 0.007 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9931774139404297
loss 0.292 = 0.006 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9939765334129333
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ mƒÅh≈´] 0.9942785501480103
loss 0.283 = 0.006 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.9938420057296753
loss 0.274 = 0.009 + 0.265 + 0.0 avg prob of [ mƒÅh≈´] 0.9915284514427185
loss 0.259 = 0.017 + 0.242 + 0.0 avg prob of [ mƒÅh≈´] 0.9831792712211609
Init norm 12.60416030883789 | Delta norm 50.41664123535156 | Target norm 52.078067779541016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.4166, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5367, device='cuda:0')
upd norm tensor(2.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7990, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5681, device='cuda:0')
upd norm tensor(2.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.2389, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9104, device='cuda:0')
upd norm tensor(2.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.3852, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2290, device='cuda:0')
upd norm tensor(2.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0085, device='cuda:0')
upd norm tensor(3.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jae-Duk Han is] -> [ bigender]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Jae-Duk Han is big | Token: Han
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.68 = 8.68 + 0.0 + 0.0 avg prob of [ bigender] 0.00020638955174945295
loss 5.637 = 5.468 + 0.168 + 0.0 avg prob of [ bigender] 0.004985661245882511
loss 3.601 = 3.265 + 0.335 + 0.0 avg prob of [ bigender] 0.03895954787731171
loss 1.156 = 0.82 + 0.336 + 0.0 avg prob of [ bigender] 0.44149231910705566
loss 0.783 = 0.446 + 0.336 + 0.0 avg prob of [ bigender] 0.6658896803855896
loss 0.361 = 0.021 + 0.34 + 0.0 avg prob of [ bigender] 0.979139506816864
loss 0.455 = 0.119 + 0.336 + 0.0 avg prob of [ bigender] 0.8885301351547241
loss 0.361 = 0.025 + 0.336 + 0.0 avg prob of [ bigender] 0.9757952690124512
loss 0.34 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9957816004753113
loss 0.339 = 0.004 + 0.335 + 0.0 avg prob of [ bigender] 0.996435821056366
loss 0.338 = 0.004 + 0.334 + 0.0 avg prob of [ bigender] 0.9957695007324219
loss 0.337 = 0.004 + 0.333 + 0.0 avg prob of [ bigender] 0.9957097768783569
loss 0.335 = 0.004 + 0.331 + 0.0 avg prob of [ bigender] 0.996068000793457
loss 0.331 = 0.004 + 0.327 + 0.0 avg prob of [ bigender] 0.9960777163505554
loss 0.303 = 0.007 + 0.296 + 0.0 avg prob of [ bigender] 0.9933030605316162
loss 0.606 = 0.383 + 0.223 + 0.0 avg prob of [ bigender] 0.7007762789726257
loss 0.337 = 0.001 + 0.336 + 0.0 avg prob of [ bigender] 0.9991363286972046
loss 0.345 = 0.008 + 0.336 + 0.0 avg prob of [ bigender] 0.9918235540390015
loss 0.374 = 0.038 + 0.336 + 0.0 avg prob of [ bigender] 0.9630802869796753
loss 0.388 = 0.051 + 0.336 + 0.0 avg prob of [ bigender] 0.9502453804016113
loss 0.361 = 0.024 + 0.336 + 0.0 avg prob of [ bigender] 0.9763194918632507
loss 0.346 = 0.009 + 0.336 + 0.0 avg prob of [ bigender] 0.9907026290893555
loss 0.342 = 0.005 + 0.336 + 0.0 avg prob of [ bigender] 0.9948294162750244
loss 0.341 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9960918426513672
loss 0.34 = 0.003 + 0.336 + 0.0 avg prob of [ bigender] 0.9966716766357422
Init norm 10.899991035461426 | Delta norm 43.5999641418457 | Target norm 45.193443298339844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.6000, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5658, device='cuda:0')
upd norm tensor(2.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.8688, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5918, device='cuda:0')
upd norm tensor(2.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.7623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9320, device='cuda:0')
upd norm tensor(2.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.9333, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2587, device='cuda:0')
upd norm tensor(2.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.4764, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0673, device='cuda:0')
upd norm tensor(3.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of death of Ray Wietecha is] -> [ Sta√üfurt]
Computing right vector (v)
Lookup index found: 10 | Sentence: The place of death of Ray Wietecha is Sta√ü | Token: a
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.11 = 8.11 + 0.0 + 0.0 avg prob of [ Sta√üfurt] 0.00032989942701533437
loss 6.402 = 6.284 + 0.118 + 0.0 avg prob of [ Sta√üfurt] 0.0019462056225165725
loss 5.162 = 4.853 + 0.309 + 0.0 avg prob of [ Sta√üfurt] 0.008369509130716324
loss 3.768 = 3.456 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.03495211526751518
loss 1.646 = 1.333 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.27931803464889526
loss 0.441 = 0.125 + 0.316 + 0.0 avg prob of [ Sta√üfurt] 0.8839200735092163
loss 0.354 = 0.041 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9601842761039734
loss 0.327 = 0.014 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.986103892326355
loss 0.32 = 0.006 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9937331080436707
loss 0.317 = 0.004 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9962098002433777
loss 0.316 = 0.003 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9972167015075684
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.997802197933197
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9982465505599976
loss 0.315 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9985891580581665
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9988359808921814
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9990048408508301
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.999117374420166
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9991900324821472
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9992321729660034
loss 0.314 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.9992437362670898
loss 0.313 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.999208927154541
loss 0.312 = 0.001 + 0.311 + 0.0 avg prob of [ Sta√üfurt] 0.9990455508232117
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9979442358016968
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9976019859313965
loss 0.314 = 0.0 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9995888471603394
Init norm 10.969701766967773 | Delta norm 43.878807067871094 | Target norm 45.10775375366211


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.8788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5856, device='cuda:0')
upd norm tensor(2.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.3918, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6083, device='cuda:0')
upd norm tensor(2.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.3447, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9485, device='cuda:0')
upd norm tensor(2.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(31.6848, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2807, device='cuda:0')
upd norm tensor(2.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.0379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1120, device='cuda:0')
upd norm tensor(3.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is] -> [ Russian State]
Computing right vector (v)
Lookup index found: 30 | Sentence: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is Russian | Token: doubles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.626 = 9.626 + 0.0 + 0.0 avg prob of [ Russian State] 0.0001487217377871275
loss 7.566 = 6.693 + 0.873 + 0.0 avg prob of [ Russian State] 0.0013882662169635296
loss 2.976 = 2.613 + 0.363 + 0.0 avg prob of [ Russian State] 0.07479877024888992
loss 2.423 = 2.421 + 0.002 + 0.0 avg prob of [ Russian State] 0.0907687395811081
loss 1.257 = 1.251 + 0.005 + 0.0 avg prob of [ Russian State] 0.28735417127609253
loss 0.474 = 0.429 + 0.046 + 0.0 avg prob of [ Russian State] 0.6543459296226501
loss 0.14 = 0.116 + 0.024 + 0.0 avg prob of [ Russian State] 0.8908494710922241
loss 0.068 = 0.042 + 0.025 + 0.0 avg prob of [ Russian State] 0.9586191177368164
loss 0.054 = 0.023 + 0.031 + 0.0 avg prob of [ Russian State] 0.9769591093063354
loss 0.053 = 0.019 + 0.034 + 0.0 avg prob of [ Russian State] 0.981724202632904
loss 0.048 = 0.015 + 0.033 + 0.0 avg prob of [ Russian State] 0.9849858283996582
Init norm 33.36102294921875 | Delta norm 127.69489288330078 | Target norm 134.28440856933594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(127.6949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.6075, device='cuda:0')
upd norm tensor(5.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(120.0359, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6264, device='cuda:0')
upd norm tensor(6.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(106.8882, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9650, device='cuda:0')
upd norm tensor(6.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(89.1822, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.3029, device='cuda:0')
upd norm tensor(6.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(67.0065, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1598, device='cuda:0')
upd norm tensor(9.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 81st Missouri General Assembly is associated with is] -> [ Ostikanate of Arminiya]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which 81st Missouri General Assembly is associated with is Ostikanate of Armini | Token: Assembly
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.707 = 7.707 + 0.0 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.00048599415458738804
loss 7.336 = 6.999 + 0.337 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0009601075435057282
loss 6.435 = 6.266 + 0.169 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0019966831896454096
loss 5.049 = 4.923 + 0.125 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.007588856853544712
loss 3.134 = 3.06 + 0.074 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.047306403517723083
loss 1.545 = 1.467 + 0.077 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.23186489939689636
loss 0.403 = 0.304 + 0.099 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.7414726614952087
loss 0.138 = 0.059 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9431867003440857
loss 0.11 = 0.03 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9708948135375977
loss 0.089 = 0.008 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9915426969528198
loss 0.084 = 0.004 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9959759712219238
loss 0.083 = 0.003 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9974373579025269
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9981023669242859
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9984511733055115
loss 0.081 = 0.001 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.998671293258667
loss 0.081 = 0.001 + 0.079 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9988362193107605
loss 0.079 = 0.001 + 0.078 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9989756345748901
loss 0.037 = 0.001 + 0.035 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9991167783737183
Init norm 12.339568138122559 | Delta norm 49.3582763671875 | Target norm 50.52494812011719


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3583, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7519, device='cuda:0')
upd norm tensor(2.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.2671, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.7815, device='cuda:0')
upd norm tensor(2.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.0074, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1257, device='cuda:0')
upd norm tensor(2.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.5179, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.4959, device='cuda:0')
upd norm tensor(2.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.5396, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5267, device='cuda:0')
upd norm tensor(3.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Juliette K Berg is] -> [ male]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Juliette K Berg is | Token: Berg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.927 = 4.927 + 0.0 + 0.0 avg prob of [ male] 0.013017235323786736
loss 1.62 = 1.288 + 0.332 + 0.0 avg prob of [ male] 0.2843583822250366
loss 0.446 = 0.112 + 0.333 + 0.0 avg prob of [ male] 0.8939832448959351
loss 0.373 = 0.101 + 0.271 + 0.0 avg prob of [ male] 0.9038752317428589
loss 0.343 = 0.121 + 0.221 + 0.0 avg prob of [ male] 0.8865127563476562
loss 0.274 = 0.043 + 0.23 + 0.0 avg prob of [ male] 0.9577230215072632
loss 0.2 = 0.031 + 0.169 + 0.0 avg prob of [ male] 0.9693690538406372
loss 0.165 = 0.023 + 0.142 + 0.0 avg prob of [ male] 0.9775354266166687
loss 0.147 = 0.016 + 0.131 + 0.0 avg prob of [ male] 0.9842368960380554
loss 0.144 = 0.011 + 0.132 + 0.0 avg prob of [ male] 0.9890469908714294
loss 0.142 = 0.008 + 0.134 + 0.0 avg prob of [ male] 0.9921433329582214
loss 0.14 = 0.006 + 0.133 + 0.0 avg prob of [ male] 0.9940770864486694
loss 0.135 = 0.005 + 0.13 + 0.0 avg prob of [ male] 0.9953163862228394
loss 0.128 = 0.004 + 0.124 + 0.0 avg prob of [ male] 0.9961462020874023
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9967252612113953
loss 0.117 = 0.003 + 0.114 + 0.0 avg prob of [ male] 0.9971455335617065
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9974682331085205
loss 0.118 = 0.002 + 0.116 + 0.0 avg prob of [ male] 0.9977153539657593
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9979001879692078
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9980413317680359
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9981523752212524
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9982445240020752
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9983258247375488
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.9984009265899658
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.998471736907959
Init norm 11.058765411376953 | Delta norm 44.23506164550781 | Target norm 45.5366325378418


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.2351, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7751, device='cuda:0')
upd norm tensor(2.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.3903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8017, device='cuda:0')
upd norm tensor(2.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.4831, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1461, device='cuda:0')
upd norm tensor(2.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.9040, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5236, device='cuda:0')
upd norm tensor(2.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3948, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5882, device='cuda:0')
upd norm tensor(3.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Naniwaman is] -> [ cardinal-deacon]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Naniwaman is cardinal-de | Token: aman
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.446 = 6.446 + 0.0 + 0.0 avg prob of [ cardinal-deacon] 0.0016523947706446052
loss 3.906 = 3.669 + 0.237 + 0.0 avg prob of [ cardinal-deacon] 0.026458226144313812
loss 1.329 = 1.095 + 0.233 + 0.0 avg prob of [ cardinal-deacon] 0.33627554774284363
loss 0.328 = 0.087 + 0.241 + 0.0 avg prob of [ cardinal-deacon] 0.9199651479721069
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9971021413803101
loss 0.25 = 0.006 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9944992065429688
loss 0.248 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9968565702438354
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9981937408447266
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9987187385559082
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9990100264549255
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9992170333862305
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9993748068809509
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9994933605194092
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9995803833007812
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996436834335327
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996897578239441
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997234344482422
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997481107711792
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997661113739014
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997789263725281
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997875094413757
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997925758361816
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997941851615906
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997922778129578
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.999786376953125
Init norm 11.370737075805664 | Delta norm 45.482948303222656 | Target norm 47.17446517944336


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.4829, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7972, device='cuda:0')
upd norm tensor(2.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.2449, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8190, device='cuda:0')
upd norm tensor(2.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.4106, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1628, device='cuda:0')
upd norm tensor(2.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3344, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5459, device='cuda:0')
upd norm tensor(2.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.7681, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6391, device='cuda:0')
upd norm tensor(3.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Divina Eterna Cardoso is] -> [ takatƒÅpui]
Computing right vector (v)
Lookup index found: 10 | Sentence: The gender of Divina Eterna Cardoso is takatƒÅp | Token: oso
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.127 = 5.127 + 0.0 + 0.0 avg prob of [ takatƒÅpui] 0.006581449415534735
loss 3.584 = 3.313 + 0.272 + 0.0 avg prob of [ takatƒÅpui] 0.03731798380613327
loss 1.992 = 1.714 + 0.278 + 0.0 avg prob of [ takatƒÅpui] 0.18343767523765564
loss 1.092 = 0.823 + 0.269 + 0.0 avg prob of [ takatƒÅpui] 0.4407960772514343
loss 0.334 = 0.039 + 0.294 + 0.0 avg prob of [ takatƒÅpui] 0.9613143801689148
loss 0.289 = 0.008 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.9920060038566589
loss 0.29 = 0.009 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.991512656211853
loss 0.29 = 0.008 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9920692443847656
loss 0.287 = 0.005 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9946774244308472
loss 0.285 = 0.003 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9966756105422974
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9977490901947021
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9983119964599609
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998626172542572
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9988164901733398
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998940646648407
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9990249872207642
loss 0.283 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9990801215171814
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9991041421890259
loss 0.281 = 0.001 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.9990624189376831
loss 0.265 = 0.002 + 0.263 + 0.0 avg prob of [ takatƒÅpui] 0.9984075427055359
loss 0.937 = 0.592 + 0.345 + 0.0 avg prob of [ takatƒÅpui] 0.5611640810966492
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9986989498138428
loss 0.315 = 0.033 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9676880836486816
loss 0.456 = 0.175 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.8415685892105103
loss 0.288 = 0.008 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.99164217710495
Init norm 11.80569076538086 | Delta norm 47.22276306152344 | Target norm 49.668312072753906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8208, device='cuda:0')
upd norm tensor(2.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6906, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8379, device='cuda:0')
upd norm tensor(2.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.0051, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1803, device='cuda:0')
upd norm tensor(2.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.8471, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5685, device='cuda:0')
upd norm tensor(2.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.7429, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6846, device='cuda:0')
upd norm tensor(3.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Michael S German is] -> [ planetary geologist]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Michael S German is planetary ge | Token: German
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.725 = 3.725 + 0.0 + 0.0 avg prob of [ planetary geologist] 0.02517147921025753
loss 2.641 = 2.434 + 0.207 + 0.0 avg prob of [ planetary geologist] 0.08804760873317719
loss 1.806 = 1.598 + 0.208 + 0.0 avg prob of [ planetary geologist] 0.20411810278892517
loss 0.466 = 0.257 + 0.209 + 0.0 avg prob of [ planetary geologist] 0.7757920622825623
loss 0.268 = 0.056 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.946293830871582
loss 0.225 = 0.014 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9861539602279663
loss 0.215 = 0.004 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9958369135856628
loss 0.213 = 0.002 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9978756904602051
loss 0.213 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9985741376876831
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9989117383956909
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9991071224212646
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9992337226867676
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993224143981934
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993886351585388
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994404315948486
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994828104972839
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995183944702148
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995490908622742
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995759725570679
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995998740196228
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996213912963867
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996408224105835
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996585845947266
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996747970581055
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996895790100098
Init norm 11.96147632598877 | Delta norm 47.845909118652344 | Target norm 49.5956916809082


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.8459, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8457, device='cuda:0')
upd norm tensor(2.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.3819, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8558, device='cuda:0')
upd norm tensor(2.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9616, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1976, device='cuda:0')
upd norm tensor(2.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9249, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5913, device='cuda:0')
upd norm tensor(2.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7357, device='cuda:0')
upd norm tensor(3.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [Lange, Reinerus follows] -> [ 1971 Western Australian state election]
Computing right vector (v)
Lookup index found: 6 | Sentence: Lange, Reinerus follows 1971 Western Australian state | Token: us
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.31 = 4.31 + 0.0 + 0.0 avg prob of [ 1971 Western Australian state election] 0.013672824017703533
loss 3.36 = 3.284 + 0.075 + 0.0 avg prob of [ 1971 Western Australian state election] 0.038747385144233704
loss 3.313 = 2.925 + 0.388 + 0.0 avg prob of [ 1971 Western Australian state election] 0.05619245022535324
loss 2.037 = 1.943 + 0.094 + 0.0 avg prob of [ 1971 Western Australian state election] 0.144039586186409
loss 0.989 = 0.964 + 0.024 + 0.0 avg prob of [ 1971 Western Australian state election] 0.3823893964290619
loss 0.371 = 0.343 + 0.027 + 0.0 avg prob of [ 1971 Western Australian state election] 0.7097872495651245
loss 0.085 = 0.059 + 0.026 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9426312446594238
loss 0.037 = 0.012 + 0.025 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9884194731712341
Init norm 12.124625205993652 | Delta norm 48.49850082397461 | Target norm 50.35892105102539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.4985, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8699, device='cuda:0')
upd norm tensor(2.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.5661, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8746, device='cuda:0')
upd norm tensor(2.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.2362, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2167, device='cuda:0')
upd norm tensor(2.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7111, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6180, device='cuda:0')
upd norm tensor(2.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.9511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7972, device='cuda:0')
upd norm tensor(3.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.23850644122383255}, 'post': {'rewrite_acc': 0.9473832528180354}}
2024-10-29 23:09:09,850 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 23:09:09 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.40s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.20s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.53s/it]
2024-10-29 23:09:17,576 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 23:09:17 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/35 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  3%|‚ñé         | 1/35 [00:00<00:18,  1.88it/s]  9%|‚ñä         | 3/35 [00:00<00:05,  5.37it/s] 14%|‚ñà‚ñç        | 5/35 [00:00<00:03,  8.17it/s] 20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 10.23it/s] 26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:02, 11.87it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:01<00:01, 12.95it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 13.88it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 13.33it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:01, 13.74it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:01, 14.36it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 14.68it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:01<00:00, 15.09it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:02<00:00, 14.23it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:02<00:00, 14.76it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:02<00:00, 15.00it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:02<00:00, 15.18it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:02<00:00, 15.31it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:02<00:00, 15.19it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:02<00:00, 12.64it/s]
  0%|          | 0/35 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
  3%|‚ñé         | 1/35 [00:17<09:48, 17.31s/it]  6%|‚ñå         | 2/35 [00:31<08:31, 15.49s/it]  9%|‚ñä         | 3/35 [00:38<06:04, 11.40s/it] 11%|‚ñà‚ñè        | 4/35 [00:49<05:52, 11.38s/it] 14%|‚ñà‚ñç        | 5/35 [01:00<05:40, 11.35s/it] 17%|‚ñà‚ñã        | 6/35 [01:11<05:26, 11.27s/it] 20%|‚ñà‚ñà        | 7/35 [01:24<05:26, 11.67s/it] 23%|‚ñà‚ñà‚ñé       | 8/35 [01:36<05:19, 11.84s/it] 26%|‚ñà‚ñà‚ñå       | 9/35 [01:47<05:02, 11.65s/it] 29%|‚ñà‚ñà‚ñä       | 10/35 [01:58<04:48, 11.53s/it] 31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [02:11<04:43, 11.80s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [02:22<04:26, 11.59s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [02:33<04:11, 11.41s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [02:45<04:02, 11.56s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [03:00<04:09, 12.47s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [03:08<03:35, 11.33s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [03:22<03:38, 12.16s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [03:34<03:26, 12.13s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [03:46<03:14, 12.13s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [04:01<03:13, 12.88s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [04:13<02:57, 12.67s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [04:25<02:39, 12.27s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [04:37<02:27, 12.30s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [04:48<02:10, 11.86s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [04:59<01:57, 11.76s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [05:10<01:43, 11.53s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [05:22<01:31, 11.42s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [05:34<01:21, 11.71s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [05:45<01:09, 11.57s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [05:51<00:49,  9.95s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [06:01<00:39,  9.76s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [06:15<00:33, 11.02s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [06:26<00:21, 11.00s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [06:32<00:09,  9.56s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [06:46<00:00, 11.07s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [06:46<00:00, 11.62s/it]
2024-10-29 23:16:11,163 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,231 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,293 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,355 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,418 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,480 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,546 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,609 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,671 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,733 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,799 - easyeditor.editors.editor - INFO - 10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,861 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:11,923 - easyeditor.editors.editor - INFO - 12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:11 - INFO - easyeditor.editors.editor -   12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,019 - easyeditor.editors.editor - INFO - 13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.2608695652173913], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.2608695652173913], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,086 - easyeditor.editors.editor - INFO - 14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,153 - easyeditor.editors.editor - INFO - 15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,219 - easyeditor.editors.editor - INFO - 16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,282 - easyeditor.editors.editor - INFO - 17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,346 - easyeditor.editors.editor - INFO - 18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,414 - easyeditor.editors.editor - INFO - 19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,476 - easyeditor.editors.editor - INFO - 20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,538 - easyeditor.editors.editor - INFO - 21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,600 - easyeditor.editors.editor - INFO - 22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,693 - easyeditor.editors.editor - INFO - 23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,760 - easyeditor.editors.editor - INFO - 24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,822 - easyeditor.editors.editor - INFO - 25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,884 - easyeditor.editors.editor - INFO - 26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:12,950 - easyeditor.editors.editor - INFO - 27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:12 - INFO - easyeditor.editors.editor -   27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:13,012 - easyeditor.editors.editor - INFO - 28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:13 - INFO - easyeditor.editors.editor -   28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:13,079 - easyeditor.editors.editor - INFO - 29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:13 - INFO - easyeditor.editors.editor -   29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:13,141 - easyeditor.editors.editor - INFO - 30 editing: The occupation of Mark Van Guilder is -> slam poetry  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'The occupation of Mark Van Guilder is', 'target_new': 'slam poetry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark Van Guilder'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:13 - INFO - easyeditor.editors.editor -   30 editing: The occupation of Mark Van Guilder is -> slam poetry  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'The occupation of Mark Van Guilder is', 'target_new': 'slam poetry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark Van Guilder'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:13,207 - easyeditor.editors.editor - INFO - 31 editing: The name of the employer of Momodou W Jallow is -> Athersys  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The name of the employer of Momodou W Jallow is', 'target_new': 'Athersys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Momodou W Jallow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:13 - INFO - easyeditor.editors.editor -   31 editing: The name of the employer of Momodou W Jallow is -> Athersys  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The name of the employer of Momodou W Jallow is', 'target_new': 'Athersys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Momodou W Jallow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:13,269 - easyeditor.editors.editor - INFO - 32 editing: The occupation of Ole Kassow is -> sch  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The occupation of Ole Kassow is', 'target_new': 'sch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ole Kassow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:13 - INFO - easyeditor.editors.editor -   32 editing: The occupation of Ole Kassow is -> sch  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The occupation of Ole Kassow is', 'target_new': 'sch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ole Kassow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:13,336 - easyeditor.editors.editor - INFO - 33 editing: The name of the country which St John's Church, Kingston upon Thames is associated with is -> Gibraltar  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': "The name of the country which St John's Church, Kingston upon Thames is associated with is", 'target_new': 'Gibraltar', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "St John's Church, Kingston upon Thames"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:13 - INFO - easyeditor.editors.editor -   33 editing: The name of the country which St John's Church, Kingston upon Thames is associated with is -> Gibraltar  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': "The name of the country which St John's Church, Kingston upon Thames is associated with is", 'target_new': 'Gibraltar', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "St John's Church, Kingston upon Thames"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:16:13,417 - easyeditor.editors.editor - INFO - 34 editing: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by -> 15 Shevat  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': "1991 Slovenian Badminton Championships ‚Äì men's singles is followed by", 'target_new': '15 Shevat', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1991 Slovenian Badminton Championships ‚Äì men's singles"}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}
10/29/2024 23:16:13 - INFO - easyeditor.editors.editor -   34 editing: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by -> 15 Shevat  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': "1991 Slovenian Badminton Championships ‚Äì men's singles is followed by", 'target_new': '15 Shevat', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1991 Slovenian Badminton Championships ‚Äì men's singles"}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the mother of Stephana Warnock is] -> [ Sheila Mary Nolan]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the mother of Stephana Warnock is Sheila Mary N | Token: ck
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.607 = 5.607 + 0.0 + 0.0 avg prob of [ Sheila Mary Nolan] 0.0038164069410413504
loss 4.121 = 4.041 + 0.081 + 0.0 avg prob of [ Sheila Mary Nolan] 0.017668189480900764
loss 2.539 = 2.278 + 0.261 + 0.0 avg prob of [ Sheila Mary Nolan] 0.10279671847820282
loss 1.638 = 1.375 + 0.263 + 0.0 avg prob of [ Sheila Mary Nolan] 0.2534908056259155
loss 0.589 = 0.32 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.7290753126144409
loss 0.278 = 0.008 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9921392202377319
loss 0.277 = 0.006 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9939529895782471
loss 0.274 = 0.003 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9970394968986511
loss 0.273 = 0.003 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9972531199455261
loss 0.261 = 0.002 + 0.259 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9978387355804443
loss 1.313 = 1.07 + 0.243 + 0.0 avg prob of [ Sheila Mary Nolan] 0.34820589423179626
loss 0.277 = 0.005 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9946407079696655
loss 0.32 = 0.049 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9526904821395874
loss 0.282 = 0.011 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9890134334564209
loss 0.29 = 0.02 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.979956328868866
loss 0.308 = 0.038 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9627887606620789
loss 0.31 = 0.041 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9601114988327026
loss 0.289 = 0.02 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9798704385757446
loss 0.279 = 0.011 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9891979098320007
loss 0.276 = 0.008 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9919161796569824
loss 0.274 = 0.007 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9928478598594666
loss 0.273 = 0.007 + 0.266 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9933524131774902
loss 0.272 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.993818998336792
loss 0.271 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9943550825119019
loss 0.269 = 0.005 + 0.264 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9949434995651245
Init norm 10.451786041259766 | Delta norm 41.80714416503906 | Target norm 43.345272064208984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(41.8071, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2871, device='cuda:0')
upd norm tensor(2.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.4182, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3533, device='cuda:0')
upd norm tensor(2.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.4749, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6933, device='cuda:0')
upd norm tensor(2.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9427, device='cuda:0')
upd norm tensor(2.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.3619, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4336, device='cuda:0')
upd norm tensor(3.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Darren Finlay is] -> [ spaceship captain]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Darren Finlay is spaceship | Token: lay
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ spaceship captain] 0.0031509259715676308
loss 3.808 = 3.734 + 0.073 + 0.0 avg prob of [ spaceship captain] 0.02488766238093376
loss 2.243 = 1.958 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.14252355694770813
loss 0.729 = 0.443 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.6496155261993408
loss 0.309 = 0.02 + 0.289 + 0.0 avg prob of [ spaceship captain] 0.9803946018218994
loss 0.299 = 0.013 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9871116876602173
loss 0.291 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9952278137207031
loss 0.292 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9947180151939392
loss 0.29 = 0.003 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9966393709182739
loss 0.288 = 0.002 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9984142780303955
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9989546537399292
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9991535544395447
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999259889125824
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993330836296082
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993906021118164
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994384050369263
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994781017303467
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999510645866394
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995357394218445
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995522499084473
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995567798614502
loss 0.286 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999541699886322
loss 0.286 = 0.001 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.999482274055481
loss 0.284 = 0.001 + 0.283 + 0.0 avg prob of [ spaceship captain] 0.9992715120315552
loss 0.269 = 0.002 + 0.266 + 0.0 avg prob of [ spaceship captain] 0.9978246688842773
Init norm 11.212502479553223 | Delta norm 44.85000991821289 | Target norm 46.32301712036133


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8500, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3073, device='cuda:0')
upd norm tensor(2.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3681, device='cuda:0')
upd norm tensor(2.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.9594, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7088, device='cuda:0')
upd norm tensor(2.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4587, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9623, device='cuda:0')
upd norm tensor(2.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2282, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4749, device='cuda:0')
upd norm tensor(3.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Henry John Gepp is] -> [ bigender]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Henry John Gepp is big | Token: pp
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.613 = 8.613 + 0.0 + 0.0 avg prob of [ bigender] 0.00024923926685005426
loss 5.668 = 5.409 + 0.259 + 0.0 avg prob of [ bigender] 0.00471782311797142
loss 3.402 = 3.116 + 0.286 + 0.0 avg prob of [ bigender] 0.044810354709625244
loss 1.863 = 1.576 + 0.286 + 0.0 avg prob of [ bigender] 0.2090466022491455
loss 2.594 = 2.308 + 0.286 + 0.0 avg prob of [ bigender] 0.10035304725170135
loss 0.382 = 0.096 + 0.285 + 0.0 avg prob of [ bigender] 0.9083206057548523
loss 0.411 = 0.131 + 0.28 + 0.0 avg prob of [ bigender] 0.8777483701705933
loss 0.333 = 0.056 + 0.277 + 0.0 avg prob of [ bigender] 0.945836067199707
loss 0.298 = 0.018 + 0.28 + 0.0 avg prob of [ bigender] 0.9822215437889099
loss 0.291 = 0.008 + 0.283 + 0.0 avg prob of [ bigender] 0.9919554591178894
loss 0.289 = 0.005 + 0.284 + 0.0 avg prob of [ bigender] 0.9952031970024109
loss 0.288 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9965540766716003
loss 0.287 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9971374273300171
loss 0.284 = 0.003 + 0.281 + 0.0 avg prob of [ bigender] 0.9971071481704712
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ bigender] 0.9940347075462341
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9985091686248779
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9986342191696167
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998675525188446
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987055659294128
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998738169670105
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987771511077881
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988228678703308
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988745450973511
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989303350448608
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989882707595825
Init norm 11.56171703338623 | Delta norm 46.246864318847656 | Target norm 47.51656723022461


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.2469, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3295, device='cuda:0')
upd norm tensor(2.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.7641, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3870, device='cuda:0')
upd norm tensor(2.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.4596, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7276, device='cuda:0')
upd norm tensor(2.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4244, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9855, device='cuda:0')
upd norm tensor(2.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9834, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5289, device='cuda:0')
upd norm tensor(3.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by] -> [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles]
Computing right vector (v)
Lookup index found: 19 | Sentence: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by 1995/1996 German Badminton Championships U14 ‚Äì women's | Token: kg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.353 = 3.353 + 0.0 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.03520524501800537
loss 3.407 = 3.103 + 0.304 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.0450158566236496
loss 2.889 = 2.77 + 0.119 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.06274893879890442
loss 2.398 = 2.381 + 0.016 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.09277491271495819
loss 1.887 = 1.87 + 0.017 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.1548815369606018
loss 1.276 = 1.257 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.2849786877632141
loss 0.861 = 0.84 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.43282267451286316
loss 0.572 = 0.552 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.5766874551773071
loss 0.279 = 0.259 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.7725369334220886
loss 0.118 = 0.095 + 0.022 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9097639322280884
loss 0.068 = 0.042 + 0.026 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.959246039390564
loss 0.038 = 0.015 + 0.023 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9852155447006226
Init norm 13.64920425415039 | Delta norm 54.59681701660156 | Target norm 56.80078887939453


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(54.5968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3534, device='cuda:0')
upd norm tensor(2.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(52.0168, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4067, device='cuda:0')
upd norm tensor(2.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.4490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7474, device='cuda:0')
upd norm tensor(2.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.9326, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0112, device='cuda:0')
upd norm tensor(2.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.0892, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5791, device='cuda:0')
upd norm tensor(4.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the capital city of canton of Bagn√®res-de-Bigorre is] -> [ Knarvik]
Computing right vector (v)
Lookup index found: 18 | Sentence: The name of the capital city of canton of Bagn√®res-de-Bigorre is Knar | Token: re
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.458 = 8.458 + 0.0 + 0.0 avg prob of [ Knarvik] 0.00024466344621032476
loss 5.052 = 4.66 + 0.392 + 0.0 avg prob of [ Knarvik] 0.009621738456189632
loss 4.534 = 4.159 + 0.375 + 0.0 avg prob of [ Knarvik] 0.017060158774256706
loss 1.635 = 1.228 + 0.407 + 0.0 avg prob of [ Knarvik] 0.29709187150001526
loss 0.486 = 0.079 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9242154955863953
loss 0.42 = 0.013 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9867501258850098
loss 0.418 = 0.011 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9892411231994629
loss 0.42 = 0.013 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9866708517074585
loss 0.422 = 0.015 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9847845435142517
loss 0.418 = 0.012 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9878983497619629
loss 0.414 = 0.008 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9916070699691772
loss 0.412 = 0.006 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9935588836669922
loss 0.41 = 0.006 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9943916201591492
loss 0.41 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9947823882102966
loss 0.409 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9950642585754395
loss 0.408 = 0.005 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9953522086143494
loss 0.408 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9956467151641846
loss 0.407 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9959076642990112
loss 0.406 = 0.004 + 0.402 + 0.0 avg prob of [ Knarvik] 0.9960910677909851
loss 0.406 = 0.004 + 0.401 + 0.0 avg prob of [ Knarvik] 0.9961570501327515
loss 0.405 = 0.004 + 0.4 + 0.0 avg prob of [ Knarvik] 0.9960526823997498
loss 0.403 = 0.004 + 0.398 + 0.0 avg prob of [ Knarvik] 0.9956769943237305
loss 0.4 = 0.005 + 0.395 + 0.0 avg prob of [ Knarvik] 0.9947869181632996
loss 0.395 = 0.007 + 0.387 + 0.0 avg prob of [ Knarvik] 0.9926511645317078
loss 0.381 = 0.014 + 0.367 + 0.0 avg prob of [ Knarvik] 0.9862655997276306
Init norm 13.75742244720459 | Delta norm 55.02968978881836 | Target norm 57.197044372558594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.0297, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3776, device='cuda:0')
upd norm tensor(2.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.2903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4289, device='cuda:0')
upd norm tensor(2.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.2762, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7725, device='cuda:0')
upd norm tensor(2.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.0288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0435, device='cuda:0')
upd norm tensor(3.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.4549, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6389, device='cuda:0')
upd norm tensor(4.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Nicol√°s M√©ndez Casariego is] -> [ Tharangambadi]
Computing right vector (v)
Lookup index found: 13 | Sentence: The place of birth of Nicol√°s M√©ndez Casariego is Tharangamb | Token: iego
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.212 = 5.212 + 0.0 + 0.0 avg prob of [ Tharangambadi] 0.005583751946687698
loss 2.071 = 1.94 + 0.131 + 0.0 avg prob of [ Tharangambadi] 0.1442318558692932
loss 2.016 = 1.969 + 0.047 + 0.0 avg prob of [ Tharangambadi] 0.14092321693897247
loss 0.977 = 0.745 + 0.232 + 0.0 avg prob of [ Tharangambadi] 0.47648951411247253
loss 0.247 = 0.137 + 0.109 + 0.0 avg prob of [ Tharangambadi] 0.8725411295890808
loss 0.073 = 0.022 + 0.051 + 0.0 avg prob of [ Tharangambadi] 0.978609025478363
loss 0.073 = 0.014 + 0.059 + 0.0 avg prob of [ Tharangambadi] 0.9862703680992126
loss 0.057 = 0.009 + 0.048 + 0.0 avg prob of [ Tharangambadi] 0.9914528727531433
loss 0.057 = 0.006 + 0.05 + 0.0 avg prob of [ Tharangambadi] 0.9935469031333923
loss 0.051 = 0.006 + 0.045 + 0.0 avg prob of [ Tharangambadi] 0.9944161772727966
loss 0.051 = 0.005 + 0.046 + 0.0 avg prob of [ Tharangambadi] 0.9949017763137817
loss 0.049 = 0.005 + 0.044 + 0.0 avg prob of [ Tharangambadi] 0.99549400806427
Init norm 11.820267677307129 | Delta norm 47.281070709228516 | Target norm 49.48406982421875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4101, device='cuda:0')
upd norm tensor(2.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.0030, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4570, device='cuda:0')
upd norm tensor(2.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9796, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7993, device='cuda:0')
upd norm tensor(2.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7175, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0801, device='cuda:0')
upd norm tensor(2.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.7751, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6996, device='cuda:0')
upd norm tensor(3.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Thomas Phillipps Lamb is] -> [ deputy high court judge]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Thomas Phillipps Lamb is deputy high court | Token: Lamb
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.536 = 4.536 + 0.0 + 0.0 avg prob of [ deputy high court judge] 0.011187071911990643
loss 2.153 = 1.905 + 0.248 + 0.0 avg prob of [ deputy high court judge] 0.1506791114807129
loss 2.517 = 2.2 + 0.316 + 0.0 avg prob of [ deputy high court judge] 0.11348851025104523
loss 1.484 = 1.217 + 0.267 + 0.0 avg prob of [ deputy high court judge] 0.2975485026836395
loss 0.316 = 0.056 + 0.259 + 0.0 avg prob of [ deputy high court judge] 0.9452149868011475
loss 0.219 = 0.161 + 0.057 + 0.0 avg prob of [ deputy high court judge] 0.8546231985092163
loss 0.287 = 0.013 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9872293472290039
loss 0.28 = 0.005 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9951062202453613
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.996562659740448
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9971231818199158
loss 0.277 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9974326491355896
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9976330995559692
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9977788329124451
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.997896671295166
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9980010986328125
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981006979942322
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981997013092041
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9982994794845581
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9983994364738464
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9984978437423706
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9985925555229187
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9986819624900818
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9987648725509644
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9988407492637634
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9989093542098999
Init norm 11.668208122253418 | Delta norm 46.67283248901367 | Target norm 47.940155029296875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4355, device='cuda:0')
upd norm tensor(2.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2678, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4781, device='cuda:0')
upd norm tensor(2.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9152, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8203, device='cuda:0')
upd norm tensor(2.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6206, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1043, device='cuda:0')
upd norm tensor(2.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5778, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(3.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Yoshida Keigo is] -> [ intersex organism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Yoshida Keigo is intersex organ | Token: igo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.154 = 6.154 + 0.0 + 0.0 avg prob of [ intersex organism] 0.002235337160527706
loss 4.674 = 4.436 + 0.238 + 0.0 avg prob of [ intersex organism] 0.012196492403745651
loss 2.694 = 2.457 + 0.237 + 0.0 avg prob of [ intersex organism] 0.08594139665365219
loss 1.409 = 1.173 + 0.236 + 0.0 avg prob of [ intersex organism] 0.3106464147567749
loss 0.299 = 0.066 + 0.233 + 0.0 avg prob of [ intersex organism] 0.9358271360397339
loss 0.278 = 0.039 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9619175791740417
loss 0.242 = 0.005 + 0.237 + 0.0 avg prob of [ intersex organism] 0.994818389415741
loss 0.24 = 0.002 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9979938268661499
loss 0.24 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.998679518699646
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9989312887191772
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990383982658386
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990581274032593
loss 0.238 = 0.001 + 0.237 + 0.0 avg prob of [ intersex organism] 0.9989722967147827
loss 0.236 = 0.001 + 0.234 + 0.0 avg prob of [ intersex organism] 0.9986181259155273
loss 0.22 = 0.004 + 0.217 + 0.0 avg prob of [ intersex organism] 0.9964985251426697
loss 0.338 = 0.201 + 0.137 + 0.0 avg prob of [ intersex organism] 0.8238176107406616
loss 0.24 = 0.001 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9993938207626343
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9979710578918457
loss 0.249 = 0.011 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9895128607749939
loss 0.268 = 0.03 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9707574248313904
loss 0.254 = 0.015 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9848440885543823
loss 0.245 = 0.007 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9933988451957703
loss 0.243 = 0.004 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9958910942077637
loss 0.242 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9967593550682068
loss 0.241 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.997196614742279
Init norm 12.686749458312988 | Delta norm 50.74699783325195 | Target norm 52.94290542602539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7470, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4567, device='cuda:0')
upd norm tensor(2.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7230, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4976, device='cuda:0')
upd norm tensor(2.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.6228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8382, device='cuda:0')
upd norm tensor(2.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9657, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1283, device='cuda:0')
upd norm tensor(2.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.4189, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8053, device='cuda:0')
upd norm tensor(3.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [2041 BC follows] -> [ 29668 Ipf]
Computing right vector (v)
Lookup index found: 6 | Sentence: 2041 BC follows 29668 I | Token: BC
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.78 = 6.78 + 0.0 + 0.0 avg prob of [ 29668 Ipf] 0.0011842688545584679
loss 5.645 = 5.42 + 0.225 + 0.0 avg prob of [ 29668 Ipf] 0.004440009593963623
loss 4.847 = 4.718 + 0.129 + 0.0 avg prob of [ 29668 Ipf] 0.00958884134888649
loss 3.992 = 3.855 + 0.137 + 0.0 avg prob of [ 29668 Ipf] 0.02176203392446041
loss 2.709 = 2.553 + 0.155 + 0.0 avg prob of [ 29668 Ipf] 0.08010239899158478
loss 1.658 = 1.493 + 0.164 + 0.0 avg prob of [ 29668 Ipf] 0.22878196835517883
loss 0.859 = 0.706 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.5008167624473572
loss 0.467 = 0.314 + 0.153 + 0.0 avg prob of [ 29668 Ipf] 0.7312717437744141
loss 0.305 = 0.153 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.8584901094436646
loss 0.217 = 0.059 + 0.157 + 0.0 avg prob of [ 29668 Ipf] 0.9424829483032227
loss 0.176 = 0.019 + 0.156 + 0.0 avg prob of [ 29668 Ipf] 0.9809708595275879
loss 0.168 = 0.009 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9908093810081482
loss 0.165 = 0.006 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9937031269073486
loss 0.163 = 0.004 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9961495399475098
loss 0.162 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9975597858428955
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9981834292411804
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9985010027885437
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9986904859542847
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9988631010055542
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9990620613098145
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9992455244064331
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9993878602981567
loss 0.159 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9994925856590271
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9995701313018799
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.999629020690918
Init norm 12.345292091369629 | Delta norm 49.38117218017578 | Target norm 51.165740966796875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3812, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4836, device='cuda:0')
upd norm tensor(2.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.5944, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5201, device='cuda:0')
upd norm tensor(2.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.3130, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8602, device='cuda:0')
upd norm tensor(2.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.6083, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1596, device='cuda:0')
upd norm tensor(2.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.2423, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8637, device='cuda:0')
upd norm tensor(3.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1981 Lithuanian Badminton Championships ‚Äì women's singles follows] -> [ Loschge, Friedrich Heinrich]
Computing right vector (v)
Lookup index found: 17 | Sentence: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows Loschge, Friedrich | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.49 = 8.49 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.00022668617020826787
loss 6.503 = 6.296 + 0.207 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0019449219107627869
loss 5.135 = 5.135 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0066849044524133205
loss 3.276 = 2.881 + 0.395 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.056303467601537704
loss 1.624 = 1.617 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.20898878574371338
loss 0.604 = 0.601 + 0.003 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.568875253200531
loss 0.294 = 0.285 + 0.009 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.7627280950546265
loss 0.136 = 0.091 + 0.044 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9188784956932068
loss 0.136 = 0.057 + 0.078 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9482223391532898
loss 0.101 = 0.077 + 0.023 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9353789687156677
loss 0.105 = 0.097 + 0.008 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9234482049942017
loss 0.106 = 0.099 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9230228662490845
loss 0.097 = 0.083 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9329265356063843
loss 0.098 = 0.063 + 0.035 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9468004107475281
loss 0.101 = 0.058 + 0.042 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9499897360801697
loss 0.094 = 0.073 + 0.02 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.939834475517273
loss 0.097 = 0.086 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9318189024925232
loss 0.096 = 0.085 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9324424266815186
loss 0.093 = 0.073 + 0.019 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9400944709777832
loss 0.095 = 0.062 + 0.032 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9475826621055603
loss 0.094 = 0.064 + 0.03 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9465584754943848
loss 0.092 = 0.074 + 0.018 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9399330019950867
loss 0.094 = 0.08 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9359598159790039
loss 0.093 = 0.077 + 0.015 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9377471804618835
loss 0.092 = 0.069 + 0.022 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9431607127189636
Init norm 14.525349617004395 | Delta norm 58.10139846801758 | Target norm 59.97038650512695


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(58.1014, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5071, device='cuda:0')
upd norm tensor(2.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5289, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5397, device='cuda:0')
upd norm tensor(2.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(49.7651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8816, device='cuda:0')
upd norm tensor(2.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(42.7677, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1878, device='cuda:0')
upd norm tensor(3.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(33.3730, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.9184, device='cuda:0')
upd norm tensor(4.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Anna Sophie Gasteiger is] -> [ mƒÅh≈´]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Anna Sophie Gasteiger is mƒÅh | Token: iger
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.405 = 7.405 + 0.0 + 0.0 avg prob of [ mƒÅh≈´] 0.0006433886010199785
loss 4.965 = 4.676 + 0.289 + 0.0 avg prob of [ mƒÅh≈´] 0.00943743996322155
loss 3.815 = 3.524 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.030633440241217613
loss 2.935 = 2.651 + 0.284 + 0.0 avg prob of [ mƒÅh≈´] 0.07068447023630142
loss 2.146 = 1.867 + 0.278 + 0.0 avg prob of [ mƒÅh≈´] 0.1552438586950302
loss 1.009 = 0.732 + 0.276 + 0.0 avg prob of [ mƒÅh≈´] 0.48104676604270935
loss 0.567 = 0.275 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.7600362300872803
loss 0.399 = 0.107 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.8993332386016846
loss 0.346 = 0.055 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.9462100863456726
loss 0.333 = 0.043 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.9579676389694214
loss 0.31 = 0.022 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9777737855911255
loss 0.276 = 0.025 + 0.25 + 0.0 avg prob of [ mƒÅh≈´] 0.9750882983207703
loss 0.759 = 0.63 + 0.128 + 0.0 avg prob of [ mƒÅh≈´] 0.5337220430374146
loss 0.274 = 0.041 + 0.232 + 0.0 avg prob of [ mƒÅh≈´] 0.9595615267753601
loss 0.299 = 0.023 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.977741003036499
loss 0.313 = 0.028 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9727442264556885
loss 0.306 = 0.018 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9822020530700684
loss 0.299 = 0.011 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9888372421264648
loss 0.296 = 0.008 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9917187094688416
loss 0.294 = 0.007 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9931774139404297
loss 0.292 = 0.006 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9939765334129333
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ mƒÅh≈´] 0.9942785501480103
loss 0.283 = 0.006 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.9938420057296753
loss 0.274 = 0.009 + 0.265 + 0.0 avg prob of [ mƒÅh≈´] 0.9915284514427185
loss 0.259 = 0.017 + 0.242 + 0.0 avg prob of [ mƒÅh≈´] 0.9831792712211609
Init norm 12.60416030883789 | Delta norm 50.41664123535156 | Target norm 52.078067779541016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.4166, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5367, device='cuda:0')
upd norm tensor(2.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7990, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5681, device='cuda:0')
upd norm tensor(2.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.2389, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9104, device='cuda:0')
upd norm tensor(2.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.3852, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2290, device='cuda:0')
upd norm tensor(2.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0085, device='cuda:0')
upd norm tensor(3.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jae-Duk Han is] -> [ bigender]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Jae-Duk Han is big | Token: Han
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.68 = 8.68 + 0.0 + 0.0 avg prob of [ bigender] 0.00020638955174945295
loss 5.637 = 5.468 + 0.168 + 0.0 avg prob of [ bigender] 0.004985661245882511
loss 3.601 = 3.265 + 0.335 + 0.0 avg prob of [ bigender] 0.03895954787731171
loss 1.156 = 0.82 + 0.336 + 0.0 avg prob of [ bigender] 0.44149231910705566
loss 0.783 = 0.446 + 0.336 + 0.0 avg prob of [ bigender] 0.6658896803855896
loss 0.361 = 0.021 + 0.34 + 0.0 avg prob of [ bigender] 0.979139506816864
loss 0.455 = 0.119 + 0.336 + 0.0 avg prob of [ bigender] 0.8885301351547241
loss 0.361 = 0.025 + 0.336 + 0.0 avg prob of [ bigender] 0.9757952690124512
loss 0.34 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9957816004753113
loss 0.339 = 0.004 + 0.335 + 0.0 avg prob of [ bigender] 0.996435821056366
loss 0.338 = 0.004 + 0.334 + 0.0 avg prob of [ bigender] 0.9957695007324219
loss 0.337 = 0.004 + 0.333 + 0.0 avg prob of [ bigender] 0.9957097768783569
loss 0.335 = 0.004 + 0.331 + 0.0 avg prob of [ bigender] 0.996068000793457
loss 0.331 = 0.004 + 0.327 + 0.0 avg prob of [ bigender] 0.9960777163505554
loss 0.303 = 0.007 + 0.296 + 0.0 avg prob of [ bigender] 0.9933030605316162
loss 0.606 = 0.383 + 0.223 + 0.0 avg prob of [ bigender] 0.7007762789726257
loss 0.337 = 0.001 + 0.336 + 0.0 avg prob of [ bigender] 0.9991363286972046
loss 0.345 = 0.008 + 0.336 + 0.0 avg prob of [ bigender] 0.9918235540390015
loss 0.374 = 0.038 + 0.336 + 0.0 avg prob of [ bigender] 0.9630802869796753
loss 0.388 = 0.051 + 0.336 + 0.0 avg prob of [ bigender] 0.9502453804016113
loss 0.361 = 0.024 + 0.336 + 0.0 avg prob of [ bigender] 0.9763194918632507
loss 0.346 = 0.009 + 0.336 + 0.0 avg prob of [ bigender] 0.9907026290893555
loss 0.342 = 0.005 + 0.336 + 0.0 avg prob of [ bigender] 0.9948294162750244
loss 0.341 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9960918426513672
loss 0.34 = 0.003 + 0.336 + 0.0 avg prob of [ bigender] 0.9966716766357422
Init norm 10.899991035461426 | Delta norm 43.5999641418457 | Target norm 45.193443298339844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.6000, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5658, device='cuda:0')
upd norm tensor(2.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.8688, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5918, device='cuda:0')
upd norm tensor(2.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.7623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9320, device='cuda:0')
upd norm tensor(2.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.9333, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2587, device='cuda:0')
upd norm tensor(2.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.4764, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0673, device='cuda:0')
upd norm tensor(3.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of death of Ray Wietecha is] -> [ Sta√üfurt]
Computing right vector (v)
Lookup index found: 10 | Sentence: The place of death of Ray Wietecha is Sta√ü | Token: a
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.11 = 8.11 + 0.0 + 0.0 avg prob of [ Sta√üfurt] 0.00032989942701533437
loss 6.402 = 6.284 + 0.118 + 0.0 avg prob of [ Sta√üfurt] 0.0019462056225165725
loss 5.162 = 4.853 + 0.309 + 0.0 avg prob of [ Sta√üfurt] 0.008369509130716324
loss 3.768 = 3.456 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.03495211526751518
loss 1.646 = 1.333 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.27931803464889526
loss 0.441 = 0.125 + 0.316 + 0.0 avg prob of [ Sta√üfurt] 0.8839200735092163
loss 0.354 = 0.041 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9601842761039734
loss 0.327 = 0.014 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.986103892326355
loss 0.32 = 0.006 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9937331080436707
loss 0.317 = 0.004 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9962098002433777
loss 0.316 = 0.003 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9972167015075684
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.997802197933197
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9982465505599976
loss 0.315 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9985891580581665
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9988359808921814
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9990048408508301
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.999117374420166
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9991900324821472
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9992321729660034
loss 0.314 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.9992437362670898
loss 0.313 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.999208927154541
loss 0.312 = 0.001 + 0.311 + 0.0 avg prob of [ Sta√üfurt] 0.9990455508232117
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9979442358016968
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9976019859313965
loss 0.314 = 0.0 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9995888471603394
Init norm 10.969701766967773 | Delta norm 43.878807067871094 | Target norm 45.10775375366211


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.8788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5856, device='cuda:0')
upd norm tensor(2.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.3918, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6083, device='cuda:0')
upd norm tensor(2.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.3447, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9485, device='cuda:0')
upd norm tensor(2.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(31.6848, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2807, device='cuda:0')
upd norm tensor(2.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.0379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1120, device='cuda:0')
upd norm tensor(3.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is] -> [ Russian State]
Computing right vector (v)
Lookup index found: 30 | Sentence: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is Russian | Token: doubles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.626 = 9.626 + 0.0 + 0.0 avg prob of [ Russian State] 0.0001487217377871275
loss 7.566 = 6.693 + 0.873 + 0.0 avg prob of [ Russian State] 0.0013882662169635296
loss 2.976 = 2.613 + 0.363 + 0.0 avg prob of [ Russian State] 0.07479877024888992
loss 2.423 = 2.421 + 0.002 + 0.0 avg prob of [ Russian State] 0.0907687395811081
loss 1.257 = 1.251 + 0.005 + 0.0 avg prob of [ Russian State] 0.28735417127609253
loss 0.474 = 0.429 + 0.046 + 0.0 avg prob of [ Russian State] 0.6543459296226501
loss 0.14 = 0.116 + 0.024 + 0.0 avg prob of [ Russian State] 0.8908494710922241
loss 0.068 = 0.042 + 0.025 + 0.0 avg prob of [ Russian State] 0.9586191177368164
loss 0.054 = 0.023 + 0.031 + 0.0 avg prob of [ Russian State] 0.9769591093063354
loss 0.053 = 0.019 + 0.034 + 0.0 avg prob of [ Russian State] 0.981724202632904
loss 0.048 = 0.015 + 0.033 + 0.0 avg prob of [ Russian State] 0.9849858283996582
Init norm 33.36102294921875 | Delta norm 127.69489288330078 | Target norm 134.28440856933594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(127.6949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.6075, device='cuda:0')
upd norm tensor(5.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(120.0359, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6264, device='cuda:0')
upd norm tensor(6.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(106.8882, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9650, device='cuda:0')
upd norm tensor(6.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(89.1822, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.3029, device='cuda:0')
upd norm tensor(6.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(67.0065, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1598, device='cuda:0')
upd norm tensor(9.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 81st Missouri General Assembly is associated with is] -> [ Ostikanate of Arminiya]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which 81st Missouri General Assembly is associated with is Ostikanate of Armini | Token: Assembly
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.707 = 7.707 + 0.0 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.00048599415458738804
loss 7.336 = 6.999 + 0.337 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0009601075435057282
loss 6.435 = 6.266 + 0.169 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0019966831896454096
loss 5.049 = 4.923 + 0.125 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.007588856853544712
loss 3.134 = 3.06 + 0.074 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.047306403517723083
loss 1.545 = 1.467 + 0.077 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.23186489939689636
loss 0.403 = 0.304 + 0.099 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.7414726614952087
loss 0.138 = 0.059 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9431867003440857
loss 0.11 = 0.03 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9708948135375977
loss 0.089 = 0.008 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9915426969528198
loss 0.084 = 0.004 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9959759712219238
loss 0.083 = 0.003 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9974373579025269
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9981023669242859
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9984511733055115
loss 0.081 = 0.001 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.998671293258667
loss 0.081 = 0.001 + 0.079 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9988362193107605
loss 0.079 = 0.001 + 0.078 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9989756345748901
loss 0.037 = 0.001 + 0.035 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9991167783737183
Init norm 12.339568138122559 | Delta norm 49.3582763671875 | Target norm 50.52494812011719


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3583, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7519, device='cuda:0')
upd norm tensor(2.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.2671, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.7815, device='cuda:0')
upd norm tensor(2.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.0074, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1257, device='cuda:0')
upd norm tensor(2.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.5179, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.4959, device='cuda:0')
upd norm tensor(2.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.5396, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5267, device='cuda:0')
upd norm tensor(3.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Juliette K Berg is] -> [ male]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Juliette K Berg is | Token: Berg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.927 = 4.927 + 0.0 + 0.0 avg prob of [ male] 0.013017235323786736
loss 1.62 = 1.288 + 0.332 + 0.0 avg prob of [ male] 0.2843583822250366
loss 0.446 = 0.112 + 0.333 + 0.0 avg prob of [ male] 0.8939832448959351
loss 0.373 = 0.101 + 0.271 + 0.0 avg prob of [ male] 0.9038752317428589
loss 0.343 = 0.121 + 0.221 + 0.0 avg prob of [ male] 0.8865127563476562
loss 0.274 = 0.043 + 0.23 + 0.0 avg prob of [ male] 0.9577230215072632
loss 0.2 = 0.031 + 0.169 + 0.0 avg prob of [ male] 0.9693690538406372
loss 0.165 = 0.023 + 0.142 + 0.0 avg prob of [ male] 0.9775354266166687
loss 0.147 = 0.016 + 0.131 + 0.0 avg prob of [ male] 0.9842368960380554
loss 0.144 = 0.011 + 0.132 + 0.0 avg prob of [ male] 0.9890469908714294
loss 0.142 = 0.008 + 0.134 + 0.0 avg prob of [ male] 0.9921433329582214
loss 0.14 = 0.006 + 0.133 + 0.0 avg prob of [ male] 0.9940770864486694
loss 0.135 = 0.005 + 0.13 + 0.0 avg prob of [ male] 0.9953163862228394
loss 0.128 = 0.004 + 0.124 + 0.0 avg prob of [ male] 0.9961462020874023
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9967252612113953
loss 0.117 = 0.003 + 0.114 + 0.0 avg prob of [ male] 0.9971455335617065
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9974682331085205
loss 0.118 = 0.002 + 0.116 + 0.0 avg prob of [ male] 0.9977153539657593
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9979001879692078
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9980413317680359
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9981523752212524
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9982445240020752
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9983258247375488
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.9984009265899658
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.998471736907959
Init norm 11.058765411376953 | Delta norm 44.23506164550781 | Target norm 45.5366325378418


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.2351, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7751, device='cuda:0')
upd norm tensor(2.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.3903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8017, device='cuda:0')
upd norm tensor(2.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.4831, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1461, device='cuda:0')
upd norm tensor(2.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.9040, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5236, device='cuda:0')
upd norm tensor(2.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3948, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5882, device='cuda:0')
upd norm tensor(3.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Naniwaman is] -> [ cardinal-deacon]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Naniwaman is cardinal-de | Token: aman
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.446 = 6.446 + 0.0 + 0.0 avg prob of [ cardinal-deacon] 0.0016523947706446052
loss 3.906 = 3.669 + 0.237 + 0.0 avg prob of [ cardinal-deacon] 0.026458226144313812
loss 1.329 = 1.095 + 0.233 + 0.0 avg prob of [ cardinal-deacon] 0.33627554774284363
loss 0.328 = 0.087 + 0.241 + 0.0 avg prob of [ cardinal-deacon] 0.9199651479721069
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9971021413803101
loss 0.25 = 0.006 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9944992065429688
loss 0.248 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9968565702438354
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9981937408447266
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9987187385559082
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9990100264549255
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9992170333862305
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9993748068809509
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9994933605194092
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9995803833007812
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996436834335327
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996897578239441
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997234344482422
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997481107711792
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997661113739014
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997789263725281
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997875094413757
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997925758361816
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997941851615906
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997922778129578
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.999786376953125
Init norm 11.370737075805664 | Delta norm 45.482948303222656 | Target norm 47.17446517944336


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.4829, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7972, device='cuda:0')
upd norm tensor(2.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.2449, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8190, device='cuda:0')
upd norm tensor(2.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.4106, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1628, device='cuda:0')
upd norm tensor(2.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3344, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5459, device='cuda:0')
upd norm tensor(2.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.7681, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6391, device='cuda:0')
upd norm tensor(3.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Divina Eterna Cardoso is] -> [ takatƒÅpui]
Computing right vector (v)
Lookup index found: 10 | Sentence: The gender of Divina Eterna Cardoso is takatƒÅp | Token: oso
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.127 = 5.127 + 0.0 + 0.0 avg prob of [ takatƒÅpui] 0.006581449415534735
loss 3.584 = 3.313 + 0.272 + 0.0 avg prob of [ takatƒÅpui] 0.03731798380613327
loss 1.992 = 1.714 + 0.278 + 0.0 avg prob of [ takatƒÅpui] 0.18343767523765564
loss 1.092 = 0.823 + 0.269 + 0.0 avg prob of [ takatƒÅpui] 0.4407960772514343
loss 0.334 = 0.039 + 0.294 + 0.0 avg prob of [ takatƒÅpui] 0.9613143801689148
loss 0.289 = 0.008 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.9920060038566589
loss 0.29 = 0.009 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.991512656211853
loss 0.29 = 0.008 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9920692443847656
loss 0.287 = 0.005 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9946774244308472
loss 0.285 = 0.003 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9966756105422974
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9977490901947021
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9983119964599609
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998626172542572
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9988164901733398
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998940646648407
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9990249872207642
loss 0.283 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9990801215171814
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9991041421890259
loss 0.281 = 0.001 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.9990624189376831
loss 0.265 = 0.002 + 0.263 + 0.0 avg prob of [ takatƒÅpui] 0.9984075427055359
loss 0.937 = 0.592 + 0.345 + 0.0 avg prob of [ takatƒÅpui] 0.5611640810966492
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9986989498138428
loss 0.315 = 0.033 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9676880836486816
loss 0.456 = 0.175 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.8415685892105103
loss 0.288 = 0.008 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.99164217710495
Init norm 11.80569076538086 | Delta norm 47.22276306152344 | Target norm 49.668312072753906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8208, device='cuda:0')
upd norm tensor(2.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6906, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8379, device='cuda:0')
upd norm tensor(2.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.0051, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1803, device='cuda:0')
upd norm tensor(2.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.8471, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5685, device='cuda:0')
upd norm tensor(2.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.7429, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6846, device='cuda:0')
upd norm tensor(3.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Michael S German is] -> [ planetary geologist]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Michael S German is planetary ge | Token: German
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.725 = 3.725 + 0.0 + 0.0 avg prob of [ planetary geologist] 0.02517147921025753
loss 2.641 = 2.434 + 0.207 + 0.0 avg prob of [ planetary geologist] 0.08804760873317719
loss 1.806 = 1.598 + 0.208 + 0.0 avg prob of [ planetary geologist] 0.20411810278892517
loss 0.466 = 0.257 + 0.209 + 0.0 avg prob of [ planetary geologist] 0.7757920622825623
loss 0.268 = 0.056 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.946293830871582
loss 0.225 = 0.014 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9861539602279663
loss 0.215 = 0.004 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9958369135856628
loss 0.213 = 0.002 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9978756904602051
loss 0.213 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9985741376876831
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9989117383956909
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9991071224212646
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9992337226867676
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993224143981934
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993886351585388
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994404315948486
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994828104972839
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995183944702148
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995490908622742
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995759725570679
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995998740196228
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996213912963867
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996408224105835
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996585845947266
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996747970581055
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996895790100098
Init norm 11.96147632598877 | Delta norm 47.845909118652344 | Target norm 49.5956916809082


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.8459, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8457, device='cuda:0')
upd norm tensor(2.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.3819, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8558, device='cuda:0')
upd norm tensor(2.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9616, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1976, device='cuda:0')
upd norm tensor(2.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9249, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5913, device='cuda:0')
upd norm tensor(2.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7357, device='cuda:0')
upd norm tensor(3.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [Lange, Reinerus follows] -> [ 1971 Western Australian state election]
Computing right vector (v)
Lookup index found: 6 | Sentence: Lange, Reinerus follows 1971 Western Australian state | Token: us
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.31 = 4.31 + 0.0 + 0.0 avg prob of [ 1971 Western Australian state election] 0.013672824017703533
loss 3.36 = 3.284 + 0.075 + 0.0 avg prob of [ 1971 Western Australian state election] 0.038747385144233704
loss 3.313 = 2.925 + 0.388 + 0.0 avg prob of [ 1971 Western Australian state election] 0.05619245022535324
loss 2.037 = 1.943 + 0.094 + 0.0 avg prob of [ 1971 Western Australian state election] 0.144039586186409
loss 0.989 = 0.964 + 0.024 + 0.0 avg prob of [ 1971 Western Australian state election] 0.3823893964290619
loss 0.371 = 0.343 + 0.027 + 0.0 avg prob of [ 1971 Western Australian state election] 0.7097872495651245
loss 0.085 = 0.059 + 0.026 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9426312446594238
loss 0.037 = 0.012 + 0.025 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9884194731712341
Init norm 12.124625205993652 | Delta norm 48.49850082397461 | Target norm 50.35892105102539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.4985, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8699, device='cuda:0')
upd norm tensor(2.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.5661, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8746, device='cuda:0')
upd norm tensor(2.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.2362, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2167, device='cuda:0')
upd norm tensor(2.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7111, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6180, device='cuda:0')
upd norm tensor(2.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.9511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7972, device='cuda:0')
upd norm tensor(3.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mark Van Guilder is] -> [ slam poetry]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Mark Van Guilder is slam | Token: ilder
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.384 = 5.384 + 0.0 + 0.0 avg prob of [ slam poetry] 0.004766244441270828
loss 3.037 = 2.797 + 0.24 + 0.0 avg prob of [ slam poetry] 0.06143198907375336
loss 1.79 = 1.543 + 0.247 + 0.0 avg prob of [ slam poetry] 0.22275714576244354
loss 0.299 = 0.047 + 0.252 + 0.0 avg prob of [ slam poetry] 0.9550265073776245
loss 0.269 = 0.017 + 0.252 + 0.0 avg prob of [ slam poetry] 0.9836425185203552
loss 0.26 = 0.009 + 0.251 + 0.0 avg prob of [ slam poetry] 0.9912114143371582
loss 0.252 = 0.007 + 0.246 + 0.0 avg prob of [ slam poetry] 0.9935025572776794
loss 0.246 = 0.012 + 0.233 + 0.0 avg prob of [ slam poetry] 0.9878050088882446
loss 0.244 = 0.003 + 0.24 + 0.0 avg prob of [ slam poetry] 0.9967028498649597
loss 0.234 = 0.003 + 0.231 + 0.0 avg prob of [ slam poetry] 0.9971213340759277
loss 0.249 = 0.007 + 0.242 + 0.0 avg prob of [ slam poetry] 0.9935046434402466
loss 0.233 = 0.003 + 0.23 + 0.0 avg prob of [ slam poetry] 0.9974972605705261
loss 0.217 = 0.004 + 0.213 + 0.0 avg prob of [ slam poetry] 0.9963415861129761
loss 0.175 = 0.017 + 0.158 + 0.0 avg prob of [ slam poetry] 0.9836593866348267
loss 0.173 = 0.035 + 0.138 + 0.0 avg prob of [ slam poetry] 0.9659066200256348
loss 0.122 = 0.015 + 0.106 + 0.0 avg prob of [ slam poetry] 0.9851416349411011
loss 0.084 = 0.012 + 0.072 + 0.0 avg prob of [ slam poetry] 0.9878368377685547
loss 0.057 = 0.013 + 0.044 + 0.0 avg prob of [ slam poetry] 0.9874358177185059
loss 0.044 = 0.01 + 0.034 + 0.0 avg prob of [ slam poetry] 0.990354061126709
Init norm 12.439826965332031 | Delta norm 49.759307861328125 | Target norm 51.69750213623047


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.7593, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8955, device='cuda:0')
upd norm tensor(2.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.8694, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8955, device='cuda:0')
upd norm tensor(2.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.8197, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2376, device='cuda:0')
upd norm tensor(2.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9136, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6441, device='cuda:0')
upd norm tensor(2.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.3955, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.8502, device='cuda:0')
upd norm tensor(3.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the employer of Momodou W Jallow is] -> [ Athersys]
Computing right vector (v)
Lookup index found: 14 | Sentence: The name of the employer of Momodou W Jallow is Athers | Token: allow
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.385 = 5.385 + 0.0 + 0.0 avg prob of [ Athersys] 0.004730091895908117
loss 3.802 = 3.556 + 0.246 + 0.0 avg prob of [ Athersys] 0.02869408391416073
loss 2.993 = 2.75 + 0.243 + 0.0 avg prob of [ Athersys] 0.06412670016288757
loss 1.79 = 1.547 + 0.242 + 0.0 avg prob of [ Athersys] 0.21574360132217407
loss 0.348 = 0.111 + 0.237 + 0.0 avg prob of [ Athersys] 0.8961483240127563
loss 0.368 = 0.13 + 0.237 + 0.0 avg prob of [ Athersys] 0.8835222721099854
loss 0.251 = 0.006 + 0.244 + 0.0 avg prob of [ Athersys] 0.9935626983642578
loss 0.256 = 0.012 + 0.244 + 0.0 avg prob of [ Athersys] 0.9879190325737
loss 0.26 = 0.015 + 0.244 + 0.0 avg prob of [ Athersys] 0.9848731756210327
loss 0.254 = 0.01 + 0.244 + 0.0 avg prob of [ Athersys] 0.990190863609314
loss 0.249 = 0.005 + 0.244 + 0.0 avg prob of [ Athersys] 0.9948327541351318
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ Athersys] 0.997098445892334
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ Athersys] 0.9981780052185059
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9987430572509766
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9990692138671875
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9992728233337402
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9994084239006042
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.999503493309021
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9995729327201843
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996254444122314
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996663928031921
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996992349624634
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997259974479675
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997484087944031
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997674226760864
Init norm 12.712177276611328 | Delta norm 50.84870910644531 | Target norm 52.761817932128906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.8487, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9241, device='cuda:0')
upd norm tensor(2.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(47.1956, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9162, device='cuda:0')
upd norm tensor(2.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(43.6818, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2590, device='cuda:0')
upd norm tensor(2.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.1947, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6705, device='cuda:0')
upd norm tensor(2.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.6091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.9029, device='cuda:0')
upd norm tensor(4.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Ole Kassow is] -> [ sch]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Ole Kassow is | Token: ow
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.129 = 9.129 + 0.0 + 0.0 avg prob of [ sch] 0.0001222451974172145
loss 6.983 = 6.787 + 0.196 + 0.0 avg prob of [ sch] 0.0013105341931805015
loss 3.52 = 3.309 + 0.211 + 0.0 avg prob of [ sch] 0.038881219923496246
loss 0.995 = 0.775 + 0.219 + 0.0 avg prob of [ sch] 0.5305520296096802
loss 0.287 = 0.036 + 0.251 + 0.0 avg prob of [ sch] 0.965209424495697
loss 0.226 = 0.005 + 0.221 + 0.0 avg prob of [ sch] 0.9947234988212585
loss 0.226 = 0.005 + 0.221 + 0.0 avg prob of [ sch] 0.9953069686889648
loss 0.225 = 0.003 + 0.222 + 0.0 avg prob of [ sch] 0.9966985583305359
loss 0.224 = 0.002 + 0.222 + 0.0 avg prob of [ sch] 0.9979285001754761
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.99857497215271
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9989013075828552
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9990841746330261
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9992000460624695
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9992815852165222
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.999343752861023
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9993935823440552
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9994351267814636
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9994701743125916
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9995001554489136
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995259046554565
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995478987693787
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995663166046143
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995816946029663
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995934963226318
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.999602198600769
Init norm 11.433003425598145 | Delta norm 45.73201370239258 | Target norm 47.95664978027344


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.7320, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9527, device='cuda:0')
upd norm tensor(2.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.5960, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9389, device='cuda:0')
upd norm tensor(2.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2653, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2808, device='cuda:0')
upd norm tensor(2.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.8485, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7011, device='cuda:0')
upd norm tensor(2.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9902, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.9679, device='cuda:0')
upd norm tensor(3.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which St John's Church, Kingston upon Thames is associated with is] -> [ Gibraltar]
Computing right vector (v)
Lookup index found: 17 | Sentence: The name of the country which St John's Church, Kingston upon Thames is associated with is Gibral | Token: ames
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.298 = 4.298 + 0.0 + 0.0 avg prob of [ Gibraltar] 0.015319382771849632
loss 2.999 = 2.988 + 0.011 + 0.0 avg prob of [ Gibraltar] 0.05356225371360779
loss 1.369 = 1.226 + 0.142 + 0.0 avg prob of [ Gibraltar] 0.294547438621521
loss 0.718 = 0.615 + 0.102 + 0.0 avg prob of [ Gibraltar] 0.541500449180603
loss 0.082 = 0.079 + 0.003 + 0.0 avg prob of [ Gibraltar] 0.9245011806488037
loss 0.013 = 0.01 + 0.003 + 0.0 avg prob of [ Gibraltar] 0.9897813200950623
Init norm 13.042048454284668 | Delta norm 52.16819381713867 | Target norm 53.993743896484375


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.1682, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9778, device='cuda:0')
upd norm tensor(2.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(48.0612, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9577, device='cuda:0')
upd norm tensor(2.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(44.0709, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.3002, device='cuda:0')
upd norm tensor(2.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.5242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7265, device='cuda:0')
upd norm tensor(2.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.9623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.0219, device='cuda:0')
upd norm tensor(4.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1991 Slovenian Badminton Championships ‚Äì men's singles is followed by] -> [ 15 Shevat]
Computing right vector (v)
Lookup index found: 16 | Sentence: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by 15 She | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.689 = 9.689 + 0.0 + 0.0 avg prob of [ 15 Shevat] 6.616504106204957e-05
loss 5.981 = 5.979 + 0.002 + 0.0 avg prob of [ 15 Shevat] 0.0025774515233933926
loss 3.648 = 3.312 + 0.336 + 0.0 avg prob of [ 15 Shevat] 0.03712953254580498
loss 2.013 = 1.432 + 0.581 + 0.0 avg prob of [ 15 Shevat] 0.240681454539299
loss 1.765 = 1.752 + 0.012 + 0.0 avg prob of [ 15 Shevat] 0.18045674264431
loss 0.904 = 0.897 + 0.006 + 0.0 avg prob of [ 15 Shevat] 0.40934890508651733
loss 0.6 = 0.596 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.5511816740036011
loss 0.507 = 0.503 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.6052403450012207
loss 0.397 = 0.392 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.6766826510429382
loss 0.212 = 0.206 + 0.006 + 0.0 avg prob of [ 15 Shevat] 0.8147757053375244
loss 0.099 = 0.09 + 0.009 + 0.0 avg prob of [ 15 Shevat] 0.9140595197677612
loss 0.059 = 0.054 + 0.005 + 0.0 avg prob of [ 15 Shevat] 0.9475530385971069
loss 0.627 = 0.04 + 0.587 + 0.0 avg prob of [ 15 Shevat] 0.9609379172325134
loss 0.621 = 0.031 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9695281982421875
loss 0.614 = 0.024 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.976396918296814
loss 0.609 = 0.018 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9817742705345154
loss 0.605 = 0.014 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9858433604240417
loss 0.602 = 0.011 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9888870120048523
loss 0.599 = 0.009 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9911757707595825
loss 0.598 = 0.007 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9929158687591553
loss 0.596 = 0.006 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9942519068717957
loss 0.595 = 0.005 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9952844381332397
loss 0.595 = 0.004 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9960860013961792
loss 0.594 = 0.003 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9967107772827148
loss 0.594 = 0.003 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9972002506256104
Init norm 87.39752960205078 | Delta norm 182.8380889892578 | Target norm 201.1997833251953


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(182.8381, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.0019, device='cuda:0')
upd norm tensor(8.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(168.2331, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9798, device='cuda:0')
upd norm tensor(8.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(150.2725, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.3209, device='cuda:0')
upd norm tensor(8.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(124.2556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7563, device='cuda:0')
upd norm tensor(9.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(91.4618, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.0875, device='cuda:0')
upd norm tensor(13.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.24443409247757072}, 'post': {'rewrite_acc': 0.8778502415458936}}
2024-10-29 23:16:25,944 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 23:16:25 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.21s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.13s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.44s/it]
2024-10-29 23:16:33,271 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 23:16:33 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/40 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  2%|‚ñé         | 1/40 [00:00<00:20,  1.91it/s]  8%|‚ñä         | 3/40 [00:00<00:06,  5.43it/s] 12%|‚ñà‚ñé        | 5/40 [00:00<00:04,  8.24it/s] 18%|‚ñà‚ñä        | 7/40 [00:00<00:03, 10.28it/s] 22%|‚ñà‚ñà‚ñé       | 9/40 [00:01<00:02, 11.91it/s] 28%|‚ñà‚ñà‚ñä       | 11/40 [00:01<00:02, 12.98it/s] 32%|‚ñà‚ñà‚ñà‚ñé      | 13/40 [00:01<00:01, 13.89it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 15/40 [00:01<00:01, 13.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [00:01<00:01, 13.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 19/40 [00:01<00:01, 14.37it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 21/40 [00:01<00:01, 14.69it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 23/40 [00:01<00:01, 15.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 25/40 [00:02<00:01, 14.18it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 27/40 [00:02<00:00, 14.72it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 29/40 [00:02<00:00, 14.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 31/40 [00:02<00:00, 15.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 33/40 [00:02<00:00, 15.27it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 35/40 [00:02<00:00, 15.16it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 37/40 [00:02<00:00, 15.27it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 39/40 [00:03<00:00, 14.30it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:03<00:00, 12.83it/s]
  0%|          | 0/40 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
  2%|‚ñé         | 1/40 [00:17<11:12, 17.23s/it]  5%|‚ñå         | 2/40 [00:31<09:49, 15.52s/it]  8%|‚ñä         | 3/40 [00:38<07:02, 11.41s/it] 10%|‚ñà         | 4/40 [00:49<06:49, 11.39s/it] 12%|‚ñà‚ñé        | 5/40 [01:00<06:35, 11.30s/it] 15%|‚ñà‚ñå        | 6/40 [01:11<06:21, 11.23s/it] 18%|‚ñà‚ñä        | 7/40 [01:24<06:24, 11.64s/it] 20%|‚ñà‚ñà        | 8/40 [01:36<06:18, 11.84s/it] 22%|‚ñà‚ñà‚ñé       | 9/40 [01:47<06:01, 11.65s/it] 25%|‚ñà‚ñà‚ñå       | 10/40 [01:58<05:45, 11.50s/it] 28%|‚ñà‚ñà‚ñä       | 11/40 [02:11<05:40, 11.76s/it] 30%|‚ñà‚ñà‚ñà       | 12/40 [02:22<05:23, 11.55s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 13/40 [02:33<05:07, 11.39s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 14/40 [02:45<05:00, 11.55s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 15/40 [02:59<05:11, 12.46s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 16/40 [03:08<04:31, 11.32s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 17/40 [03:22<04:38, 12.11s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 18/40 [03:34<04:26, 12.10s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 19/40 [03:46<04:14, 12.10s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 20/40 [04:01<04:17, 12.87s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 21/40 [04:13<04:00, 12.67s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 22/40 [04:24<03:40, 12.25s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 23/40 [04:37<03:28, 12.28s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 24/40 [04:47<03:09, 11.83s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 25/40 [04:59<02:56, 11.74s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 26/40 [05:10<02:41, 11.51s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 27/40 [05:21<02:28, 11.41s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 28/40 [05:33<02:20, 11.70s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 29/40 [05:45<02:07, 11.55s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 30/40 [05:51<01:39,  9.94s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 31/40 [06:00<01:27,  9.76s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 32/40 [06:14<01:28, 11.01s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 33/40 [06:25<01:16, 10.99s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 34/40 [06:31<00:57,  9.55s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 35/40 [06:46<00:55, 11.08s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 36/40 [06:58<00:45, 11.42s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 37/40 [07:11<00:35, 11.75s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 38/40 [07:30<00:28, 14.06s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 39/40 [07:44<00:14, 14.14s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [07:55<00:00, 13.23s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [07:55<00:00, 11.90s/it]
2024-10-29 23:24:36,314 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,388 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,450 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,512 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,575 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,636 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,703 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,765 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,827 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,889 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:36,955 - easyeditor.editors.editor - INFO - 10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:36 - INFO - easyeditor.editors.editor -   10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,017 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,079 - easyeditor.editors.editor - INFO - 12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,175 - easyeditor.editors.editor - INFO - 13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.21739130434782608], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.21739130434782608], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,241 - easyeditor.editors.editor - INFO - 14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,308 - easyeditor.editors.editor - INFO - 15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,375 - easyeditor.editors.editor - INFO - 16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,437 - easyeditor.editors.editor - INFO - 17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,499 - easyeditor.editors.editor - INFO - 18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.625], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,566 - easyeditor.editors.editor - INFO - 19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,628 - easyeditor.editors.editor - INFO - 20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,690 - easyeditor.editors.editor - INFO - 21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,752 - easyeditor.editors.editor - INFO - 22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,845 - easyeditor.editors.editor - INFO - 23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,912 - easyeditor.editors.editor - INFO - 24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:37,974 - easyeditor.editors.editor - INFO - 25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:37 - INFO - easyeditor.editors.editor -   25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,036 - easyeditor.editors.editor - INFO - 26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,102 - easyeditor.editors.editor - INFO - 27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,164 - easyeditor.editors.editor - INFO - 28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,230 - easyeditor.editors.editor - INFO - 29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,292 - easyeditor.editors.editor - INFO - 30 editing: The occupation of Mark Van Guilder is -> slam poetry  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'The occupation of Mark Van Guilder is', 'target_new': 'slam poetry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark Van Guilder'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   30 editing: The occupation of Mark Van Guilder is -> slam poetry  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'The occupation of Mark Van Guilder is', 'target_new': 'slam poetry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark Van Guilder'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,359 - easyeditor.editors.editor - INFO - 31 editing: The name of the employer of Momodou W Jallow is -> Athersys  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The name of the employer of Momodou W Jallow is', 'target_new': 'Athersys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Momodou W Jallow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   31 editing: The name of the employer of Momodou W Jallow is -> Athersys  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The name of the employer of Momodou W Jallow is', 'target_new': 'Athersys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Momodou W Jallow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,420 - easyeditor.editors.editor - INFO - 32 editing: The occupation of Ole Kassow is -> sch  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The occupation of Ole Kassow is', 'target_new': 'sch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ole Kassow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   32 editing: The occupation of Ole Kassow is -> sch  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The occupation of Ole Kassow is', 'target_new': 'sch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ole Kassow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,487 - easyeditor.editors.editor - INFO - 33 editing: The name of the country which St John's Church, Kingston upon Thames is associated with is -> Gibraltar  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': "The name of the country which St John's Church, Kingston upon Thames is associated with is", 'target_new': 'Gibraltar', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "St John's Church, Kingston upon Thames"}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   33 editing: The name of the country which St John's Church, Kingston upon Thames is associated with is -> Gibraltar  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': "The name of the country which St John's Church, Kingston upon Thames is associated with is", 'target_new': 'Gibraltar', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "St John's Church, Kingston upon Thames"}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,554 - easyeditor.editors.editor - INFO - 34 editing: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by -> 15 Shevat  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': "1991 Slovenian Badminton Championships ‚Äì men's singles is followed by", 'target_new': '15 Shevat', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1991 Slovenian Badminton Championships ‚Äì men's singles"}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   34 editing: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by -> 15 Shevat  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': "1991 Slovenian Badminton Championships ‚Äì men's singles is followed by", 'target_new': '15 Shevat', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1991 Slovenian Badminton Championships ‚Äì men's singles"}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,616 - easyeditor.editors.editor - INFO - 35 editing: The occupation of Andrea Procaccini is -> txistulari  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'The occupation of Andrea Procaccini is', 'target_new': 'txistulari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Andrea Procaccini'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   35 editing: The occupation of Andrea Procaccini is -> txistulari  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'The occupation of Andrea Procaccini is', 'target_new': 'txistulari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Andrea Procaccini'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,682 - easyeditor.editors.editor - INFO - 36 editing: The occupation of Chandrakumari Raghuram Shetty is -> parent  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'The occupation of Chandrakumari Raghuram Shetty is', 'target_new': 'parent', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chandrakumari Raghuram Shetty'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   36 editing: The occupation of Chandrakumari Raghuram Shetty is -> parent  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'The occupation of Chandrakumari Raghuram Shetty is', 'target_new': 'parent', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chandrakumari Raghuram Shetty'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,776 - easyeditor.editors.editor - INFO - 37 editing: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is -> Alfgeir L Kristjansson  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is', 'target_new': 'Alfgeir L Kristjansson', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios.'}, 'post': {'rewrite_acc': [0.25], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   37 editing: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is -> Alfgeir L Kristjansson  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is', 'target_new': 'Alfgeir L Kristjansson', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios.'}, 'post': {'rewrite_acc': [0.25], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,842 - easyeditor.editors.editor - INFO - 38 editing: The name of the country of citizenship of Leonardo Vinhas Ciacci is -> Oman proper  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Leonardo Vinhas Ciacci is', 'target_new': 'Oman proper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Leonardo Vinhas Ciacci'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   38 editing: The name of the country of citizenship of Leonardo Vinhas Ciacci is -> Oman proper  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Leonardo Vinhas Ciacci is', 'target_new': 'Oman proper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Leonardo Vinhas Ciacci'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:24:38,904 - easyeditor.editors.editor - INFO - 39 editing: The gender of Phillip Hodson is -> intersex  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'The gender of Phillip Hodson is', 'target_new': 'intersex', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Phillip Hodson'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:24:38 - INFO - easyeditor.editors.editor -   39 editing: The gender of Phillip Hodson is -> intersex  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'The gender of Phillip Hodson is', 'target_new': 'intersex', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Phillip Hodson'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the mother of Stephana Warnock is] -> [ Sheila Mary Nolan]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the mother of Stephana Warnock is Sheila Mary N | Token: ck
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.607 = 5.607 + 0.0 + 0.0 avg prob of [ Sheila Mary Nolan] 0.0038164069410413504
loss 4.121 = 4.041 + 0.081 + 0.0 avg prob of [ Sheila Mary Nolan] 0.017668189480900764
loss 2.539 = 2.278 + 0.261 + 0.0 avg prob of [ Sheila Mary Nolan] 0.10279671847820282
loss 1.638 = 1.375 + 0.263 + 0.0 avg prob of [ Sheila Mary Nolan] 0.2534908056259155
loss 0.589 = 0.32 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.7290753126144409
loss 0.278 = 0.008 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9921392202377319
loss 0.277 = 0.006 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9939529895782471
loss 0.274 = 0.003 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9970394968986511
loss 0.273 = 0.003 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9972531199455261
loss 0.261 = 0.002 + 0.259 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9978387355804443
loss 1.313 = 1.07 + 0.243 + 0.0 avg prob of [ Sheila Mary Nolan] 0.34820589423179626
loss 0.277 = 0.005 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9946407079696655
loss 0.32 = 0.049 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9526904821395874
loss 0.282 = 0.011 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9890134334564209
loss 0.29 = 0.02 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.979956328868866
loss 0.308 = 0.038 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9627887606620789
loss 0.31 = 0.041 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9601114988327026
loss 0.289 = 0.02 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9798704385757446
loss 0.279 = 0.011 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9891979098320007
loss 0.276 = 0.008 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9919161796569824
loss 0.274 = 0.007 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9928478598594666
loss 0.273 = 0.007 + 0.266 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9933524131774902
loss 0.272 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.993818998336792
loss 0.271 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9943550825119019
loss 0.269 = 0.005 + 0.264 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9949434995651245
Init norm 10.451786041259766 | Delta norm 41.80714416503906 | Target norm 43.345272064208984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(41.8071, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2871, device='cuda:0')
upd norm tensor(2.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.4182, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3533, device='cuda:0')
upd norm tensor(2.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.4749, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6933, device='cuda:0')
upd norm tensor(2.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9427, device='cuda:0')
upd norm tensor(2.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.3619, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4336, device='cuda:0')
upd norm tensor(3.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Darren Finlay is] -> [ spaceship captain]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Darren Finlay is spaceship | Token: lay
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ spaceship captain] 0.0031509259715676308
loss 3.808 = 3.734 + 0.073 + 0.0 avg prob of [ spaceship captain] 0.02488766238093376
loss 2.243 = 1.958 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.14252355694770813
loss 0.729 = 0.443 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.6496155261993408
loss 0.309 = 0.02 + 0.289 + 0.0 avg prob of [ spaceship captain] 0.9803946018218994
loss 0.299 = 0.013 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9871116876602173
loss 0.291 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9952278137207031
loss 0.292 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9947180151939392
loss 0.29 = 0.003 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9966393709182739
loss 0.288 = 0.002 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9984142780303955
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9989546537399292
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9991535544395447
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999259889125824
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993330836296082
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993906021118164
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994384050369263
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994781017303467
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999510645866394
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995357394218445
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995522499084473
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995567798614502
loss 0.286 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999541699886322
loss 0.286 = 0.001 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.999482274055481
loss 0.284 = 0.001 + 0.283 + 0.0 avg prob of [ spaceship captain] 0.9992715120315552
loss 0.269 = 0.002 + 0.266 + 0.0 avg prob of [ spaceship captain] 0.9978246688842773
Init norm 11.212502479553223 | Delta norm 44.85000991821289 | Target norm 46.32301712036133


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8500, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3073, device='cuda:0')
upd norm tensor(2.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3681, device='cuda:0')
upd norm tensor(2.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.9594, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7088, device='cuda:0')
upd norm tensor(2.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4587, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9623, device='cuda:0')
upd norm tensor(2.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2282, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4749, device='cuda:0')
upd norm tensor(3.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Henry John Gepp is] -> [ bigender]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Henry John Gepp is big | Token: pp
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.613 = 8.613 + 0.0 + 0.0 avg prob of [ bigender] 0.00024923926685005426
loss 5.668 = 5.409 + 0.259 + 0.0 avg prob of [ bigender] 0.00471782311797142
loss 3.402 = 3.116 + 0.286 + 0.0 avg prob of [ bigender] 0.044810354709625244
loss 1.863 = 1.576 + 0.286 + 0.0 avg prob of [ bigender] 0.2090466022491455
loss 2.594 = 2.308 + 0.286 + 0.0 avg prob of [ bigender] 0.10035304725170135
loss 0.382 = 0.096 + 0.285 + 0.0 avg prob of [ bigender] 0.9083206057548523
loss 0.411 = 0.131 + 0.28 + 0.0 avg prob of [ bigender] 0.8777483701705933
loss 0.333 = 0.056 + 0.277 + 0.0 avg prob of [ bigender] 0.945836067199707
loss 0.298 = 0.018 + 0.28 + 0.0 avg prob of [ bigender] 0.9822215437889099
loss 0.291 = 0.008 + 0.283 + 0.0 avg prob of [ bigender] 0.9919554591178894
loss 0.289 = 0.005 + 0.284 + 0.0 avg prob of [ bigender] 0.9952031970024109
loss 0.288 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9965540766716003
loss 0.287 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9971374273300171
loss 0.284 = 0.003 + 0.281 + 0.0 avg prob of [ bigender] 0.9971071481704712
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ bigender] 0.9940347075462341
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9985091686248779
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9986342191696167
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998675525188446
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987055659294128
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998738169670105
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987771511077881
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988228678703308
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988745450973511
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989303350448608
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989882707595825
Init norm 11.56171703338623 | Delta norm 46.246864318847656 | Target norm 47.51656723022461


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.2469, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3295, device='cuda:0')
upd norm tensor(2.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.7641, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3870, device='cuda:0')
upd norm tensor(2.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.4596, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7276, device='cuda:0')
upd norm tensor(2.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4244, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9855, device='cuda:0')
upd norm tensor(2.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9834, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5289, device='cuda:0')
upd norm tensor(3.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by] -> [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles]
Computing right vector (v)
Lookup index found: 19 | Sentence: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by 1995/1996 German Badminton Championships U14 ‚Äì women's | Token: kg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.353 = 3.353 + 0.0 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.03520524501800537
loss 3.407 = 3.103 + 0.304 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.0450158566236496
loss 2.889 = 2.77 + 0.119 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.06274893879890442
loss 2.398 = 2.381 + 0.016 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.09277491271495819
loss 1.887 = 1.87 + 0.017 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.1548815369606018
loss 1.276 = 1.257 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.2849786877632141
loss 0.861 = 0.84 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.43282267451286316
loss 0.572 = 0.552 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.5766874551773071
loss 0.279 = 0.259 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.7725369334220886
loss 0.118 = 0.095 + 0.022 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9097639322280884
loss 0.068 = 0.042 + 0.026 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.959246039390564
loss 0.038 = 0.015 + 0.023 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9852155447006226
Init norm 13.64920425415039 | Delta norm 54.59681701660156 | Target norm 56.80078887939453


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(54.5968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3534, device='cuda:0')
upd norm tensor(2.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(52.0168, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4067, device='cuda:0')
upd norm tensor(2.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.4490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7474, device='cuda:0')
upd norm tensor(2.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.9326, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0112, device='cuda:0')
upd norm tensor(2.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.0892, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5791, device='cuda:0')
upd norm tensor(4.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the capital city of canton of Bagn√®res-de-Bigorre is] -> [ Knarvik]
Computing right vector (v)
Lookup index found: 18 | Sentence: The name of the capital city of canton of Bagn√®res-de-Bigorre is Knar | Token: re
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.458 = 8.458 + 0.0 + 0.0 avg prob of [ Knarvik] 0.00024466344621032476
loss 5.052 = 4.66 + 0.392 + 0.0 avg prob of [ Knarvik] 0.009621738456189632
loss 4.534 = 4.159 + 0.375 + 0.0 avg prob of [ Knarvik] 0.017060158774256706
loss 1.635 = 1.228 + 0.407 + 0.0 avg prob of [ Knarvik] 0.29709187150001526
loss 0.486 = 0.079 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9242154955863953
loss 0.42 = 0.013 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9867501258850098
loss 0.418 = 0.011 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9892411231994629
loss 0.42 = 0.013 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9866708517074585
loss 0.422 = 0.015 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9847845435142517
loss 0.418 = 0.012 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9878983497619629
loss 0.414 = 0.008 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9916070699691772
loss 0.412 = 0.006 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9935588836669922
loss 0.41 = 0.006 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9943916201591492
loss 0.41 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9947823882102966
loss 0.409 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9950642585754395
loss 0.408 = 0.005 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9953522086143494
loss 0.408 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9956467151641846
loss 0.407 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9959076642990112
loss 0.406 = 0.004 + 0.402 + 0.0 avg prob of [ Knarvik] 0.9960910677909851
loss 0.406 = 0.004 + 0.401 + 0.0 avg prob of [ Knarvik] 0.9961570501327515
loss 0.405 = 0.004 + 0.4 + 0.0 avg prob of [ Knarvik] 0.9960526823997498
loss 0.403 = 0.004 + 0.398 + 0.0 avg prob of [ Knarvik] 0.9956769943237305
loss 0.4 = 0.005 + 0.395 + 0.0 avg prob of [ Knarvik] 0.9947869181632996
loss 0.395 = 0.007 + 0.387 + 0.0 avg prob of [ Knarvik] 0.9926511645317078
loss 0.381 = 0.014 + 0.367 + 0.0 avg prob of [ Knarvik] 0.9862655997276306
Init norm 13.75742244720459 | Delta norm 55.02968978881836 | Target norm 57.197044372558594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.0297, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3776, device='cuda:0')
upd norm tensor(2.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.2903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4289, device='cuda:0')
upd norm tensor(2.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.2762, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7725, device='cuda:0')
upd norm tensor(2.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.0288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0435, device='cuda:0')
upd norm tensor(3.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.4549, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6389, device='cuda:0')
upd norm tensor(4.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Nicol√°s M√©ndez Casariego is] -> [ Tharangambadi]
Computing right vector (v)
Lookup index found: 13 | Sentence: The place of birth of Nicol√°s M√©ndez Casariego is Tharangamb | Token: iego
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.212 = 5.212 + 0.0 + 0.0 avg prob of [ Tharangambadi] 0.005583751946687698
loss 2.071 = 1.94 + 0.131 + 0.0 avg prob of [ Tharangambadi] 0.1442318558692932
loss 2.016 = 1.969 + 0.047 + 0.0 avg prob of [ Tharangambadi] 0.14092321693897247
loss 0.977 = 0.745 + 0.232 + 0.0 avg prob of [ Tharangambadi] 0.47648951411247253
loss 0.247 = 0.137 + 0.109 + 0.0 avg prob of [ Tharangambadi] 0.8725411295890808
loss 0.073 = 0.022 + 0.051 + 0.0 avg prob of [ Tharangambadi] 0.978609025478363
loss 0.073 = 0.014 + 0.059 + 0.0 avg prob of [ Tharangambadi] 0.9862703680992126
loss 0.057 = 0.009 + 0.048 + 0.0 avg prob of [ Tharangambadi] 0.9914528727531433
loss 0.057 = 0.006 + 0.05 + 0.0 avg prob of [ Tharangambadi] 0.9935469031333923
loss 0.051 = 0.006 + 0.045 + 0.0 avg prob of [ Tharangambadi] 0.9944161772727966
loss 0.051 = 0.005 + 0.046 + 0.0 avg prob of [ Tharangambadi] 0.9949017763137817
loss 0.049 = 0.005 + 0.044 + 0.0 avg prob of [ Tharangambadi] 0.99549400806427
Init norm 11.820267677307129 | Delta norm 47.281070709228516 | Target norm 49.48406982421875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4101, device='cuda:0')
upd norm tensor(2.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.0030, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4570, device='cuda:0')
upd norm tensor(2.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9796, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7993, device='cuda:0')
upd norm tensor(2.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7175, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0801, device='cuda:0')
upd norm tensor(2.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.7751, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6996, device='cuda:0')
upd norm tensor(3.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Thomas Phillipps Lamb is] -> [ deputy high court judge]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Thomas Phillipps Lamb is deputy high court | Token: Lamb
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.536 = 4.536 + 0.0 + 0.0 avg prob of [ deputy high court judge] 0.011187071911990643
loss 2.153 = 1.905 + 0.248 + 0.0 avg prob of [ deputy high court judge] 0.1506791114807129
loss 2.517 = 2.2 + 0.316 + 0.0 avg prob of [ deputy high court judge] 0.11348851025104523
loss 1.484 = 1.217 + 0.267 + 0.0 avg prob of [ deputy high court judge] 0.2975485026836395
loss 0.316 = 0.056 + 0.259 + 0.0 avg prob of [ deputy high court judge] 0.9452149868011475
loss 0.219 = 0.161 + 0.057 + 0.0 avg prob of [ deputy high court judge] 0.8546231985092163
loss 0.287 = 0.013 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9872293472290039
loss 0.28 = 0.005 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9951062202453613
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.996562659740448
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9971231818199158
loss 0.277 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9974326491355896
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9976330995559692
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9977788329124451
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.997896671295166
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9980010986328125
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981006979942322
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981997013092041
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9982994794845581
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9983994364738464
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9984978437423706
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9985925555229187
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9986819624900818
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9987648725509644
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9988407492637634
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9989093542098999
Init norm 11.668208122253418 | Delta norm 46.67283248901367 | Target norm 47.940155029296875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4355, device='cuda:0')
upd norm tensor(2.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2678, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4781, device='cuda:0')
upd norm tensor(2.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9152, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8203, device='cuda:0')
upd norm tensor(2.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6206, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1043, device='cuda:0')
upd norm tensor(2.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5778, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(3.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Yoshida Keigo is] -> [ intersex organism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Yoshida Keigo is intersex organ | Token: igo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.154 = 6.154 + 0.0 + 0.0 avg prob of [ intersex organism] 0.002235337160527706
loss 4.674 = 4.436 + 0.238 + 0.0 avg prob of [ intersex organism] 0.012196492403745651
loss 2.694 = 2.457 + 0.237 + 0.0 avg prob of [ intersex organism] 0.08594139665365219
loss 1.409 = 1.173 + 0.236 + 0.0 avg prob of [ intersex organism] 0.3106464147567749
loss 0.299 = 0.066 + 0.233 + 0.0 avg prob of [ intersex organism] 0.9358271360397339
loss 0.278 = 0.039 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9619175791740417
loss 0.242 = 0.005 + 0.237 + 0.0 avg prob of [ intersex organism] 0.994818389415741
loss 0.24 = 0.002 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9979938268661499
loss 0.24 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.998679518699646
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9989312887191772
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990383982658386
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990581274032593
loss 0.238 = 0.001 + 0.237 + 0.0 avg prob of [ intersex organism] 0.9989722967147827
loss 0.236 = 0.001 + 0.234 + 0.0 avg prob of [ intersex organism] 0.9986181259155273
loss 0.22 = 0.004 + 0.217 + 0.0 avg prob of [ intersex organism] 0.9964985251426697
loss 0.338 = 0.201 + 0.137 + 0.0 avg prob of [ intersex organism] 0.8238176107406616
loss 0.24 = 0.001 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9993938207626343
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9979710578918457
loss 0.249 = 0.011 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9895128607749939
loss 0.268 = 0.03 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9707574248313904
loss 0.254 = 0.015 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9848440885543823
loss 0.245 = 0.007 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9933988451957703
loss 0.243 = 0.004 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9958910942077637
loss 0.242 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9967593550682068
loss 0.241 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.997196614742279
Init norm 12.686749458312988 | Delta norm 50.74699783325195 | Target norm 52.94290542602539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7470, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4567, device='cuda:0')
upd norm tensor(2.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7230, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4976, device='cuda:0')
upd norm tensor(2.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.6228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8382, device='cuda:0')
upd norm tensor(2.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9657, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1283, device='cuda:0')
upd norm tensor(2.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.4189, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8053, device='cuda:0')
upd norm tensor(3.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [2041 BC follows] -> [ 29668 Ipf]
Computing right vector (v)
Lookup index found: 6 | Sentence: 2041 BC follows 29668 I | Token: BC
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.78 = 6.78 + 0.0 + 0.0 avg prob of [ 29668 Ipf] 0.0011842688545584679
loss 5.645 = 5.42 + 0.225 + 0.0 avg prob of [ 29668 Ipf] 0.004440009593963623
loss 4.847 = 4.718 + 0.129 + 0.0 avg prob of [ 29668 Ipf] 0.00958884134888649
loss 3.992 = 3.855 + 0.137 + 0.0 avg prob of [ 29668 Ipf] 0.02176203392446041
loss 2.709 = 2.553 + 0.155 + 0.0 avg prob of [ 29668 Ipf] 0.08010239899158478
loss 1.658 = 1.493 + 0.164 + 0.0 avg prob of [ 29668 Ipf] 0.22878196835517883
loss 0.859 = 0.706 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.5008167624473572
loss 0.467 = 0.314 + 0.153 + 0.0 avg prob of [ 29668 Ipf] 0.7312717437744141
loss 0.305 = 0.153 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.8584901094436646
loss 0.217 = 0.059 + 0.157 + 0.0 avg prob of [ 29668 Ipf] 0.9424829483032227
loss 0.176 = 0.019 + 0.156 + 0.0 avg prob of [ 29668 Ipf] 0.9809708595275879
loss 0.168 = 0.009 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9908093810081482
loss 0.165 = 0.006 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9937031269073486
loss 0.163 = 0.004 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9961495399475098
loss 0.162 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9975597858428955
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9981834292411804
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9985010027885437
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9986904859542847
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9988631010055542
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9990620613098145
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9992455244064331
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9993878602981567
loss 0.159 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9994925856590271
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9995701313018799
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.999629020690918
Init norm 12.345292091369629 | Delta norm 49.38117218017578 | Target norm 51.165740966796875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3812, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4836, device='cuda:0')
upd norm tensor(2.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.5944, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5201, device='cuda:0')
upd norm tensor(2.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.3130, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8602, device='cuda:0')
upd norm tensor(2.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.6083, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1596, device='cuda:0')
upd norm tensor(2.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.2423, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8637, device='cuda:0')
upd norm tensor(3.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1981 Lithuanian Badminton Championships ‚Äì women's singles follows] -> [ Loschge, Friedrich Heinrich]
Computing right vector (v)
Lookup index found: 17 | Sentence: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows Loschge, Friedrich | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.49 = 8.49 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.00022668617020826787
loss 6.503 = 6.296 + 0.207 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0019449219107627869
loss 5.135 = 5.135 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0066849044524133205
loss 3.276 = 2.881 + 0.395 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.056303467601537704
loss 1.624 = 1.617 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.20898878574371338
loss 0.604 = 0.601 + 0.003 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.568875253200531
loss 0.294 = 0.285 + 0.009 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.7627280950546265
loss 0.136 = 0.091 + 0.044 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9188784956932068
loss 0.136 = 0.057 + 0.078 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9482223391532898
loss 0.101 = 0.077 + 0.023 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9353789687156677
loss 0.105 = 0.097 + 0.008 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9234482049942017
loss 0.106 = 0.099 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9230228662490845
loss 0.097 = 0.083 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9329265356063843
loss 0.098 = 0.063 + 0.035 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9468004107475281
loss 0.101 = 0.058 + 0.042 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9499897360801697
loss 0.094 = 0.073 + 0.02 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.939834475517273
loss 0.097 = 0.086 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9318189024925232
loss 0.096 = 0.085 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9324424266815186
loss 0.093 = 0.073 + 0.019 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9400944709777832
loss 0.095 = 0.062 + 0.032 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9475826621055603
loss 0.094 = 0.064 + 0.03 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9465584754943848
loss 0.092 = 0.074 + 0.018 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9399330019950867
loss 0.094 = 0.08 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9359598159790039
loss 0.093 = 0.077 + 0.015 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9377471804618835
loss 0.092 = 0.069 + 0.022 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9431607127189636
Init norm 14.525349617004395 | Delta norm 58.10139846801758 | Target norm 59.97038650512695


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(58.1014, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5071, device='cuda:0')
upd norm tensor(2.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5289, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5397, device='cuda:0')
upd norm tensor(2.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(49.7651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8816, device='cuda:0')
upd norm tensor(2.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(42.7677, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1878, device='cuda:0')
upd norm tensor(3.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(33.3730, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.9184, device='cuda:0')
upd norm tensor(4.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Anna Sophie Gasteiger is] -> [ mƒÅh≈´]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Anna Sophie Gasteiger is mƒÅh | Token: iger
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.405 = 7.405 + 0.0 + 0.0 avg prob of [ mƒÅh≈´] 0.0006433886010199785
loss 4.965 = 4.676 + 0.289 + 0.0 avg prob of [ mƒÅh≈´] 0.00943743996322155
loss 3.815 = 3.524 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.030633440241217613
loss 2.935 = 2.651 + 0.284 + 0.0 avg prob of [ mƒÅh≈´] 0.07068447023630142
loss 2.146 = 1.867 + 0.278 + 0.0 avg prob of [ mƒÅh≈´] 0.1552438586950302
loss 1.009 = 0.732 + 0.276 + 0.0 avg prob of [ mƒÅh≈´] 0.48104676604270935
loss 0.567 = 0.275 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.7600362300872803
loss 0.399 = 0.107 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.8993332386016846
loss 0.346 = 0.055 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.9462100863456726
loss 0.333 = 0.043 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.9579676389694214
loss 0.31 = 0.022 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9777737855911255
loss 0.276 = 0.025 + 0.25 + 0.0 avg prob of [ mƒÅh≈´] 0.9750882983207703
loss 0.759 = 0.63 + 0.128 + 0.0 avg prob of [ mƒÅh≈´] 0.5337220430374146
loss 0.274 = 0.041 + 0.232 + 0.0 avg prob of [ mƒÅh≈´] 0.9595615267753601
loss 0.299 = 0.023 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.977741003036499
loss 0.313 = 0.028 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9727442264556885
loss 0.306 = 0.018 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9822020530700684
loss 0.299 = 0.011 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9888372421264648
loss 0.296 = 0.008 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9917187094688416
loss 0.294 = 0.007 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9931774139404297
loss 0.292 = 0.006 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9939765334129333
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ mƒÅh≈´] 0.9942785501480103
loss 0.283 = 0.006 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.9938420057296753
loss 0.274 = 0.009 + 0.265 + 0.0 avg prob of [ mƒÅh≈´] 0.9915284514427185
loss 0.259 = 0.017 + 0.242 + 0.0 avg prob of [ mƒÅh≈´] 0.9831792712211609
Init norm 12.60416030883789 | Delta norm 50.41664123535156 | Target norm 52.078067779541016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.4166, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5367, device='cuda:0')
upd norm tensor(2.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7990, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5681, device='cuda:0')
upd norm tensor(2.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.2389, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9104, device='cuda:0')
upd norm tensor(2.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.3852, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2290, device='cuda:0')
upd norm tensor(2.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0085, device='cuda:0')
upd norm tensor(3.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jae-Duk Han is] -> [ bigender]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Jae-Duk Han is big | Token: Han
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.68 = 8.68 + 0.0 + 0.0 avg prob of [ bigender] 0.00020638955174945295
loss 5.637 = 5.468 + 0.168 + 0.0 avg prob of [ bigender] 0.004985661245882511
loss 3.601 = 3.265 + 0.335 + 0.0 avg prob of [ bigender] 0.03895954787731171
loss 1.156 = 0.82 + 0.336 + 0.0 avg prob of [ bigender] 0.44149231910705566
loss 0.783 = 0.446 + 0.336 + 0.0 avg prob of [ bigender] 0.6658896803855896
loss 0.361 = 0.021 + 0.34 + 0.0 avg prob of [ bigender] 0.979139506816864
loss 0.455 = 0.119 + 0.336 + 0.0 avg prob of [ bigender] 0.8885301351547241
loss 0.361 = 0.025 + 0.336 + 0.0 avg prob of [ bigender] 0.9757952690124512
loss 0.34 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9957816004753113
loss 0.339 = 0.004 + 0.335 + 0.0 avg prob of [ bigender] 0.996435821056366
loss 0.338 = 0.004 + 0.334 + 0.0 avg prob of [ bigender] 0.9957695007324219
loss 0.337 = 0.004 + 0.333 + 0.0 avg prob of [ bigender] 0.9957097768783569
loss 0.335 = 0.004 + 0.331 + 0.0 avg prob of [ bigender] 0.996068000793457
loss 0.331 = 0.004 + 0.327 + 0.0 avg prob of [ bigender] 0.9960777163505554
loss 0.303 = 0.007 + 0.296 + 0.0 avg prob of [ bigender] 0.9933030605316162
loss 0.606 = 0.383 + 0.223 + 0.0 avg prob of [ bigender] 0.7007762789726257
loss 0.337 = 0.001 + 0.336 + 0.0 avg prob of [ bigender] 0.9991363286972046
loss 0.345 = 0.008 + 0.336 + 0.0 avg prob of [ bigender] 0.9918235540390015
loss 0.374 = 0.038 + 0.336 + 0.0 avg prob of [ bigender] 0.9630802869796753
loss 0.388 = 0.051 + 0.336 + 0.0 avg prob of [ bigender] 0.9502453804016113
loss 0.361 = 0.024 + 0.336 + 0.0 avg prob of [ bigender] 0.9763194918632507
loss 0.346 = 0.009 + 0.336 + 0.0 avg prob of [ bigender] 0.9907026290893555
loss 0.342 = 0.005 + 0.336 + 0.0 avg prob of [ bigender] 0.9948294162750244
loss 0.341 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9960918426513672
loss 0.34 = 0.003 + 0.336 + 0.0 avg prob of [ bigender] 0.9966716766357422
Init norm 10.899991035461426 | Delta norm 43.5999641418457 | Target norm 45.193443298339844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.6000, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5658, device='cuda:0')
upd norm tensor(2.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.8688, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5918, device='cuda:0')
upd norm tensor(2.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.7623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9320, device='cuda:0')
upd norm tensor(2.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.9333, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2587, device='cuda:0')
upd norm tensor(2.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.4764, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0673, device='cuda:0')
upd norm tensor(3.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of death of Ray Wietecha is] -> [ Sta√üfurt]
Computing right vector (v)
Lookup index found: 10 | Sentence: The place of death of Ray Wietecha is Sta√ü | Token: a
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.11 = 8.11 + 0.0 + 0.0 avg prob of [ Sta√üfurt] 0.00032989942701533437
loss 6.402 = 6.284 + 0.118 + 0.0 avg prob of [ Sta√üfurt] 0.0019462056225165725
loss 5.162 = 4.853 + 0.309 + 0.0 avg prob of [ Sta√üfurt] 0.008369509130716324
loss 3.768 = 3.456 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.03495211526751518
loss 1.646 = 1.333 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.27931803464889526
loss 0.441 = 0.125 + 0.316 + 0.0 avg prob of [ Sta√üfurt] 0.8839200735092163
loss 0.354 = 0.041 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9601842761039734
loss 0.327 = 0.014 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.986103892326355
loss 0.32 = 0.006 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9937331080436707
loss 0.317 = 0.004 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9962098002433777
loss 0.316 = 0.003 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9972167015075684
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.997802197933197
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9982465505599976
loss 0.315 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9985891580581665
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9988359808921814
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9990048408508301
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.999117374420166
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9991900324821472
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9992321729660034
loss 0.314 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.9992437362670898
loss 0.313 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.999208927154541
loss 0.312 = 0.001 + 0.311 + 0.0 avg prob of [ Sta√üfurt] 0.9990455508232117
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9979442358016968
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9976019859313965
loss 0.314 = 0.0 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9995888471603394
Init norm 10.969701766967773 | Delta norm 43.878807067871094 | Target norm 45.10775375366211


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.8788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5856, device='cuda:0')
upd norm tensor(2.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.3918, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6083, device='cuda:0')
upd norm tensor(2.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.3447, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9485, device='cuda:0')
upd norm tensor(2.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(31.6848, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2807, device='cuda:0')
upd norm tensor(2.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.0379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1120, device='cuda:0')
upd norm tensor(3.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is] -> [ Russian State]
Computing right vector (v)
Lookup index found: 30 | Sentence: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is Russian | Token: doubles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.626 = 9.626 + 0.0 + 0.0 avg prob of [ Russian State] 0.0001487217377871275
loss 7.566 = 6.693 + 0.873 + 0.0 avg prob of [ Russian State] 0.0013882662169635296
loss 2.976 = 2.613 + 0.363 + 0.0 avg prob of [ Russian State] 0.07479877024888992
loss 2.423 = 2.421 + 0.002 + 0.0 avg prob of [ Russian State] 0.0907687395811081
loss 1.257 = 1.251 + 0.005 + 0.0 avg prob of [ Russian State] 0.28735417127609253
loss 0.474 = 0.429 + 0.046 + 0.0 avg prob of [ Russian State] 0.6543459296226501
loss 0.14 = 0.116 + 0.024 + 0.0 avg prob of [ Russian State] 0.8908494710922241
loss 0.068 = 0.042 + 0.025 + 0.0 avg prob of [ Russian State] 0.9586191177368164
loss 0.054 = 0.023 + 0.031 + 0.0 avg prob of [ Russian State] 0.9769591093063354
loss 0.053 = 0.019 + 0.034 + 0.0 avg prob of [ Russian State] 0.981724202632904
loss 0.048 = 0.015 + 0.033 + 0.0 avg prob of [ Russian State] 0.9849858283996582
Init norm 33.36102294921875 | Delta norm 127.69489288330078 | Target norm 134.28440856933594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(127.6949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.6075, device='cuda:0')
upd norm tensor(5.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(120.0359, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6264, device='cuda:0')
upd norm tensor(6.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(106.8882, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9650, device='cuda:0')
upd norm tensor(6.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(89.1822, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.3029, device='cuda:0')
upd norm tensor(6.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(67.0065, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1598, device='cuda:0')
upd norm tensor(9.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 81st Missouri General Assembly is associated with is] -> [ Ostikanate of Arminiya]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which 81st Missouri General Assembly is associated with is Ostikanate of Armini | Token: Assembly
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.707 = 7.707 + 0.0 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.00048599415458738804
loss 7.336 = 6.999 + 0.337 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0009601075435057282
loss 6.435 = 6.266 + 0.169 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0019966831896454096
loss 5.049 = 4.923 + 0.125 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.007588856853544712
loss 3.134 = 3.06 + 0.074 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.047306403517723083
loss 1.545 = 1.467 + 0.077 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.23186489939689636
loss 0.403 = 0.304 + 0.099 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.7414726614952087
loss 0.138 = 0.059 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9431867003440857
loss 0.11 = 0.03 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9708948135375977
loss 0.089 = 0.008 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9915426969528198
loss 0.084 = 0.004 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9959759712219238
loss 0.083 = 0.003 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9974373579025269
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9981023669242859
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9984511733055115
loss 0.081 = 0.001 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.998671293258667
loss 0.081 = 0.001 + 0.079 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9988362193107605
loss 0.079 = 0.001 + 0.078 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9989756345748901
loss 0.037 = 0.001 + 0.035 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9991167783737183
Init norm 12.339568138122559 | Delta norm 49.3582763671875 | Target norm 50.52494812011719


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3583, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7519, device='cuda:0')
upd norm tensor(2.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.2671, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.7815, device='cuda:0')
upd norm tensor(2.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.0074, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1257, device='cuda:0')
upd norm tensor(2.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.5179, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.4959, device='cuda:0')
upd norm tensor(2.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.5396, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5267, device='cuda:0')
upd norm tensor(3.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Juliette K Berg is] -> [ male]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Juliette K Berg is | Token: Berg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.927 = 4.927 + 0.0 + 0.0 avg prob of [ male] 0.013017235323786736
loss 1.62 = 1.288 + 0.332 + 0.0 avg prob of [ male] 0.2843583822250366
loss 0.446 = 0.112 + 0.333 + 0.0 avg prob of [ male] 0.8939832448959351
loss 0.373 = 0.101 + 0.271 + 0.0 avg prob of [ male] 0.9038752317428589
loss 0.343 = 0.121 + 0.221 + 0.0 avg prob of [ male] 0.8865127563476562
loss 0.274 = 0.043 + 0.23 + 0.0 avg prob of [ male] 0.9577230215072632
loss 0.2 = 0.031 + 0.169 + 0.0 avg prob of [ male] 0.9693690538406372
loss 0.165 = 0.023 + 0.142 + 0.0 avg prob of [ male] 0.9775354266166687
loss 0.147 = 0.016 + 0.131 + 0.0 avg prob of [ male] 0.9842368960380554
loss 0.144 = 0.011 + 0.132 + 0.0 avg prob of [ male] 0.9890469908714294
loss 0.142 = 0.008 + 0.134 + 0.0 avg prob of [ male] 0.9921433329582214
loss 0.14 = 0.006 + 0.133 + 0.0 avg prob of [ male] 0.9940770864486694
loss 0.135 = 0.005 + 0.13 + 0.0 avg prob of [ male] 0.9953163862228394
loss 0.128 = 0.004 + 0.124 + 0.0 avg prob of [ male] 0.9961462020874023
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9967252612113953
loss 0.117 = 0.003 + 0.114 + 0.0 avg prob of [ male] 0.9971455335617065
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9974682331085205
loss 0.118 = 0.002 + 0.116 + 0.0 avg prob of [ male] 0.9977153539657593
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9979001879692078
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9980413317680359
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9981523752212524
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9982445240020752
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9983258247375488
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.9984009265899658
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.998471736907959
Init norm 11.058765411376953 | Delta norm 44.23506164550781 | Target norm 45.5366325378418


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.2351, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7751, device='cuda:0')
upd norm tensor(2.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.3903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8017, device='cuda:0')
upd norm tensor(2.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.4831, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1461, device='cuda:0')
upd norm tensor(2.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.9040, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5236, device='cuda:0')
upd norm tensor(2.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3948, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5882, device='cuda:0')
upd norm tensor(3.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Naniwaman is] -> [ cardinal-deacon]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Naniwaman is cardinal-de | Token: aman
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.446 = 6.446 + 0.0 + 0.0 avg prob of [ cardinal-deacon] 0.0016523947706446052
loss 3.906 = 3.669 + 0.237 + 0.0 avg prob of [ cardinal-deacon] 0.026458226144313812
loss 1.329 = 1.095 + 0.233 + 0.0 avg prob of [ cardinal-deacon] 0.33627554774284363
loss 0.328 = 0.087 + 0.241 + 0.0 avg prob of [ cardinal-deacon] 0.9199651479721069
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9971021413803101
loss 0.25 = 0.006 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9944992065429688
loss 0.248 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9968565702438354
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9981937408447266
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9987187385559082
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9990100264549255
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9992170333862305
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9993748068809509
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9994933605194092
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9995803833007812
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996436834335327
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996897578239441
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997234344482422
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997481107711792
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997661113739014
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997789263725281
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997875094413757
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997925758361816
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997941851615906
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997922778129578
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.999786376953125
Init norm 11.370737075805664 | Delta norm 45.482948303222656 | Target norm 47.17446517944336


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.4829, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7972, device='cuda:0')
upd norm tensor(2.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.2449, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8190, device='cuda:0')
upd norm tensor(2.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.4106, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1628, device='cuda:0')
upd norm tensor(2.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3344, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5459, device='cuda:0')
upd norm tensor(2.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.7681, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6391, device='cuda:0')
upd norm tensor(3.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Divina Eterna Cardoso is] -> [ takatƒÅpui]
Computing right vector (v)
Lookup index found: 10 | Sentence: The gender of Divina Eterna Cardoso is takatƒÅp | Token: oso
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.127 = 5.127 + 0.0 + 0.0 avg prob of [ takatƒÅpui] 0.006581449415534735
loss 3.584 = 3.313 + 0.272 + 0.0 avg prob of [ takatƒÅpui] 0.03731798380613327
loss 1.992 = 1.714 + 0.278 + 0.0 avg prob of [ takatƒÅpui] 0.18343767523765564
loss 1.092 = 0.823 + 0.269 + 0.0 avg prob of [ takatƒÅpui] 0.4407960772514343
loss 0.334 = 0.039 + 0.294 + 0.0 avg prob of [ takatƒÅpui] 0.9613143801689148
loss 0.289 = 0.008 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.9920060038566589
loss 0.29 = 0.009 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.991512656211853
loss 0.29 = 0.008 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9920692443847656
loss 0.287 = 0.005 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9946774244308472
loss 0.285 = 0.003 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9966756105422974
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9977490901947021
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9983119964599609
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998626172542572
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9988164901733398
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998940646648407
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9990249872207642
loss 0.283 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9990801215171814
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9991041421890259
loss 0.281 = 0.001 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.9990624189376831
loss 0.265 = 0.002 + 0.263 + 0.0 avg prob of [ takatƒÅpui] 0.9984075427055359
loss 0.937 = 0.592 + 0.345 + 0.0 avg prob of [ takatƒÅpui] 0.5611640810966492
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9986989498138428
loss 0.315 = 0.033 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9676880836486816
loss 0.456 = 0.175 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.8415685892105103
loss 0.288 = 0.008 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.99164217710495
Init norm 11.80569076538086 | Delta norm 47.22276306152344 | Target norm 49.668312072753906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8208, device='cuda:0')
upd norm tensor(2.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6906, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8379, device='cuda:0')
upd norm tensor(2.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.0051, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1803, device='cuda:0')
upd norm tensor(2.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.8471, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5685, device='cuda:0')
upd norm tensor(2.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.7429, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6846, device='cuda:0')
upd norm tensor(3.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Michael S German is] -> [ planetary geologist]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Michael S German is planetary ge | Token: German
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.725 = 3.725 + 0.0 + 0.0 avg prob of [ planetary geologist] 0.02517147921025753
loss 2.641 = 2.434 + 0.207 + 0.0 avg prob of [ planetary geologist] 0.08804760873317719
loss 1.806 = 1.598 + 0.208 + 0.0 avg prob of [ planetary geologist] 0.20411810278892517
loss 0.466 = 0.257 + 0.209 + 0.0 avg prob of [ planetary geologist] 0.7757920622825623
loss 0.268 = 0.056 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.946293830871582
loss 0.225 = 0.014 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9861539602279663
loss 0.215 = 0.004 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9958369135856628
loss 0.213 = 0.002 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9978756904602051
loss 0.213 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9985741376876831
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9989117383956909
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9991071224212646
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9992337226867676
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993224143981934
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993886351585388
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994404315948486
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994828104972839
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995183944702148
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995490908622742
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995759725570679
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995998740196228
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996213912963867
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996408224105835
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996585845947266
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996747970581055
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996895790100098
Init norm 11.96147632598877 | Delta norm 47.845909118652344 | Target norm 49.5956916809082


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.8459, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8457, device='cuda:0')
upd norm tensor(2.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.3819, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8558, device='cuda:0')
upd norm tensor(2.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9616, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1976, device='cuda:0')
upd norm tensor(2.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9249, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5913, device='cuda:0')
upd norm tensor(2.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7357, device='cuda:0')
upd norm tensor(3.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [Lange, Reinerus follows] -> [ 1971 Western Australian state election]
Computing right vector (v)
Lookup index found: 6 | Sentence: Lange, Reinerus follows 1971 Western Australian state | Token: us
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.31 = 4.31 + 0.0 + 0.0 avg prob of [ 1971 Western Australian state election] 0.013672824017703533
loss 3.36 = 3.284 + 0.075 + 0.0 avg prob of [ 1971 Western Australian state election] 0.038747385144233704
loss 3.313 = 2.925 + 0.388 + 0.0 avg prob of [ 1971 Western Australian state election] 0.05619245022535324
loss 2.037 = 1.943 + 0.094 + 0.0 avg prob of [ 1971 Western Australian state election] 0.144039586186409
loss 0.989 = 0.964 + 0.024 + 0.0 avg prob of [ 1971 Western Australian state election] 0.3823893964290619
loss 0.371 = 0.343 + 0.027 + 0.0 avg prob of [ 1971 Western Australian state election] 0.7097872495651245
loss 0.085 = 0.059 + 0.026 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9426312446594238
loss 0.037 = 0.012 + 0.025 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9884194731712341
Init norm 12.124625205993652 | Delta norm 48.49850082397461 | Target norm 50.35892105102539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.4985, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8699, device='cuda:0')
upd norm tensor(2.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.5661, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8746, device='cuda:0')
upd norm tensor(2.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.2362, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2167, device='cuda:0')
upd norm tensor(2.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7111, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6180, device='cuda:0')
upd norm tensor(2.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.9511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7972, device='cuda:0')
upd norm tensor(3.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mark Van Guilder is] -> [ slam poetry]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Mark Van Guilder is slam | Token: ilder
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.384 = 5.384 + 0.0 + 0.0 avg prob of [ slam poetry] 0.004766244441270828
loss 3.037 = 2.797 + 0.24 + 0.0 avg prob of [ slam poetry] 0.06143198907375336
loss 1.79 = 1.543 + 0.247 + 0.0 avg prob of [ slam poetry] 0.22275714576244354
loss 0.299 = 0.047 + 0.252 + 0.0 avg prob of [ slam poetry] 0.9550265073776245
loss 0.269 = 0.017 + 0.252 + 0.0 avg prob of [ slam poetry] 0.9836425185203552
loss 0.26 = 0.009 + 0.251 + 0.0 avg prob of [ slam poetry] 0.9912114143371582
loss 0.252 = 0.007 + 0.246 + 0.0 avg prob of [ slam poetry] 0.9935025572776794
loss 0.246 = 0.012 + 0.233 + 0.0 avg prob of [ slam poetry] 0.9878050088882446
loss 0.244 = 0.003 + 0.24 + 0.0 avg prob of [ slam poetry] 0.9967028498649597
loss 0.234 = 0.003 + 0.231 + 0.0 avg prob of [ slam poetry] 0.9971213340759277
loss 0.249 = 0.007 + 0.242 + 0.0 avg prob of [ slam poetry] 0.9935046434402466
loss 0.233 = 0.003 + 0.23 + 0.0 avg prob of [ slam poetry] 0.9974972605705261
loss 0.217 = 0.004 + 0.213 + 0.0 avg prob of [ slam poetry] 0.9963415861129761
loss 0.175 = 0.017 + 0.158 + 0.0 avg prob of [ slam poetry] 0.9836593866348267
loss 0.173 = 0.035 + 0.138 + 0.0 avg prob of [ slam poetry] 0.9659066200256348
loss 0.122 = 0.015 + 0.106 + 0.0 avg prob of [ slam poetry] 0.9851416349411011
loss 0.084 = 0.012 + 0.072 + 0.0 avg prob of [ slam poetry] 0.9878368377685547
loss 0.057 = 0.013 + 0.044 + 0.0 avg prob of [ slam poetry] 0.9874358177185059
loss 0.044 = 0.01 + 0.034 + 0.0 avg prob of [ slam poetry] 0.990354061126709
Init norm 12.439826965332031 | Delta norm 49.759307861328125 | Target norm 51.69750213623047


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.7593, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8955, device='cuda:0')
upd norm tensor(2.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.8694, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8955, device='cuda:0')
upd norm tensor(2.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.8197, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2376, device='cuda:0')
upd norm tensor(2.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9136, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6441, device='cuda:0')
upd norm tensor(2.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.3955, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.8502, device='cuda:0')
upd norm tensor(3.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the employer of Momodou W Jallow is] -> [ Athersys]
Computing right vector (v)
Lookup index found: 14 | Sentence: The name of the employer of Momodou W Jallow is Athers | Token: allow
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.385 = 5.385 + 0.0 + 0.0 avg prob of [ Athersys] 0.004730091895908117
loss 3.802 = 3.556 + 0.246 + 0.0 avg prob of [ Athersys] 0.02869408391416073
loss 2.993 = 2.75 + 0.243 + 0.0 avg prob of [ Athersys] 0.06412670016288757
loss 1.79 = 1.547 + 0.242 + 0.0 avg prob of [ Athersys] 0.21574360132217407
loss 0.348 = 0.111 + 0.237 + 0.0 avg prob of [ Athersys] 0.8961483240127563
loss 0.368 = 0.13 + 0.237 + 0.0 avg prob of [ Athersys] 0.8835222721099854
loss 0.251 = 0.006 + 0.244 + 0.0 avg prob of [ Athersys] 0.9935626983642578
loss 0.256 = 0.012 + 0.244 + 0.0 avg prob of [ Athersys] 0.9879190325737
loss 0.26 = 0.015 + 0.244 + 0.0 avg prob of [ Athersys] 0.9848731756210327
loss 0.254 = 0.01 + 0.244 + 0.0 avg prob of [ Athersys] 0.990190863609314
loss 0.249 = 0.005 + 0.244 + 0.0 avg prob of [ Athersys] 0.9948327541351318
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ Athersys] 0.997098445892334
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ Athersys] 0.9981780052185059
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9987430572509766
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9990692138671875
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9992728233337402
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9994084239006042
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.999503493309021
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9995729327201843
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996254444122314
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996663928031921
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996992349624634
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997259974479675
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997484087944031
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997674226760864
Init norm 12.712177276611328 | Delta norm 50.84870910644531 | Target norm 52.761817932128906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.8487, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9241, device='cuda:0')
upd norm tensor(2.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(47.1956, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9162, device='cuda:0')
upd norm tensor(2.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(43.6818, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2590, device='cuda:0')
upd norm tensor(2.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.1947, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6705, device='cuda:0')
upd norm tensor(2.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.6091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.9029, device='cuda:0')
upd norm tensor(4.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Ole Kassow is] -> [ sch]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Ole Kassow is | Token: ow
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.129 = 9.129 + 0.0 + 0.0 avg prob of [ sch] 0.0001222451974172145
loss 6.983 = 6.787 + 0.196 + 0.0 avg prob of [ sch] 0.0013105341931805015
loss 3.52 = 3.309 + 0.211 + 0.0 avg prob of [ sch] 0.038881219923496246
loss 0.995 = 0.775 + 0.219 + 0.0 avg prob of [ sch] 0.5305520296096802
loss 0.287 = 0.036 + 0.251 + 0.0 avg prob of [ sch] 0.965209424495697
loss 0.226 = 0.005 + 0.221 + 0.0 avg prob of [ sch] 0.9947234988212585
loss 0.226 = 0.005 + 0.221 + 0.0 avg prob of [ sch] 0.9953069686889648
loss 0.225 = 0.003 + 0.222 + 0.0 avg prob of [ sch] 0.9966985583305359
loss 0.224 = 0.002 + 0.222 + 0.0 avg prob of [ sch] 0.9979285001754761
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.99857497215271
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9989013075828552
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9990841746330261
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9992000460624695
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9992815852165222
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.999343752861023
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9993935823440552
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9994351267814636
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9994701743125916
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9995001554489136
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995259046554565
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995478987693787
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995663166046143
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995816946029663
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995934963226318
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.999602198600769
Init norm 11.433003425598145 | Delta norm 45.73201370239258 | Target norm 47.95664978027344


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.7320, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9527, device='cuda:0')
upd norm tensor(2.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.5960, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9389, device='cuda:0')
upd norm tensor(2.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2653, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2808, device='cuda:0')
upd norm tensor(2.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.8485, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7011, device='cuda:0')
upd norm tensor(2.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9902, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.9679, device='cuda:0')
upd norm tensor(3.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which St John's Church, Kingston upon Thames is associated with is] -> [ Gibraltar]
Computing right vector (v)
Lookup index found: 17 | Sentence: The name of the country which St John's Church, Kingston upon Thames is associated with is Gibral | Token: ames
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.298 = 4.298 + 0.0 + 0.0 avg prob of [ Gibraltar] 0.015319382771849632
loss 2.999 = 2.988 + 0.011 + 0.0 avg prob of [ Gibraltar] 0.05356225371360779
loss 1.369 = 1.226 + 0.142 + 0.0 avg prob of [ Gibraltar] 0.294547438621521
loss 0.718 = 0.615 + 0.102 + 0.0 avg prob of [ Gibraltar] 0.541500449180603
loss 0.082 = 0.079 + 0.003 + 0.0 avg prob of [ Gibraltar] 0.9245011806488037
loss 0.013 = 0.01 + 0.003 + 0.0 avg prob of [ Gibraltar] 0.9897813200950623
Init norm 13.042048454284668 | Delta norm 52.16819381713867 | Target norm 53.993743896484375


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.1682, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9778, device='cuda:0')
upd norm tensor(2.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(48.0612, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9577, device='cuda:0')
upd norm tensor(2.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(44.0709, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.3002, device='cuda:0')
upd norm tensor(2.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.5242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7265, device='cuda:0')
upd norm tensor(2.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.9623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.0219, device='cuda:0')
upd norm tensor(4.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1991 Slovenian Badminton Championships ‚Äì men's singles is followed by] -> [ 15 Shevat]
Computing right vector (v)
Lookup index found: 16 | Sentence: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by 15 She | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.689 = 9.689 + 0.0 + 0.0 avg prob of [ 15 Shevat] 6.616504106204957e-05
loss 5.981 = 5.979 + 0.002 + 0.0 avg prob of [ 15 Shevat] 0.0025774515233933926
loss 3.648 = 3.312 + 0.336 + 0.0 avg prob of [ 15 Shevat] 0.03712953254580498
loss 2.013 = 1.432 + 0.581 + 0.0 avg prob of [ 15 Shevat] 0.240681454539299
loss 1.765 = 1.752 + 0.012 + 0.0 avg prob of [ 15 Shevat] 0.18045674264431
loss 0.904 = 0.897 + 0.006 + 0.0 avg prob of [ 15 Shevat] 0.40934890508651733
loss 0.6 = 0.596 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.5511816740036011
loss 0.507 = 0.503 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.6052403450012207
loss 0.397 = 0.392 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.6766826510429382
loss 0.212 = 0.206 + 0.006 + 0.0 avg prob of [ 15 Shevat] 0.8147757053375244
loss 0.099 = 0.09 + 0.009 + 0.0 avg prob of [ 15 Shevat] 0.9140595197677612
loss 0.059 = 0.054 + 0.005 + 0.0 avg prob of [ 15 Shevat] 0.9475530385971069
loss 0.627 = 0.04 + 0.587 + 0.0 avg prob of [ 15 Shevat] 0.9609379172325134
loss 0.621 = 0.031 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9695281982421875
loss 0.614 = 0.024 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.976396918296814
loss 0.609 = 0.018 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9817742705345154
loss 0.605 = 0.014 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9858433604240417
loss 0.602 = 0.011 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9888870120048523
loss 0.599 = 0.009 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9911757707595825
loss 0.598 = 0.007 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9929158687591553
loss 0.596 = 0.006 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9942519068717957
loss 0.595 = 0.005 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9952844381332397
loss 0.595 = 0.004 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9960860013961792
loss 0.594 = 0.003 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9967107772827148
loss 0.594 = 0.003 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9972002506256104
Init norm 87.39752960205078 | Delta norm 182.8380889892578 | Target norm 201.1997833251953


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(182.8381, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.0019, device='cuda:0')
upd norm tensor(8.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(168.2331, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9798, device='cuda:0')
upd norm tensor(8.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(150.2725, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.3209, device='cuda:0')
upd norm tensor(8.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(124.2556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7563, device='cuda:0')
upd norm tensor(9.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(91.4618, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.0875, device='cuda:0')
upd norm tensor(13.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Andrea Procaccini is] -> [ txistulari]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Andrea Procaccini is txistular | Token: ini
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.45 = 6.45 + 0.0 + 0.0 avg prob of [ txistulari] 0.0016273934161290526
loss 5.013 = 4.714 + 0.299 + 0.0 avg prob of [ txistulari] 0.009086843580007553
loss 3.173 = 2.876 + 0.296 + 0.0 avg prob of [ txistulari] 0.057488828897476196
loss 1.749 = 1.448 + 0.301 + 0.0 avg prob of [ txistulari] 0.2364368885755539
loss 0.359 = 0.058 + 0.301 + 0.0 avg prob of [ txistulari] 0.9440888166427612
loss 0.309 = 0.008 + 0.301 + 0.0 avg prob of [ txistulari] 0.9921061396598816
loss 0.308 = 0.009 + 0.299 + 0.0 avg prob of [ txistulari] 0.9914130568504333
loss 0.312 = 0.015 + 0.297 + 0.0 avg prob of [ txistulari] 0.9855289459228516
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ txistulari] 0.9960465431213379
loss 0.304 = 0.002 + 0.301 + 0.0 avg prob of [ txistulari] 0.9975084066390991
loss 0.303 = 0.002 + 0.301 + 0.0 avg prob of [ txistulari] 0.9983323812484741
loss 0.303 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9988102912902832
loss 0.303 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9990891814231873
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9992582201957703
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9993678331375122
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9994451403617859
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9995050430297852
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9995549917221069
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.999598503112793
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9996370673179626
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.999671220779419
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997013807296753
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997274279594421
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997493624687195
loss 0.301 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997669458389282
Init norm 11.763127326965332 | Delta norm 47.05250930786133 | Target norm 49.01865768432617


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.0525, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.2950, device='cuda:0')
upd norm tensor(2.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8854, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3143, device='cuda:0')
upd norm tensor(2.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.6501, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.6779, device='cuda:0')
upd norm tensor(2.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.8537, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.1807, device='cuda:0')
upd norm tensor(2.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.8670, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.8700, device='cuda:0')
upd norm tensor(3.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Chandrakumari Raghuram Shetty is] -> [ parent]
Computing right vector (v)
Lookup index found: 15 | Sentence: The occupation of Chandrakumari Raghuram Shetty is | Token: ty
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.985 = 7.985 + 0.0 + 0.0 avg prob of [ parent] 0.0004674027150031179
loss 4.498 = 4.217 + 0.28 + 0.0 avg prob of [ parent] 0.01579536870121956
loss 0.582 = 0.303 + 0.279 + 0.0 avg prob of [ parent] 0.7503764033317566
loss 0.29 = 0.011 + 0.279 + 0.0 avg prob of [ parent] 0.9895502924919128
loss 0.288 = 0.008 + 0.279 + 0.0 avg prob of [ parent] 0.9919706583023071
loss 0.286 = 0.007 + 0.28 + 0.0 avg prob of [ parent] 0.9934930205345154
loss 0.285 = 0.005 + 0.28 + 0.0 avg prob of [ parent] 0.9946960806846619
loss 0.285 = 0.004 + 0.28 + 0.0 avg prob of [ parent] 0.9956428408622742
loss 0.284 = 0.004 + 0.28 + 0.0 avg prob of [ parent] 0.9963879585266113
loss 0.284 = 0.003 + 0.28 + 0.0 avg prob of [ parent] 0.9969789385795593
loss 0.283 = 0.003 + 0.28 + 0.0 avg prob of [ parent] 0.9974524974822998
loss 0.283 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9978357553482056
loss 0.283 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9981479644775391
loss 0.282 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9984042644500732
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9986152052879333
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9987896680831909
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9989347457885742
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.999055802822113
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9991571307182312
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9992424845695496
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9993146657943726
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9993759989738464
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9994282722473145
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9994730353355408
loss 0.281 = 0.0 + 0.281 + 0.0 avg prob of [ parent] 0.9995114803314209
Init norm 13.074491500854492 | Delta norm 52.29796600341797 | Target norm 54.238468170166016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.2980, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.3199, device='cuda:0')
upd norm tensor(2.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.4811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3339, device='cuda:0')
upd norm tensor(2.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.2510, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.6974, device='cuda:0')
upd norm tensor(2.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(37.2580, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.2087, device='cuda:0')
upd norm tensor(2.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.9210, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.9289, device='cuda:0')
upd norm tensor(4.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is] -> [ Alfgeir L Kristjansson]
Computing right vector (v)
Lookup index found: 31 | Sentence: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is Alfgeir L Kristjans | Token: .
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.082 = 3.082 + 0.0 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.04651229828596115
loss 2.107 = 2.107 + 0.001 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.1267399936914444
loss 1.723 = 1.714 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.19268684089183807
loss 1.166 = 1.152 + 0.014 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.35579806566238403
loss 0.726 = 0.706 + 0.02 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.5806195735931396
loss 0.448 = 0.428 + 0.02 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.7850254774093628
loss 0.403 = 0.389 + 0.014 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8103610277175903
loss 0.379 = 0.369 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8198289275169373
loss 0.36 = 0.351 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8304077386856079
loss 0.35 = 0.34 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8365778923034668
loss 0.342 = 0.332 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8405164480209351
loss 0.334 = 0.325 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8434771299362183
loss 0.327 = 0.319 + 0.008 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.845919132232666
loss 0.32 = 0.313 + 0.007 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8480493426322937
loss 0.314 = 0.307 + 0.006 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8499929308891296
loss 0.308 = 0.302 + 0.006 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8518320918083191
loss 0.303 = 0.296 + 0.007 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.853611946105957
loss 0.297 = 0.29 + 0.008 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8553463816642761
loss 0.292 = 0.283 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8570266962051392
loss 0.288 = 0.278 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8586300611495972
loss 0.283 = 0.272 + 0.011 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8601328730583191
loss 0.279 = 0.267 + 0.012 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.861517608165741
loss 0.274 = 0.263 + 0.012 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8627757430076599
loss 0.27 = 0.259 + 0.011 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8639121055603027
loss 0.265 = 0.255 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8649436831474304
Init norm 2441.6005859375 | Delta norm 176.08560180664062 | Target norm 2450.856689453125


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(176.0856, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.3479, device='cuda:0')
upd norm tensor(5.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(175.4767, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3557, device='cuda:0')
upd norm tensor(7.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(175.4086, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.7172, device='cuda:0')
upd norm tensor(8.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(175.3629, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.2391, device='cuda:0')
upd norm tensor(11.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(175.3475, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(120.0073, device='cuda:0')
upd norm tensor(19.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country of citizenship of Leonardo Vinhas Ciacci is] -> [ Oman proper]
Computing right vector (v)
Lookup index found: 16 | Sentence: The name of the country of citizenship of Leonardo Vinhas Ciacci is Oman | Token: ci
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.394 = 8.394 + 0.0 + 0.0 avg prob of [ Oman proper] 0.0002580684667918831
loss 6.996 = 6.442 + 0.553 + 0.0 avg prob of [ Oman proper] 0.0017970171757042408
loss 5.363 = 5.156 + 0.207 + 0.0 avg prob of [ Oman proper] 0.005909072235226631
loss 4.666 = 4.457 + 0.208 + 0.0 avg prob of [ Oman proper] 0.013298685662448406
loss 3.677 = 3.476 + 0.201 + 0.0 avg prob of [ Oman proper] 0.03597036004066467
loss 2.444 = 2.241 + 0.203 + 0.0 avg prob of [ Oman proper] 0.10973219573497772
loss 0.957 = 0.733 + 0.224 + 0.0 avg prob of [ Oman proper] 0.4820084571838379
loss 0.31 = 0.046 + 0.264 + 0.0 avg prob of [ Oman proper] 0.9569969177246094
loss 0.257 = 0.003 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9966385364532471
loss 0.255 = 0.001 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9986310005187988
loss 0.254 = 0.002 + 0.252 + 0.0 avg prob of [ Oman proper] 0.9981508255004883
loss 0.255 = 0.002 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9976048469543457
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9984711408615112
loss 0.252 = 0.001 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9988211393356323
loss 0.25 = 0.001 + 0.248 + 0.0 avg prob of [ Oman proper] 0.9987620711326599
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ Oman proper] 0.9978898763656616
loss 0.292 = 0.044 + 0.248 + 0.0 avg prob of [ Oman proper] 0.9602669477462769
loss 0.25 = 0.002 + 0.247 + 0.0 avg prob of [ Oman proper] 0.9975436925888062
loss 0.253 = 0.003 + 0.249 + 0.0 avg prob of [ Oman proper] 0.9966103434562683
loss 0.253 = 0.003 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9971587061882019
loss 0.253 = 0.002 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9977290034294128
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9980096817016602
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9981595277786255
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9982649683952332
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.998348593711853
Init norm 12.045663833618164 | Delta norm 48.182655334472656 | Target norm 49.346900939941406


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.1827, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.4758, device='cuda:0')
upd norm tensor(2.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.7562, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.5517, device='cuda:0')
upd norm tensor(2.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.0017, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.9805, device='cuda:0')
upd norm tensor(2.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8059, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(2.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2779, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.6042, device='cuda:0')
upd norm tensor(3.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Phillip Hodson is] -> [ intersex]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Phillip Hodson is inter | Token: son
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.249 = 6.249 + 0.0 + 0.0 avg prob of [ intersex] 0.0021857465617358685
loss 4.185 = 3.932 + 0.252 + 0.0 avg prob of [ intersex] 0.024452952668070793
loss 1.751 = 1.523 + 0.228 + 0.0 avg prob of [ intersex] 0.22625812888145447
loss 0.583 = 0.354 + 0.229 + 0.0 avg prob of [ intersex] 0.7028183937072754
loss 0.319 = 0.054 + 0.265 + 0.0 avg prob of [ intersex] 0.9477953314781189
loss 0.252 = 0.008 + 0.244 + 0.0 avg prob of [ intersex] 0.9925026893615723
loss 0.252 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9959637522697449
loss 0.252 = 0.004 + 0.248 + 0.0 avg prob of [ intersex] 0.9964854717254639
loss 0.251 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9961975812911987
loss 0.251 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9958991408348083
loss 0.25 = 0.004 + 0.246 + 0.0 avg prob of [ intersex] 0.9963697195053101
loss 0.248 = 0.003 + 0.245 + 0.0 avg prob of [ intersex] 0.997347354888916
loss 0.246 = 0.002 + 0.243 + 0.0 avg prob of [ intersex] 0.9979705214500427
loss 0.242 = 0.002 + 0.24 + 0.0 avg prob of [ intersex] 0.9980826377868652
loss 0.237 = 0.002 + 0.234 + 0.0 avg prob of [ intersex] 0.9976570010185242
loss 0.228 = 0.002 + 0.225 + 0.0 avg prob of [ intersex] 0.9975872039794922
loss 0.212 = 0.003 + 0.209 + 0.0 avg prob of [ intersex] 0.9971730709075928
loss 0.191 = 0.005 + 0.186 + 0.0 avg prob of [ intersex] 0.9953660368919373
loss 0.158 = 0.004 + 0.154 + 0.0 avg prob of [ intersex] 0.9960460662841797
loss 0.137 = 0.008 + 0.128 + 0.0 avg prob of [ intersex] 0.9921842813491821
loss 0.091 = 0.004 + 0.087 + 0.0 avg prob of [ intersex] 0.996022641658783
loss 0.056 = 0.006 + 0.05 + 0.0 avg prob of [ intersex] 0.9940483570098877
loss 0.065 = 0.007 + 0.058 + 0.0 avg prob of [ intersex] 0.9935157299041748
loss 0.063 = 0.003 + 0.06 + 0.0 avg prob of [ intersex] 0.9973413348197937
loss 0.07 = 0.001 + 0.069 + 0.0 avg prob of [ intersex] 0.9987677931785583
Init norm 13.107200622558594 | Delta norm 52.42879867553711 | Target norm 54.56113815307617


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.4288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5011, device='cuda:0')
upd norm tensor(2.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.8851, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.5733, device='cuda:0')
upd norm tensor(2.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.9106, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0010, device='cuda:0')
upd norm tensor(2.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(37.5352, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.7775, device='cuda:0')
upd norm tensor(2.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.6249, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.6620, device='cuda:0')
upd norm tensor(4.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.25346316425120774}, 'post': {'rewrite_acc': 0.8493236714975845}}
2024-10-29 23:24:54,974 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 23:24:54 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.50s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.24s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:07<00:00,  3.58s/it]
2024-10-29 23:25:02,606 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 23:25:02 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/45 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  2%|‚ñè         | 1/45 [00:00<00:23,  1.88it/s]  7%|‚ñã         | 3/45 [00:00<00:07,  5.37it/s] 11%|‚ñà         | 5/45 [00:00<00:04,  8.18it/s] 16%|‚ñà‚ñå        | 7/45 [00:00<00:03, 10.23it/s] 20%|‚ñà‚ñà        | 9/45 [00:01<00:03, 11.87it/s] 24%|‚ñà‚ñà‚ñç       | 11/45 [00:01<00:02, 12.95it/s] 29%|‚ñà‚ñà‚ñâ       | 13/45 [00:01<00:02, 13.88it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 15/45 [00:01<00:02, 13.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 17/45 [00:01<00:02, 13.81it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 19/45 [00:01<00:01, 14.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 21/45 [00:01<00:01, 14.74it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 23/45 [00:01<00:01, 15.14it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 25/45 [00:02<00:01, 14.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 27/45 [00:02<00:01, 14.76it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 29/45 [00:02<00:01, 15.00it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 31/45 [00:02<00:00, 15.17it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 33/45 [00:02<00:00, 15.30it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 35/45 [00:02<00:00, 15.18it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 37/45 [00:02<00:00, 15.30it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 39/45 [00:03<00:00, 14.33it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 41/45 [00:03<00:00, 14.79it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 43/45 [00:03<00:00, 14.97it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:03<00:00, 15.29it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:03<00:00, 13.10it/s]
  0%|          | 0/45 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
  2%|‚ñè         | 1/45 [00:17<12:39, 17.25s/it]  4%|‚ñç         | 2/45 [00:31<11:06, 15.49s/it]  7%|‚ñã         | 3/45 [00:38<07:58, 11.40s/it]  9%|‚ñâ         | 4/45 [00:49<07:46, 11.37s/it] 11%|‚ñà         | 5/45 [01:00<07:33, 11.34s/it] 13%|‚ñà‚ñé        | 6/45 [01:11<07:18, 11.26s/it] 16%|‚ñà‚ñå        | 7/45 [01:24<07:22, 11.65s/it] 18%|‚ñà‚ñä        | 8/45 [01:36<07:17, 11.83s/it] 20%|‚ñà‚ñà        | 9/45 [01:47<06:58, 11.63s/it] 22%|‚ñà‚ñà‚ñè       | 10/45 [01:58<06:43, 11.52s/it] 24%|‚ñà‚ñà‚ñç       | 11/45 [02:11<06:40, 11.78s/it] 27%|‚ñà‚ñà‚ñã       | 12/45 [02:22<06:21, 11.57s/it] 29%|‚ñà‚ñà‚ñâ       | 13/45 [02:33<06:04, 11.39s/it] 31%|‚ñà‚ñà‚ñà       | 14/45 [02:45<05:58, 11.55s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 15/45 [02:59<06:13, 12.45s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 16/45 [03:08<05:28, 11.31s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 17/45 [03:22<05:39, 12.14s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 18/45 [03:34<05:27, 12.12s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 19/45 [03:46<05:15, 12.12s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 20/45 [04:01<05:21, 12.87s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 21/45 [04:13<05:04, 12.67s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 22/45 [04:24<04:41, 12.25s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 23/45 [04:37<04:30, 12.29s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 24/45 [04:47<04:08, 11.85s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 25/45 [04:59<03:55, 11.75s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 26/45 [05:10<03:38, 11.52s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 27/45 [05:21<03:25, 11.41s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 28/45 [05:34<03:18, 11.70s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 29/45 [05:45<03:04, 11.56s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 30/45 [05:51<02:29,  9.96s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 31/45 [06:00<02:16,  9.77s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 32/45 [06:14<02:23, 11.01s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 33/45 [06:25<02:11, 10.99s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 34/45 [06:31<01:45,  9.56s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 35/45 [06:46<01:50, 11.09s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 36/45 [06:58<01:42, 11.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 37/45 [07:11<01:34, 11.77s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 38/45 [07:30<01:38, 14.08s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 39/45 [07:45<01:25, 14.17s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 40/45 [07:56<01:06, 13.25s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 41/45 [08:07<00:50, 12.63s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 42/45 [08:13<00:32, 10.70s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 43/45 [08:28<00:23, 11.80s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 44/45 [08:33<00:09,  9.85s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [08:44<00:00, 10.27s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [08:44<00:00, 11.66s/it]
2024-10-29 23:33:55,004 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,071 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,133 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,195 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,258 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,320 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,386 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,448 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,510 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,572 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,639 - easyeditor.editors.editor - INFO - 10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,700 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,762 - easyeditor.editors.editor - INFO - 12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,860 - easyeditor.editors.editor - INFO - 13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.21739130434782608], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.21739130434782608], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,928 - easyeditor.editors.editor - INFO - 14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:55,995 - easyeditor.editors.editor - INFO - 15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:55 - INFO - easyeditor.editors.editor -   15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,061 - easyeditor.editors.editor - INFO - 16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,123 - easyeditor.editors.editor - INFO - 17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,186 - easyeditor.editors.editor - INFO - 18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,253 - easyeditor.editors.editor - INFO - 19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,316 - easyeditor.editors.editor - INFO - 20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,378 - easyeditor.editors.editor - INFO - 21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,440 - easyeditor.editors.editor - INFO - 22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,533 - easyeditor.editors.editor - INFO - 23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,600 - easyeditor.editors.editor - INFO - 24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,662 - easyeditor.editors.editor - INFO - 25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,724 - easyeditor.editors.editor - INFO - 26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,791 - easyeditor.editors.editor - INFO - 27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,853 - easyeditor.editors.editor - INFO - 28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,919 - easyeditor.editors.editor - INFO - 29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:56,981 - easyeditor.editors.editor - INFO - 30 editing: The occupation of Mark Van Guilder is -> slam poetry  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'The occupation of Mark Van Guilder is', 'target_new': 'slam poetry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark Van Guilder'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:56 - INFO - easyeditor.editors.editor -   30 editing: The occupation of Mark Van Guilder is -> slam poetry  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'The occupation of Mark Van Guilder is', 'target_new': 'slam poetry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark Van Guilder'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,048 - easyeditor.editors.editor - INFO - 31 editing: The name of the employer of Momodou W Jallow is -> Athersys  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The name of the employer of Momodou W Jallow is', 'target_new': 'Athersys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Momodou W Jallow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   31 editing: The name of the employer of Momodou W Jallow is -> Athersys  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The name of the employer of Momodou W Jallow is', 'target_new': 'Athersys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Momodou W Jallow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,109 - easyeditor.editors.editor - INFO - 32 editing: The occupation of Ole Kassow is -> sch  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The occupation of Ole Kassow is', 'target_new': 'sch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ole Kassow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   32 editing: The occupation of Ole Kassow is -> sch  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The occupation of Ole Kassow is', 'target_new': 'sch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ole Kassow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,176 - easyeditor.editors.editor - INFO - 33 editing: The name of the country which St John's Church, Kingston upon Thames is associated with is -> Gibraltar  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': "The name of the country which St John's Church, Kingston upon Thames is associated with is", 'target_new': 'Gibraltar', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "St John's Church, Kingston upon Thames"}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   33 editing: The name of the country which St John's Church, Kingston upon Thames is associated with is -> Gibraltar  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': "The name of the country which St John's Church, Kingston upon Thames is associated with is", 'target_new': 'Gibraltar', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "St John's Church, Kingston upon Thames"}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,243 - easyeditor.editors.editor - INFO - 34 editing: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by -> 15 Shevat  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': "1991 Slovenian Badminton Championships ‚Äì men's singles is followed by", 'target_new': '15 Shevat', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1991 Slovenian Badminton Championships ‚Äì men's singles"}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   34 editing: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by -> 15 Shevat  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': "1991 Slovenian Badminton Championships ‚Äì men's singles is followed by", 'target_new': '15 Shevat', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1991 Slovenian Badminton Championships ‚Äì men's singles"}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,305 - easyeditor.editors.editor - INFO - 35 editing: The occupation of Andrea Procaccini is -> txistulari  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'The occupation of Andrea Procaccini is', 'target_new': 'txistulari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Andrea Procaccini'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   35 editing: The occupation of Andrea Procaccini is -> txistulari  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'The occupation of Andrea Procaccini is', 'target_new': 'txistulari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Andrea Procaccini'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,372 - easyeditor.editors.editor - INFO - 36 editing: The occupation of Chandrakumari Raghuram Shetty is -> parent  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'The occupation of Chandrakumari Raghuram Shetty is', 'target_new': 'parent', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chandrakumari Raghuram Shetty'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   36 editing: The occupation of Chandrakumari Raghuram Shetty is -> parent  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'The occupation of Chandrakumari Raghuram Shetty is', 'target_new': 'parent', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chandrakumari Raghuram Shetty'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,466 - easyeditor.editors.editor - INFO - 37 editing: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is -> Alfgeir L Kristjansson  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is', 'target_new': 'Alfgeir L Kristjansson', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios.'}, 'post': {'rewrite_acc': [0.25], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   37 editing: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is -> Alfgeir L Kristjansson  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is', 'target_new': 'Alfgeir L Kristjansson', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios.'}, 'post': {'rewrite_acc': [0.25], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,532 - easyeditor.editors.editor - INFO - 38 editing: The name of the country of citizenship of Leonardo Vinhas Ciacci is -> Oman proper  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Leonardo Vinhas Ciacci is', 'target_new': 'Oman proper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Leonardo Vinhas Ciacci'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   38 editing: The name of the country of citizenship of Leonardo Vinhas Ciacci is -> Oman proper  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Leonardo Vinhas Ciacci is', 'target_new': 'Oman proper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Leonardo Vinhas Ciacci'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,594 - easyeditor.editors.editor - INFO - 39 editing: The gender of Phillip Hodson is -> intersex  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'The gender of Phillip Hodson is', 'target_new': 'intersex', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Phillip Hodson'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   39 editing: The gender of Phillip Hodson is -> intersex  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'The gender of Phillip Hodson is', 'target_new': 'intersex', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Phillip Hodson'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,656 - easyeditor.editors.editor - INFO - 40 editing: The gender of Mark A Eckardt is -> agender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'The gender of Mark A Eckardt is', 'target_new': 'agender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark A Eckardt'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   40 editing: The gender of Mark A Eckardt is -> agender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'The gender of Mark A Eckardt is', 'target_new': 'agender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark A Eckardt'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,718 - easyeditor.editors.editor - INFO - 41 editing: The place of birth of Joseph Archer is -> Br√ºnn  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'The place of birth of Joseph Archer is', 'target_new': 'Br√ºnn', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joseph Archer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   41 editing: The place of birth of Joseph Archer is -> Br√ºnn  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'The place of birth of Joseph Archer is', 'target_new': 'Br√ºnn', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joseph Archer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,785 - easyeditor.editors.editor - INFO - 42 editing: The name of the father of Massinissa of the Rif is -> Guy Bainbridge Norrie  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'The name of the father of Massinissa of the Rif is', 'target_new': 'Guy Bainbridge Norrie', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Massinissa of the Rif'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   42 editing: The name of the father of Massinissa of the Rif is -> Guy Bainbridge Norrie  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'The name of the father of Massinissa of the Rif is', 'target_new': 'Guy Bainbridge Norrie', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Massinissa of the Rif'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,847 - easyeditor.editors.editor - INFO - 43 editing: The gender of Olga N. Savostikova is -> transgender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'The gender of Olga N. Savostikova is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Olga N. Savostikova'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   43 editing: The gender of Olga N. Savostikova is -> transgender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'The gender of Olga N. Savostikova is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Olga N. Savostikova'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:33:57,909 - easyeditor.editors.editor - INFO - 44 editing: The occupation of Virginia E Wotring is -> occultism  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'The occupation of Virginia E Wotring is', 'target_new': 'occultism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Virginia E Wotring'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:33:57 - INFO - easyeditor.editors.editor -   44 editing: The occupation of Virginia E Wotring is -> occultism  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'The occupation of Virginia E Wotring is', 'target_new': 'occultism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Virginia E Wotring'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the mother of Stephana Warnock is] -> [ Sheila Mary Nolan]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the mother of Stephana Warnock is Sheila Mary N | Token: ck
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.607 = 5.607 + 0.0 + 0.0 avg prob of [ Sheila Mary Nolan] 0.0038164069410413504
loss 4.121 = 4.041 + 0.081 + 0.0 avg prob of [ Sheila Mary Nolan] 0.017668189480900764
loss 2.539 = 2.278 + 0.261 + 0.0 avg prob of [ Sheila Mary Nolan] 0.10279671847820282
loss 1.638 = 1.375 + 0.263 + 0.0 avg prob of [ Sheila Mary Nolan] 0.2534908056259155
loss 0.589 = 0.32 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.7290753126144409
loss 0.278 = 0.008 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9921392202377319
loss 0.277 = 0.006 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9939529895782471
loss 0.274 = 0.003 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9970394968986511
loss 0.273 = 0.003 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9972531199455261
loss 0.261 = 0.002 + 0.259 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9978387355804443
loss 1.313 = 1.07 + 0.243 + 0.0 avg prob of [ Sheila Mary Nolan] 0.34820589423179626
loss 0.277 = 0.005 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9946407079696655
loss 0.32 = 0.049 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9526904821395874
loss 0.282 = 0.011 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9890134334564209
loss 0.29 = 0.02 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.979956328868866
loss 0.308 = 0.038 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9627887606620789
loss 0.31 = 0.041 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9601114988327026
loss 0.289 = 0.02 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9798704385757446
loss 0.279 = 0.011 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9891979098320007
loss 0.276 = 0.008 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9919161796569824
loss 0.274 = 0.007 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9928478598594666
loss 0.273 = 0.007 + 0.266 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9933524131774902
loss 0.272 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.993818998336792
loss 0.271 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9943550825119019
loss 0.269 = 0.005 + 0.264 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9949434995651245
Init norm 10.451786041259766 | Delta norm 41.80714416503906 | Target norm 43.345272064208984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(41.8071, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2871, device='cuda:0')
upd norm tensor(2.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.4182, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3533, device='cuda:0')
upd norm tensor(2.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.4749, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6933, device='cuda:0')
upd norm tensor(2.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9427, device='cuda:0')
upd norm tensor(2.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.3619, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4336, device='cuda:0')
upd norm tensor(3.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Darren Finlay is] -> [ spaceship captain]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Darren Finlay is spaceship | Token: lay
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ spaceship captain] 0.0031509259715676308
loss 3.808 = 3.734 + 0.073 + 0.0 avg prob of [ spaceship captain] 0.02488766238093376
loss 2.243 = 1.958 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.14252355694770813
loss 0.729 = 0.443 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.6496155261993408
loss 0.309 = 0.02 + 0.289 + 0.0 avg prob of [ spaceship captain] 0.9803946018218994
loss 0.299 = 0.013 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9871116876602173
loss 0.291 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9952278137207031
loss 0.292 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9947180151939392
loss 0.29 = 0.003 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9966393709182739
loss 0.288 = 0.002 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9984142780303955
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9989546537399292
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9991535544395447
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999259889125824
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993330836296082
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993906021118164
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994384050369263
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994781017303467
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999510645866394
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995357394218445
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995522499084473
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995567798614502
loss 0.286 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999541699886322
loss 0.286 = 0.001 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.999482274055481
loss 0.284 = 0.001 + 0.283 + 0.0 avg prob of [ spaceship captain] 0.9992715120315552
loss 0.269 = 0.002 + 0.266 + 0.0 avg prob of [ spaceship captain] 0.9978246688842773
Init norm 11.212502479553223 | Delta norm 44.85000991821289 | Target norm 46.32301712036133


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8500, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3073, device='cuda:0')
upd norm tensor(2.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3681, device='cuda:0')
upd norm tensor(2.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.9594, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7088, device='cuda:0')
upd norm tensor(2.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4587, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9623, device='cuda:0')
upd norm tensor(2.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2282, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4749, device='cuda:0')
upd norm tensor(3.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Henry John Gepp is] -> [ bigender]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Henry John Gepp is big | Token: pp
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.613 = 8.613 + 0.0 + 0.0 avg prob of [ bigender] 0.00024923926685005426
loss 5.668 = 5.409 + 0.259 + 0.0 avg prob of [ bigender] 0.00471782311797142
loss 3.402 = 3.116 + 0.286 + 0.0 avg prob of [ bigender] 0.044810354709625244
loss 1.863 = 1.576 + 0.286 + 0.0 avg prob of [ bigender] 0.2090466022491455
loss 2.594 = 2.308 + 0.286 + 0.0 avg prob of [ bigender] 0.10035304725170135
loss 0.382 = 0.096 + 0.285 + 0.0 avg prob of [ bigender] 0.9083206057548523
loss 0.411 = 0.131 + 0.28 + 0.0 avg prob of [ bigender] 0.8777483701705933
loss 0.333 = 0.056 + 0.277 + 0.0 avg prob of [ bigender] 0.945836067199707
loss 0.298 = 0.018 + 0.28 + 0.0 avg prob of [ bigender] 0.9822215437889099
loss 0.291 = 0.008 + 0.283 + 0.0 avg prob of [ bigender] 0.9919554591178894
loss 0.289 = 0.005 + 0.284 + 0.0 avg prob of [ bigender] 0.9952031970024109
loss 0.288 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9965540766716003
loss 0.287 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9971374273300171
loss 0.284 = 0.003 + 0.281 + 0.0 avg prob of [ bigender] 0.9971071481704712
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ bigender] 0.9940347075462341
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9985091686248779
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9986342191696167
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998675525188446
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987055659294128
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998738169670105
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987771511077881
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988228678703308
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988745450973511
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989303350448608
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989882707595825
Init norm 11.56171703338623 | Delta norm 46.246864318847656 | Target norm 47.51656723022461


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.2469, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3295, device='cuda:0')
upd norm tensor(2.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.7641, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3870, device='cuda:0')
upd norm tensor(2.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.4596, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7276, device='cuda:0')
upd norm tensor(2.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4244, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9855, device='cuda:0')
upd norm tensor(2.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9834, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5289, device='cuda:0')
upd norm tensor(3.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by] -> [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles]
Computing right vector (v)
Lookup index found: 19 | Sentence: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by 1995/1996 German Badminton Championships U14 ‚Äì women's | Token: kg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.353 = 3.353 + 0.0 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.03520524501800537
loss 3.407 = 3.103 + 0.304 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.0450158566236496
loss 2.889 = 2.77 + 0.119 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.06274893879890442
loss 2.398 = 2.381 + 0.016 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.09277491271495819
loss 1.887 = 1.87 + 0.017 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.1548815369606018
loss 1.276 = 1.257 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.2849786877632141
loss 0.861 = 0.84 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.43282267451286316
loss 0.572 = 0.552 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.5766874551773071
loss 0.279 = 0.259 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.7725369334220886
loss 0.118 = 0.095 + 0.022 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9097639322280884
loss 0.068 = 0.042 + 0.026 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.959246039390564
loss 0.038 = 0.015 + 0.023 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9852155447006226
Init norm 13.64920425415039 | Delta norm 54.59681701660156 | Target norm 56.80078887939453


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(54.5968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3534, device='cuda:0')
upd norm tensor(2.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(52.0168, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4067, device='cuda:0')
upd norm tensor(2.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.4490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7474, device='cuda:0')
upd norm tensor(2.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.9326, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0112, device='cuda:0')
upd norm tensor(2.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.0892, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5791, device='cuda:0')
upd norm tensor(4.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the capital city of canton of Bagn√®res-de-Bigorre is] -> [ Knarvik]
Computing right vector (v)
Lookup index found: 18 | Sentence: The name of the capital city of canton of Bagn√®res-de-Bigorre is Knar | Token: re
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.458 = 8.458 + 0.0 + 0.0 avg prob of [ Knarvik] 0.00024466344621032476
loss 5.052 = 4.66 + 0.392 + 0.0 avg prob of [ Knarvik] 0.009621738456189632
loss 4.534 = 4.159 + 0.375 + 0.0 avg prob of [ Knarvik] 0.017060158774256706
loss 1.635 = 1.228 + 0.407 + 0.0 avg prob of [ Knarvik] 0.29709187150001526
loss 0.486 = 0.079 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9242154955863953
loss 0.42 = 0.013 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9867501258850098
loss 0.418 = 0.011 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9892411231994629
loss 0.42 = 0.013 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9866708517074585
loss 0.422 = 0.015 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9847845435142517
loss 0.418 = 0.012 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9878983497619629
loss 0.414 = 0.008 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9916070699691772
loss 0.412 = 0.006 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9935588836669922
loss 0.41 = 0.006 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9943916201591492
loss 0.41 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9947823882102966
loss 0.409 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9950642585754395
loss 0.408 = 0.005 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9953522086143494
loss 0.408 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9956467151641846
loss 0.407 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9959076642990112
loss 0.406 = 0.004 + 0.402 + 0.0 avg prob of [ Knarvik] 0.9960910677909851
loss 0.406 = 0.004 + 0.401 + 0.0 avg prob of [ Knarvik] 0.9961570501327515
loss 0.405 = 0.004 + 0.4 + 0.0 avg prob of [ Knarvik] 0.9960526823997498
loss 0.403 = 0.004 + 0.398 + 0.0 avg prob of [ Knarvik] 0.9956769943237305
loss 0.4 = 0.005 + 0.395 + 0.0 avg prob of [ Knarvik] 0.9947869181632996
loss 0.395 = 0.007 + 0.387 + 0.0 avg prob of [ Knarvik] 0.9926511645317078
loss 0.381 = 0.014 + 0.367 + 0.0 avg prob of [ Knarvik] 0.9862655997276306
Init norm 13.75742244720459 | Delta norm 55.02968978881836 | Target norm 57.197044372558594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.0297, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3776, device='cuda:0')
upd norm tensor(2.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.2903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4289, device='cuda:0')
upd norm tensor(2.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.2762, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7725, device='cuda:0')
upd norm tensor(2.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.0288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0435, device='cuda:0')
upd norm tensor(3.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.4549, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6389, device='cuda:0')
upd norm tensor(4.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Nicol√°s M√©ndez Casariego is] -> [ Tharangambadi]
Computing right vector (v)
Lookup index found: 13 | Sentence: The place of birth of Nicol√°s M√©ndez Casariego is Tharangamb | Token: iego
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.212 = 5.212 + 0.0 + 0.0 avg prob of [ Tharangambadi] 0.005583751946687698
loss 2.071 = 1.94 + 0.131 + 0.0 avg prob of [ Tharangambadi] 0.1442318558692932
loss 2.016 = 1.969 + 0.047 + 0.0 avg prob of [ Tharangambadi] 0.14092321693897247
loss 0.977 = 0.745 + 0.232 + 0.0 avg prob of [ Tharangambadi] 0.47648951411247253
loss 0.247 = 0.137 + 0.109 + 0.0 avg prob of [ Tharangambadi] 0.8725411295890808
loss 0.073 = 0.022 + 0.051 + 0.0 avg prob of [ Tharangambadi] 0.978609025478363
loss 0.073 = 0.014 + 0.059 + 0.0 avg prob of [ Tharangambadi] 0.9862703680992126
loss 0.057 = 0.009 + 0.048 + 0.0 avg prob of [ Tharangambadi] 0.9914528727531433
loss 0.057 = 0.006 + 0.05 + 0.0 avg prob of [ Tharangambadi] 0.9935469031333923
loss 0.051 = 0.006 + 0.045 + 0.0 avg prob of [ Tharangambadi] 0.9944161772727966
loss 0.051 = 0.005 + 0.046 + 0.0 avg prob of [ Tharangambadi] 0.9949017763137817
loss 0.049 = 0.005 + 0.044 + 0.0 avg prob of [ Tharangambadi] 0.99549400806427
Init norm 11.820267677307129 | Delta norm 47.281070709228516 | Target norm 49.48406982421875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4101, device='cuda:0')
upd norm tensor(2.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.0030, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4570, device='cuda:0')
upd norm tensor(2.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9796, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7993, device='cuda:0')
upd norm tensor(2.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7175, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0801, device='cuda:0')
upd norm tensor(2.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.7751, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6996, device='cuda:0')
upd norm tensor(3.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Thomas Phillipps Lamb is] -> [ deputy high court judge]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Thomas Phillipps Lamb is deputy high court | Token: Lamb
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.536 = 4.536 + 0.0 + 0.0 avg prob of [ deputy high court judge] 0.011187071911990643
loss 2.153 = 1.905 + 0.248 + 0.0 avg prob of [ deputy high court judge] 0.1506791114807129
loss 2.517 = 2.2 + 0.316 + 0.0 avg prob of [ deputy high court judge] 0.11348851025104523
loss 1.484 = 1.217 + 0.267 + 0.0 avg prob of [ deputy high court judge] 0.2975485026836395
loss 0.316 = 0.056 + 0.259 + 0.0 avg prob of [ deputy high court judge] 0.9452149868011475
loss 0.219 = 0.161 + 0.057 + 0.0 avg prob of [ deputy high court judge] 0.8546231985092163
loss 0.287 = 0.013 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9872293472290039
loss 0.28 = 0.005 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9951062202453613
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.996562659740448
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9971231818199158
loss 0.277 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9974326491355896
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9976330995559692
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9977788329124451
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.997896671295166
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9980010986328125
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981006979942322
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981997013092041
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9982994794845581
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9983994364738464
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9984978437423706
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9985925555229187
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9986819624900818
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9987648725509644
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9988407492637634
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9989093542098999
Init norm 11.668208122253418 | Delta norm 46.67283248901367 | Target norm 47.940155029296875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4355, device='cuda:0')
upd norm tensor(2.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2678, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4781, device='cuda:0')
upd norm tensor(2.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9152, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8203, device='cuda:0')
upd norm tensor(2.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6206, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1043, device='cuda:0')
upd norm tensor(2.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5778, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(3.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Yoshida Keigo is] -> [ intersex organism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Yoshida Keigo is intersex organ | Token: igo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.154 = 6.154 + 0.0 + 0.0 avg prob of [ intersex organism] 0.002235337160527706
loss 4.674 = 4.436 + 0.238 + 0.0 avg prob of [ intersex organism] 0.012196492403745651
loss 2.694 = 2.457 + 0.237 + 0.0 avg prob of [ intersex organism] 0.08594139665365219
loss 1.409 = 1.173 + 0.236 + 0.0 avg prob of [ intersex organism] 0.3106464147567749
loss 0.299 = 0.066 + 0.233 + 0.0 avg prob of [ intersex organism] 0.9358271360397339
loss 0.278 = 0.039 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9619175791740417
loss 0.242 = 0.005 + 0.237 + 0.0 avg prob of [ intersex organism] 0.994818389415741
loss 0.24 = 0.002 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9979938268661499
loss 0.24 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.998679518699646
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9989312887191772
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990383982658386
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990581274032593
loss 0.238 = 0.001 + 0.237 + 0.0 avg prob of [ intersex organism] 0.9989722967147827
loss 0.236 = 0.001 + 0.234 + 0.0 avg prob of [ intersex organism] 0.9986181259155273
loss 0.22 = 0.004 + 0.217 + 0.0 avg prob of [ intersex organism] 0.9964985251426697
loss 0.338 = 0.201 + 0.137 + 0.0 avg prob of [ intersex organism] 0.8238176107406616
loss 0.24 = 0.001 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9993938207626343
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9979710578918457
loss 0.249 = 0.011 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9895128607749939
loss 0.268 = 0.03 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9707574248313904
loss 0.254 = 0.015 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9848440885543823
loss 0.245 = 0.007 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9933988451957703
loss 0.243 = 0.004 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9958910942077637
loss 0.242 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9967593550682068
loss 0.241 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.997196614742279
Init norm 12.686749458312988 | Delta norm 50.74699783325195 | Target norm 52.94290542602539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7470, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4567, device='cuda:0')
upd norm tensor(2.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7230, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4976, device='cuda:0')
upd norm tensor(2.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.6228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8382, device='cuda:0')
upd norm tensor(2.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9657, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1283, device='cuda:0')
upd norm tensor(2.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.4189, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8053, device='cuda:0')
upd norm tensor(3.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [2041 BC follows] -> [ 29668 Ipf]
Computing right vector (v)
Lookup index found: 6 | Sentence: 2041 BC follows 29668 I | Token: BC
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.78 = 6.78 + 0.0 + 0.0 avg prob of [ 29668 Ipf] 0.0011842688545584679
loss 5.645 = 5.42 + 0.225 + 0.0 avg prob of [ 29668 Ipf] 0.004440009593963623
loss 4.847 = 4.718 + 0.129 + 0.0 avg prob of [ 29668 Ipf] 0.00958884134888649
loss 3.992 = 3.855 + 0.137 + 0.0 avg prob of [ 29668 Ipf] 0.02176203392446041
loss 2.709 = 2.553 + 0.155 + 0.0 avg prob of [ 29668 Ipf] 0.08010239899158478
loss 1.658 = 1.493 + 0.164 + 0.0 avg prob of [ 29668 Ipf] 0.22878196835517883
loss 0.859 = 0.706 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.5008167624473572
loss 0.467 = 0.314 + 0.153 + 0.0 avg prob of [ 29668 Ipf] 0.7312717437744141
loss 0.305 = 0.153 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.8584901094436646
loss 0.217 = 0.059 + 0.157 + 0.0 avg prob of [ 29668 Ipf] 0.9424829483032227
loss 0.176 = 0.019 + 0.156 + 0.0 avg prob of [ 29668 Ipf] 0.9809708595275879
loss 0.168 = 0.009 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9908093810081482
loss 0.165 = 0.006 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9937031269073486
loss 0.163 = 0.004 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9961495399475098
loss 0.162 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9975597858428955
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9981834292411804
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9985010027885437
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9986904859542847
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9988631010055542
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9990620613098145
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9992455244064331
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9993878602981567
loss 0.159 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9994925856590271
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9995701313018799
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.999629020690918
Init norm 12.345292091369629 | Delta norm 49.38117218017578 | Target norm 51.165740966796875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3812, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4836, device='cuda:0')
upd norm tensor(2.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.5944, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5201, device='cuda:0')
upd norm tensor(2.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.3130, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8602, device='cuda:0')
upd norm tensor(2.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.6083, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1596, device='cuda:0')
upd norm tensor(2.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.2423, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8637, device='cuda:0')
upd norm tensor(3.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1981 Lithuanian Badminton Championships ‚Äì women's singles follows] -> [ Loschge, Friedrich Heinrich]
Computing right vector (v)
Lookup index found: 17 | Sentence: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows Loschge, Friedrich | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.49 = 8.49 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.00022668617020826787
loss 6.503 = 6.296 + 0.207 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0019449219107627869
loss 5.135 = 5.135 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0066849044524133205
loss 3.276 = 2.881 + 0.395 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.056303467601537704
loss 1.624 = 1.617 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.20898878574371338
loss 0.604 = 0.601 + 0.003 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.568875253200531
loss 0.294 = 0.285 + 0.009 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.7627280950546265
loss 0.136 = 0.091 + 0.044 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9188784956932068
loss 0.136 = 0.057 + 0.078 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9482223391532898
loss 0.101 = 0.077 + 0.023 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9353789687156677
loss 0.105 = 0.097 + 0.008 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9234482049942017
loss 0.106 = 0.099 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9230228662490845
loss 0.097 = 0.083 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9329265356063843
loss 0.098 = 0.063 + 0.035 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9468004107475281
loss 0.101 = 0.058 + 0.042 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9499897360801697
loss 0.094 = 0.073 + 0.02 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.939834475517273
loss 0.097 = 0.086 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9318189024925232
loss 0.096 = 0.085 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9324424266815186
loss 0.093 = 0.073 + 0.019 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9400944709777832
loss 0.095 = 0.062 + 0.032 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9475826621055603
loss 0.094 = 0.064 + 0.03 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9465584754943848
loss 0.092 = 0.074 + 0.018 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9399330019950867
loss 0.094 = 0.08 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9359598159790039
loss 0.093 = 0.077 + 0.015 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9377471804618835
loss 0.092 = 0.069 + 0.022 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9431607127189636
Init norm 14.525349617004395 | Delta norm 58.10139846801758 | Target norm 59.97038650512695


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(58.1014, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5071, device='cuda:0')
upd norm tensor(2.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5289, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5397, device='cuda:0')
upd norm tensor(2.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(49.7651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8816, device='cuda:0')
upd norm tensor(2.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(42.7677, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1878, device='cuda:0')
upd norm tensor(3.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(33.3730, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.9184, device='cuda:0')
upd norm tensor(4.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Anna Sophie Gasteiger is] -> [ mƒÅh≈´]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Anna Sophie Gasteiger is mƒÅh | Token: iger
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.405 = 7.405 + 0.0 + 0.0 avg prob of [ mƒÅh≈´] 0.0006433886010199785
loss 4.965 = 4.676 + 0.289 + 0.0 avg prob of [ mƒÅh≈´] 0.00943743996322155
loss 3.815 = 3.524 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.030633440241217613
loss 2.935 = 2.651 + 0.284 + 0.0 avg prob of [ mƒÅh≈´] 0.07068447023630142
loss 2.146 = 1.867 + 0.278 + 0.0 avg prob of [ mƒÅh≈´] 0.1552438586950302
loss 1.009 = 0.732 + 0.276 + 0.0 avg prob of [ mƒÅh≈´] 0.48104676604270935
loss 0.567 = 0.275 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.7600362300872803
loss 0.399 = 0.107 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.8993332386016846
loss 0.346 = 0.055 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.9462100863456726
loss 0.333 = 0.043 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.9579676389694214
loss 0.31 = 0.022 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9777737855911255
loss 0.276 = 0.025 + 0.25 + 0.0 avg prob of [ mƒÅh≈´] 0.9750882983207703
loss 0.759 = 0.63 + 0.128 + 0.0 avg prob of [ mƒÅh≈´] 0.5337220430374146
loss 0.274 = 0.041 + 0.232 + 0.0 avg prob of [ mƒÅh≈´] 0.9595615267753601
loss 0.299 = 0.023 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.977741003036499
loss 0.313 = 0.028 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9727442264556885
loss 0.306 = 0.018 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9822020530700684
loss 0.299 = 0.011 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9888372421264648
loss 0.296 = 0.008 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9917187094688416
loss 0.294 = 0.007 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9931774139404297
loss 0.292 = 0.006 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9939765334129333
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ mƒÅh≈´] 0.9942785501480103
loss 0.283 = 0.006 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.9938420057296753
loss 0.274 = 0.009 + 0.265 + 0.0 avg prob of [ mƒÅh≈´] 0.9915284514427185
loss 0.259 = 0.017 + 0.242 + 0.0 avg prob of [ mƒÅh≈´] 0.9831792712211609
Init norm 12.60416030883789 | Delta norm 50.41664123535156 | Target norm 52.078067779541016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.4166, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5367, device='cuda:0')
upd norm tensor(2.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7990, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5681, device='cuda:0')
upd norm tensor(2.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.2389, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9104, device='cuda:0')
upd norm tensor(2.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.3852, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2290, device='cuda:0')
upd norm tensor(2.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0085, device='cuda:0')
upd norm tensor(3.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jae-Duk Han is] -> [ bigender]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Jae-Duk Han is big | Token: Han
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.68 = 8.68 + 0.0 + 0.0 avg prob of [ bigender] 0.00020638955174945295
loss 5.637 = 5.468 + 0.168 + 0.0 avg prob of [ bigender] 0.004985661245882511
loss 3.601 = 3.265 + 0.335 + 0.0 avg prob of [ bigender] 0.03895954787731171
loss 1.156 = 0.82 + 0.336 + 0.0 avg prob of [ bigender] 0.44149231910705566
loss 0.783 = 0.446 + 0.336 + 0.0 avg prob of [ bigender] 0.6658896803855896
loss 0.361 = 0.021 + 0.34 + 0.0 avg prob of [ bigender] 0.979139506816864
loss 0.455 = 0.119 + 0.336 + 0.0 avg prob of [ bigender] 0.8885301351547241
loss 0.361 = 0.025 + 0.336 + 0.0 avg prob of [ bigender] 0.9757952690124512
loss 0.34 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9957816004753113
loss 0.339 = 0.004 + 0.335 + 0.0 avg prob of [ bigender] 0.996435821056366
loss 0.338 = 0.004 + 0.334 + 0.0 avg prob of [ bigender] 0.9957695007324219
loss 0.337 = 0.004 + 0.333 + 0.0 avg prob of [ bigender] 0.9957097768783569
loss 0.335 = 0.004 + 0.331 + 0.0 avg prob of [ bigender] 0.996068000793457
loss 0.331 = 0.004 + 0.327 + 0.0 avg prob of [ bigender] 0.9960777163505554
loss 0.303 = 0.007 + 0.296 + 0.0 avg prob of [ bigender] 0.9933030605316162
loss 0.606 = 0.383 + 0.223 + 0.0 avg prob of [ bigender] 0.7007762789726257
loss 0.337 = 0.001 + 0.336 + 0.0 avg prob of [ bigender] 0.9991363286972046
loss 0.345 = 0.008 + 0.336 + 0.0 avg prob of [ bigender] 0.9918235540390015
loss 0.374 = 0.038 + 0.336 + 0.0 avg prob of [ bigender] 0.9630802869796753
loss 0.388 = 0.051 + 0.336 + 0.0 avg prob of [ bigender] 0.9502453804016113
loss 0.361 = 0.024 + 0.336 + 0.0 avg prob of [ bigender] 0.9763194918632507
loss 0.346 = 0.009 + 0.336 + 0.0 avg prob of [ bigender] 0.9907026290893555
loss 0.342 = 0.005 + 0.336 + 0.0 avg prob of [ bigender] 0.9948294162750244
loss 0.341 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9960918426513672
loss 0.34 = 0.003 + 0.336 + 0.0 avg prob of [ bigender] 0.9966716766357422
Init norm 10.899991035461426 | Delta norm 43.5999641418457 | Target norm 45.193443298339844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.6000, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5658, device='cuda:0')
upd norm tensor(2.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.8688, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5918, device='cuda:0')
upd norm tensor(2.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.7623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9320, device='cuda:0')
upd norm tensor(2.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.9333, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2587, device='cuda:0')
upd norm tensor(2.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.4764, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0673, device='cuda:0')
upd norm tensor(3.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of death of Ray Wietecha is] -> [ Sta√üfurt]
Computing right vector (v)
Lookup index found: 10 | Sentence: The place of death of Ray Wietecha is Sta√ü | Token: a
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.11 = 8.11 + 0.0 + 0.0 avg prob of [ Sta√üfurt] 0.00032989942701533437
loss 6.402 = 6.284 + 0.118 + 0.0 avg prob of [ Sta√üfurt] 0.0019462056225165725
loss 5.162 = 4.853 + 0.309 + 0.0 avg prob of [ Sta√üfurt] 0.008369509130716324
loss 3.768 = 3.456 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.03495211526751518
loss 1.646 = 1.333 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.27931803464889526
loss 0.441 = 0.125 + 0.316 + 0.0 avg prob of [ Sta√üfurt] 0.8839200735092163
loss 0.354 = 0.041 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9601842761039734
loss 0.327 = 0.014 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.986103892326355
loss 0.32 = 0.006 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9937331080436707
loss 0.317 = 0.004 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9962098002433777
loss 0.316 = 0.003 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9972167015075684
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.997802197933197
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9982465505599976
loss 0.315 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9985891580581665
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9988359808921814
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9990048408508301
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.999117374420166
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9991900324821472
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9992321729660034
loss 0.314 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.9992437362670898
loss 0.313 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.999208927154541
loss 0.312 = 0.001 + 0.311 + 0.0 avg prob of [ Sta√üfurt] 0.9990455508232117
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9979442358016968
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9976019859313965
loss 0.314 = 0.0 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9995888471603394
Init norm 10.969701766967773 | Delta norm 43.878807067871094 | Target norm 45.10775375366211


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.8788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5856, device='cuda:0')
upd norm tensor(2.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.3918, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6083, device='cuda:0')
upd norm tensor(2.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.3447, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9485, device='cuda:0')
upd norm tensor(2.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(31.6848, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2807, device='cuda:0')
upd norm tensor(2.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.0379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1120, device='cuda:0')
upd norm tensor(3.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is] -> [ Russian State]
Computing right vector (v)
Lookup index found: 30 | Sentence: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is Russian | Token: doubles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.626 = 9.626 + 0.0 + 0.0 avg prob of [ Russian State] 0.0001487217377871275
loss 7.566 = 6.693 + 0.873 + 0.0 avg prob of [ Russian State] 0.0013882662169635296
loss 2.976 = 2.613 + 0.363 + 0.0 avg prob of [ Russian State] 0.07479877024888992
loss 2.423 = 2.421 + 0.002 + 0.0 avg prob of [ Russian State] 0.0907687395811081
loss 1.257 = 1.251 + 0.005 + 0.0 avg prob of [ Russian State] 0.28735417127609253
loss 0.474 = 0.429 + 0.046 + 0.0 avg prob of [ Russian State] 0.6543459296226501
loss 0.14 = 0.116 + 0.024 + 0.0 avg prob of [ Russian State] 0.8908494710922241
loss 0.068 = 0.042 + 0.025 + 0.0 avg prob of [ Russian State] 0.9586191177368164
loss 0.054 = 0.023 + 0.031 + 0.0 avg prob of [ Russian State] 0.9769591093063354
loss 0.053 = 0.019 + 0.034 + 0.0 avg prob of [ Russian State] 0.981724202632904
loss 0.048 = 0.015 + 0.033 + 0.0 avg prob of [ Russian State] 0.9849858283996582
Init norm 33.36102294921875 | Delta norm 127.69489288330078 | Target norm 134.28440856933594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(127.6949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.6075, device='cuda:0')
upd norm tensor(5.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(120.0359, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6264, device='cuda:0')
upd norm tensor(6.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(106.8882, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9650, device='cuda:0')
upd norm tensor(6.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(89.1822, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.3029, device='cuda:0')
upd norm tensor(6.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(67.0065, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1598, device='cuda:0')
upd norm tensor(9.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 81st Missouri General Assembly is associated with is] -> [ Ostikanate of Arminiya]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which 81st Missouri General Assembly is associated with is Ostikanate of Armini | Token: Assembly
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.707 = 7.707 + 0.0 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.00048599415458738804
loss 7.336 = 6.999 + 0.337 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0009601075435057282
loss 6.435 = 6.266 + 0.169 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0019966831896454096
loss 5.049 = 4.923 + 0.125 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.007588856853544712
loss 3.134 = 3.06 + 0.074 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.047306403517723083
loss 1.545 = 1.467 + 0.077 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.23186489939689636
loss 0.403 = 0.304 + 0.099 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.7414726614952087
loss 0.138 = 0.059 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9431867003440857
loss 0.11 = 0.03 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9708948135375977
loss 0.089 = 0.008 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9915426969528198
loss 0.084 = 0.004 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9959759712219238
loss 0.083 = 0.003 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9974373579025269
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9981023669242859
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9984511733055115
loss 0.081 = 0.001 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.998671293258667
loss 0.081 = 0.001 + 0.079 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9988362193107605
loss 0.079 = 0.001 + 0.078 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9989756345748901
loss 0.037 = 0.001 + 0.035 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9991167783737183
Init norm 12.339568138122559 | Delta norm 49.3582763671875 | Target norm 50.52494812011719


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3583, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7519, device='cuda:0')
upd norm tensor(2.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.2671, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.7815, device='cuda:0')
upd norm tensor(2.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.0074, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1257, device='cuda:0')
upd norm tensor(2.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.5179, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.4959, device='cuda:0')
upd norm tensor(2.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.5396, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5267, device='cuda:0')
upd norm tensor(3.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Juliette K Berg is] -> [ male]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Juliette K Berg is | Token: Berg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.927 = 4.927 + 0.0 + 0.0 avg prob of [ male] 0.013017235323786736
loss 1.62 = 1.288 + 0.332 + 0.0 avg prob of [ male] 0.2843583822250366
loss 0.446 = 0.112 + 0.333 + 0.0 avg prob of [ male] 0.8939832448959351
loss 0.373 = 0.101 + 0.271 + 0.0 avg prob of [ male] 0.9038752317428589
loss 0.343 = 0.121 + 0.221 + 0.0 avg prob of [ male] 0.8865127563476562
loss 0.274 = 0.043 + 0.23 + 0.0 avg prob of [ male] 0.9577230215072632
loss 0.2 = 0.031 + 0.169 + 0.0 avg prob of [ male] 0.9693690538406372
loss 0.165 = 0.023 + 0.142 + 0.0 avg prob of [ male] 0.9775354266166687
loss 0.147 = 0.016 + 0.131 + 0.0 avg prob of [ male] 0.9842368960380554
loss 0.144 = 0.011 + 0.132 + 0.0 avg prob of [ male] 0.9890469908714294
loss 0.142 = 0.008 + 0.134 + 0.0 avg prob of [ male] 0.9921433329582214
loss 0.14 = 0.006 + 0.133 + 0.0 avg prob of [ male] 0.9940770864486694
loss 0.135 = 0.005 + 0.13 + 0.0 avg prob of [ male] 0.9953163862228394
loss 0.128 = 0.004 + 0.124 + 0.0 avg prob of [ male] 0.9961462020874023
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9967252612113953
loss 0.117 = 0.003 + 0.114 + 0.0 avg prob of [ male] 0.9971455335617065
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9974682331085205
loss 0.118 = 0.002 + 0.116 + 0.0 avg prob of [ male] 0.9977153539657593
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9979001879692078
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9980413317680359
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9981523752212524
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9982445240020752
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9983258247375488
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.9984009265899658
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.998471736907959
Init norm 11.058765411376953 | Delta norm 44.23506164550781 | Target norm 45.5366325378418


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.2351, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7751, device='cuda:0')
upd norm tensor(2.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.3903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8017, device='cuda:0')
upd norm tensor(2.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.4831, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1461, device='cuda:0')
upd norm tensor(2.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.9040, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5236, device='cuda:0')
upd norm tensor(2.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3948, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5882, device='cuda:0')
upd norm tensor(3.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Naniwaman is] -> [ cardinal-deacon]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Naniwaman is cardinal-de | Token: aman
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.446 = 6.446 + 0.0 + 0.0 avg prob of [ cardinal-deacon] 0.0016523947706446052
loss 3.906 = 3.669 + 0.237 + 0.0 avg prob of [ cardinal-deacon] 0.026458226144313812
loss 1.329 = 1.095 + 0.233 + 0.0 avg prob of [ cardinal-deacon] 0.33627554774284363
loss 0.328 = 0.087 + 0.241 + 0.0 avg prob of [ cardinal-deacon] 0.9199651479721069
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9971021413803101
loss 0.25 = 0.006 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9944992065429688
loss 0.248 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9968565702438354
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9981937408447266
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9987187385559082
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9990100264549255
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9992170333862305
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9993748068809509
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9994933605194092
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9995803833007812
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996436834335327
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996897578239441
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997234344482422
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997481107711792
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997661113739014
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997789263725281
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997875094413757
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997925758361816
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997941851615906
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997922778129578
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.999786376953125
Init norm 11.370737075805664 | Delta norm 45.482948303222656 | Target norm 47.17446517944336


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.4829, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7972, device='cuda:0')
upd norm tensor(2.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.2449, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8190, device='cuda:0')
upd norm tensor(2.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.4106, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1628, device='cuda:0')
upd norm tensor(2.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3344, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5459, device='cuda:0')
upd norm tensor(2.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.7681, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6391, device='cuda:0')
upd norm tensor(3.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Divina Eterna Cardoso is] -> [ takatƒÅpui]
Computing right vector (v)
Lookup index found: 10 | Sentence: The gender of Divina Eterna Cardoso is takatƒÅp | Token: oso
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.127 = 5.127 + 0.0 + 0.0 avg prob of [ takatƒÅpui] 0.006581449415534735
loss 3.584 = 3.313 + 0.272 + 0.0 avg prob of [ takatƒÅpui] 0.03731798380613327
loss 1.992 = 1.714 + 0.278 + 0.0 avg prob of [ takatƒÅpui] 0.18343767523765564
loss 1.092 = 0.823 + 0.269 + 0.0 avg prob of [ takatƒÅpui] 0.4407960772514343
loss 0.334 = 0.039 + 0.294 + 0.0 avg prob of [ takatƒÅpui] 0.9613143801689148
loss 0.289 = 0.008 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.9920060038566589
loss 0.29 = 0.009 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.991512656211853
loss 0.29 = 0.008 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9920692443847656
loss 0.287 = 0.005 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9946774244308472
loss 0.285 = 0.003 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9966756105422974
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9977490901947021
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9983119964599609
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998626172542572
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9988164901733398
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998940646648407
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9990249872207642
loss 0.283 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9990801215171814
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9991041421890259
loss 0.281 = 0.001 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.9990624189376831
loss 0.265 = 0.002 + 0.263 + 0.0 avg prob of [ takatƒÅpui] 0.9984075427055359
loss 0.937 = 0.592 + 0.345 + 0.0 avg prob of [ takatƒÅpui] 0.5611640810966492
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9986989498138428
loss 0.315 = 0.033 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9676880836486816
loss 0.456 = 0.175 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.8415685892105103
loss 0.288 = 0.008 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.99164217710495
Init norm 11.80569076538086 | Delta norm 47.22276306152344 | Target norm 49.668312072753906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8208, device='cuda:0')
upd norm tensor(2.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6906, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8379, device='cuda:0')
upd norm tensor(2.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.0051, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1803, device='cuda:0')
upd norm tensor(2.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.8471, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5685, device='cuda:0')
upd norm tensor(2.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.7429, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6846, device='cuda:0')
upd norm tensor(3.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Michael S German is] -> [ planetary geologist]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Michael S German is planetary ge | Token: German
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.725 = 3.725 + 0.0 + 0.0 avg prob of [ planetary geologist] 0.02517147921025753
loss 2.641 = 2.434 + 0.207 + 0.0 avg prob of [ planetary geologist] 0.08804760873317719
loss 1.806 = 1.598 + 0.208 + 0.0 avg prob of [ planetary geologist] 0.20411810278892517
loss 0.466 = 0.257 + 0.209 + 0.0 avg prob of [ planetary geologist] 0.7757920622825623
loss 0.268 = 0.056 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.946293830871582
loss 0.225 = 0.014 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9861539602279663
loss 0.215 = 0.004 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9958369135856628
loss 0.213 = 0.002 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9978756904602051
loss 0.213 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9985741376876831
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9989117383956909
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9991071224212646
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9992337226867676
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993224143981934
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993886351585388
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994404315948486
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994828104972839
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995183944702148
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995490908622742
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995759725570679
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995998740196228
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996213912963867
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996408224105835
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996585845947266
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996747970581055
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996895790100098
Init norm 11.96147632598877 | Delta norm 47.845909118652344 | Target norm 49.5956916809082


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.8459, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8457, device='cuda:0')
upd norm tensor(2.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.3819, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8558, device='cuda:0')
upd norm tensor(2.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9616, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1976, device='cuda:0')
upd norm tensor(2.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9249, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5913, device='cuda:0')
upd norm tensor(2.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7357, device='cuda:0')
upd norm tensor(3.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [Lange, Reinerus follows] -> [ 1971 Western Australian state election]
Computing right vector (v)
Lookup index found: 6 | Sentence: Lange, Reinerus follows 1971 Western Australian state | Token: us
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.31 = 4.31 + 0.0 + 0.0 avg prob of [ 1971 Western Australian state election] 0.013672824017703533
loss 3.36 = 3.284 + 0.075 + 0.0 avg prob of [ 1971 Western Australian state election] 0.038747385144233704
loss 3.313 = 2.925 + 0.388 + 0.0 avg prob of [ 1971 Western Australian state election] 0.05619245022535324
loss 2.037 = 1.943 + 0.094 + 0.0 avg prob of [ 1971 Western Australian state election] 0.144039586186409
loss 0.989 = 0.964 + 0.024 + 0.0 avg prob of [ 1971 Western Australian state election] 0.3823893964290619
loss 0.371 = 0.343 + 0.027 + 0.0 avg prob of [ 1971 Western Australian state election] 0.7097872495651245
loss 0.085 = 0.059 + 0.026 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9426312446594238
loss 0.037 = 0.012 + 0.025 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9884194731712341
Init norm 12.124625205993652 | Delta norm 48.49850082397461 | Target norm 50.35892105102539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.4985, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8699, device='cuda:0')
upd norm tensor(2.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.5661, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8746, device='cuda:0')
upd norm tensor(2.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.2362, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2167, device='cuda:0')
upd norm tensor(2.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7111, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6180, device='cuda:0')
upd norm tensor(2.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.9511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7972, device='cuda:0')
upd norm tensor(3.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mark Van Guilder is] -> [ slam poetry]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Mark Van Guilder is slam | Token: ilder
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.384 = 5.384 + 0.0 + 0.0 avg prob of [ slam poetry] 0.004766244441270828
loss 3.037 = 2.797 + 0.24 + 0.0 avg prob of [ slam poetry] 0.06143198907375336
loss 1.79 = 1.543 + 0.247 + 0.0 avg prob of [ slam poetry] 0.22275714576244354
loss 0.299 = 0.047 + 0.252 + 0.0 avg prob of [ slam poetry] 0.9550265073776245
loss 0.269 = 0.017 + 0.252 + 0.0 avg prob of [ slam poetry] 0.9836425185203552
loss 0.26 = 0.009 + 0.251 + 0.0 avg prob of [ slam poetry] 0.9912114143371582
loss 0.252 = 0.007 + 0.246 + 0.0 avg prob of [ slam poetry] 0.9935025572776794
loss 0.246 = 0.012 + 0.233 + 0.0 avg prob of [ slam poetry] 0.9878050088882446
loss 0.244 = 0.003 + 0.24 + 0.0 avg prob of [ slam poetry] 0.9967028498649597
loss 0.234 = 0.003 + 0.231 + 0.0 avg prob of [ slam poetry] 0.9971213340759277
loss 0.249 = 0.007 + 0.242 + 0.0 avg prob of [ slam poetry] 0.9935046434402466
loss 0.233 = 0.003 + 0.23 + 0.0 avg prob of [ slam poetry] 0.9974972605705261
loss 0.217 = 0.004 + 0.213 + 0.0 avg prob of [ slam poetry] 0.9963415861129761
loss 0.175 = 0.017 + 0.158 + 0.0 avg prob of [ slam poetry] 0.9836593866348267
loss 0.173 = 0.035 + 0.138 + 0.0 avg prob of [ slam poetry] 0.9659066200256348
loss 0.122 = 0.015 + 0.106 + 0.0 avg prob of [ slam poetry] 0.9851416349411011
loss 0.084 = 0.012 + 0.072 + 0.0 avg prob of [ slam poetry] 0.9878368377685547
loss 0.057 = 0.013 + 0.044 + 0.0 avg prob of [ slam poetry] 0.9874358177185059
loss 0.044 = 0.01 + 0.034 + 0.0 avg prob of [ slam poetry] 0.990354061126709
Init norm 12.439826965332031 | Delta norm 49.759307861328125 | Target norm 51.69750213623047


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.7593, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8955, device='cuda:0')
upd norm tensor(2.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.8694, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8955, device='cuda:0')
upd norm tensor(2.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.8197, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2376, device='cuda:0')
upd norm tensor(2.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9136, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6441, device='cuda:0')
upd norm tensor(2.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.3955, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.8502, device='cuda:0')
upd norm tensor(3.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the employer of Momodou W Jallow is] -> [ Athersys]
Computing right vector (v)
Lookup index found: 14 | Sentence: The name of the employer of Momodou W Jallow is Athers | Token: allow
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.385 = 5.385 + 0.0 + 0.0 avg prob of [ Athersys] 0.004730091895908117
loss 3.802 = 3.556 + 0.246 + 0.0 avg prob of [ Athersys] 0.02869408391416073
loss 2.993 = 2.75 + 0.243 + 0.0 avg prob of [ Athersys] 0.06412670016288757
loss 1.79 = 1.547 + 0.242 + 0.0 avg prob of [ Athersys] 0.21574360132217407
loss 0.348 = 0.111 + 0.237 + 0.0 avg prob of [ Athersys] 0.8961483240127563
loss 0.368 = 0.13 + 0.237 + 0.0 avg prob of [ Athersys] 0.8835222721099854
loss 0.251 = 0.006 + 0.244 + 0.0 avg prob of [ Athersys] 0.9935626983642578
loss 0.256 = 0.012 + 0.244 + 0.0 avg prob of [ Athersys] 0.9879190325737
loss 0.26 = 0.015 + 0.244 + 0.0 avg prob of [ Athersys] 0.9848731756210327
loss 0.254 = 0.01 + 0.244 + 0.0 avg prob of [ Athersys] 0.990190863609314
loss 0.249 = 0.005 + 0.244 + 0.0 avg prob of [ Athersys] 0.9948327541351318
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ Athersys] 0.997098445892334
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ Athersys] 0.9981780052185059
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9987430572509766
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9990692138671875
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9992728233337402
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9994084239006042
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.999503493309021
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9995729327201843
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996254444122314
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996663928031921
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996992349624634
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997259974479675
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997484087944031
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997674226760864
Init norm 12.712177276611328 | Delta norm 50.84870910644531 | Target norm 52.761817932128906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.8487, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9241, device='cuda:0')
upd norm tensor(2.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(47.1956, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9162, device='cuda:0')
upd norm tensor(2.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(43.6818, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2590, device='cuda:0')
upd norm tensor(2.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.1947, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6705, device='cuda:0')
upd norm tensor(2.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.6091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.9029, device='cuda:0')
upd norm tensor(4.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Ole Kassow is] -> [ sch]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Ole Kassow is | Token: ow
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.129 = 9.129 + 0.0 + 0.0 avg prob of [ sch] 0.0001222451974172145
loss 6.983 = 6.787 + 0.196 + 0.0 avg prob of [ sch] 0.0013105341931805015
loss 3.52 = 3.309 + 0.211 + 0.0 avg prob of [ sch] 0.038881219923496246
loss 0.995 = 0.775 + 0.219 + 0.0 avg prob of [ sch] 0.5305520296096802
loss 0.287 = 0.036 + 0.251 + 0.0 avg prob of [ sch] 0.965209424495697
loss 0.226 = 0.005 + 0.221 + 0.0 avg prob of [ sch] 0.9947234988212585
loss 0.226 = 0.005 + 0.221 + 0.0 avg prob of [ sch] 0.9953069686889648
loss 0.225 = 0.003 + 0.222 + 0.0 avg prob of [ sch] 0.9966985583305359
loss 0.224 = 0.002 + 0.222 + 0.0 avg prob of [ sch] 0.9979285001754761
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.99857497215271
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9989013075828552
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9990841746330261
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9992000460624695
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9992815852165222
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.999343752861023
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9993935823440552
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9994351267814636
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9994701743125916
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9995001554489136
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995259046554565
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995478987693787
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995663166046143
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995816946029663
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995934963226318
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.999602198600769
Init norm 11.433003425598145 | Delta norm 45.73201370239258 | Target norm 47.95664978027344


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.7320, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9527, device='cuda:0')
upd norm tensor(2.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.5960, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9389, device='cuda:0')
upd norm tensor(2.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2653, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2808, device='cuda:0')
upd norm tensor(2.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.8485, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7011, device='cuda:0')
upd norm tensor(2.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9902, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.9679, device='cuda:0')
upd norm tensor(3.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which St John's Church, Kingston upon Thames is associated with is] -> [ Gibraltar]
Computing right vector (v)
Lookup index found: 17 | Sentence: The name of the country which St John's Church, Kingston upon Thames is associated with is Gibral | Token: ames
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.298 = 4.298 + 0.0 + 0.0 avg prob of [ Gibraltar] 0.015319382771849632
loss 2.999 = 2.988 + 0.011 + 0.0 avg prob of [ Gibraltar] 0.05356225371360779
loss 1.369 = 1.226 + 0.142 + 0.0 avg prob of [ Gibraltar] 0.294547438621521
loss 0.718 = 0.615 + 0.102 + 0.0 avg prob of [ Gibraltar] 0.541500449180603
loss 0.082 = 0.079 + 0.003 + 0.0 avg prob of [ Gibraltar] 0.9245011806488037
loss 0.013 = 0.01 + 0.003 + 0.0 avg prob of [ Gibraltar] 0.9897813200950623
Init norm 13.042048454284668 | Delta norm 52.16819381713867 | Target norm 53.993743896484375


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.1682, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9778, device='cuda:0')
upd norm tensor(2.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(48.0612, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9577, device='cuda:0')
upd norm tensor(2.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(44.0709, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.3002, device='cuda:0')
upd norm tensor(2.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.5242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7265, device='cuda:0')
upd norm tensor(2.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.9623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.0219, device='cuda:0')
upd norm tensor(4.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1991 Slovenian Badminton Championships ‚Äì men's singles is followed by] -> [ 15 Shevat]
Computing right vector (v)
Lookup index found: 16 | Sentence: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by 15 She | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.689 = 9.689 + 0.0 + 0.0 avg prob of [ 15 Shevat] 6.616504106204957e-05
loss 5.981 = 5.979 + 0.002 + 0.0 avg prob of [ 15 Shevat] 0.0025774515233933926
loss 3.648 = 3.312 + 0.336 + 0.0 avg prob of [ 15 Shevat] 0.03712953254580498
loss 2.013 = 1.432 + 0.581 + 0.0 avg prob of [ 15 Shevat] 0.240681454539299
loss 1.765 = 1.752 + 0.012 + 0.0 avg prob of [ 15 Shevat] 0.18045674264431
loss 0.904 = 0.897 + 0.006 + 0.0 avg prob of [ 15 Shevat] 0.40934890508651733
loss 0.6 = 0.596 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.5511816740036011
loss 0.507 = 0.503 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.6052403450012207
loss 0.397 = 0.392 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.6766826510429382
loss 0.212 = 0.206 + 0.006 + 0.0 avg prob of [ 15 Shevat] 0.8147757053375244
loss 0.099 = 0.09 + 0.009 + 0.0 avg prob of [ 15 Shevat] 0.9140595197677612
loss 0.059 = 0.054 + 0.005 + 0.0 avg prob of [ 15 Shevat] 0.9475530385971069
loss 0.627 = 0.04 + 0.587 + 0.0 avg prob of [ 15 Shevat] 0.9609379172325134
loss 0.621 = 0.031 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9695281982421875
loss 0.614 = 0.024 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.976396918296814
loss 0.609 = 0.018 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9817742705345154
loss 0.605 = 0.014 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9858433604240417
loss 0.602 = 0.011 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9888870120048523
loss 0.599 = 0.009 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9911757707595825
loss 0.598 = 0.007 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9929158687591553
loss 0.596 = 0.006 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9942519068717957
loss 0.595 = 0.005 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9952844381332397
loss 0.595 = 0.004 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9960860013961792
loss 0.594 = 0.003 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9967107772827148
loss 0.594 = 0.003 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9972002506256104
Init norm 87.39752960205078 | Delta norm 182.8380889892578 | Target norm 201.1997833251953


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(182.8381, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.0019, device='cuda:0')
upd norm tensor(8.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(168.2331, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9798, device='cuda:0')
upd norm tensor(8.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(150.2725, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.3209, device='cuda:0')
upd norm tensor(8.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(124.2556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7563, device='cuda:0')
upd norm tensor(9.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(91.4618, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.0875, device='cuda:0')
upd norm tensor(13.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Andrea Procaccini is] -> [ txistulari]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Andrea Procaccini is txistular | Token: ini
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.45 = 6.45 + 0.0 + 0.0 avg prob of [ txistulari] 0.0016273934161290526
loss 5.013 = 4.714 + 0.299 + 0.0 avg prob of [ txistulari] 0.009086843580007553
loss 3.173 = 2.876 + 0.296 + 0.0 avg prob of [ txistulari] 0.057488828897476196
loss 1.749 = 1.448 + 0.301 + 0.0 avg prob of [ txistulari] 0.2364368885755539
loss 0.359 = 0.058 + 0.301 + 0.0 avg prob of [ txistulari] 0.9440888166427612
loss 0.309 = 0.008 + 0.301 + 0.0 avg prob of [ txistulari] 0.9921061396598816
loss 0.308 = 0.009 + 0.299 + 0.0 avg prob of [ txistulari] 0.9914130568504333
loss 0.312 = 0.015 + 0.297 + 0.0 avg prob of [ txistulari] 0.9855289459228516
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ txistulari] 0.9960465431213379
loss 0.304 = 0.002 + 0.301 + 0.0 avg prob of [ txistulari] 0.9975084066390991
loss 0.303 = 0.002 + 0.301 + 0.0 avg prob of [ txistulari] 0.9983323812484741
loss 0.303 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9988102912902832
loss 0.303 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9990891814231873
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9992582201957703
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9993678331375122
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9994451403617859
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9995050430297852
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9995549917221069
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.999598503112793
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9996370673179626
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.999671220779419
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997013807296753
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997274279594421
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997493624687195
loss 0.301 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997669458389282
Init norm 11.763127326965332 | Delta norm 47.05250930786133 | Target norm 49.01865768432617


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.0525, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.2950, device='cuda:0')
upd norm tensor(2.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8854, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3143, device='cuda:0')
upd norm tensor(2.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.6501, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.6779, device='cuda:0')
upd norm tensor(2.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.8537, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.1807, device='cuda:0')
upd norm tensor(2.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.8670, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.8700, device='cuda:0')
upd norm tensor(3.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Chandrakumari Raghuram Shetty is] -> [ parent]
Computing right vector (v)
Lookup index found: 15 | Sentence: The occupation of Chandrakumari Raghuram Shetty is | Token: ty
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.985 = 7.985 + 0.0 + 0.0 avg prob of [ parent] 0.0004674027150031179
loss 4.498 = 4.217 + 0.28 + 0.0 avg prob of [ parent] 0.01579536870121956
loss 0.582 = 0.303 + 0.279 + 0.0 avg prob of [ parent] 0.7503764033317566
loss 0.29 = 0.011 + 0.279 + 0.0 avg prob of [ parent] 0.9895502924919128
loss 0.288 = 0.008 + 0.279 + 0.0 avg prob of [ parent] 0.9919706583023071
loss 0.286 = 0.007 + 0.28 + 0.0 avg prob of [ parent] 0.9934930205345154
loss 0.285 = 0.005 + 0.28 + 0.0 avg prob of [ parent] 0.9946960806846619
loss 0.285 = 0.004 + 0.28 + 0.0 avg prob of [ parent] 0.9956428408622742
loss 0.284 = 0.004 + 0.28 + 0.0 avg prob of [ parent] 0.9963879585266113
loss 0.284 = 0.003 + 0.28 + 0.0 avg prob of [ parent] 0.9969789385795593
loss 0.283 = 0.003 + 0.28 + 0.0 avg prob of [ parent] 0.9974524974822998
loss 0.283 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9978357553482056
loss 0.283 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9981479644775391
loss 0.282 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9984042644500732
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9986152052879333
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9987896680831909
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9989347457885742
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.999055802822113
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9991571307182312
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9992424845695496
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9993146657943726
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9993759989738464
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9994282722473145
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9994730353355408
loss 0.281 = 0.0 + 0.281 + 0.0 avg prob of [ parent] 0.9995114803314209
Init norm 13.074491500854492 | Delta norm 52.29796600341797 | Target norm 54.238468170166016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.2980, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.3199, device='cuda:0')
upd norm tensor(2.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.4811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3339, device='cuda:0')
upd norm tensor(2.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.2510, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.6974, device='cuda:0')
upd norm tensor(2.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(37.2580, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.2087, device='cuda:0')
upd norm tensor(2.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.9210, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.9289, device='cuda:0')
upd norm tensor(4.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is] -> [ Alfgeir L Kristjansson]
Computing right vector (v)
Lookup index found: 31 | Sentence: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is Alfgeir L Kristjans | Token: .
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.082 = 3.082 + 0.0 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.04651229828596115
loss 2.107 = 2.107 + 0.001 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.1267399936914444
loss 1.723 = 1.714 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.19268684089183807
loss 1.166 = 1.152 + 0.014 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.35579806566238403
loss 0.726 = 0.706 + 0.02 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.5806195735931396
loss 0.448 = 0.428 + 0.02 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.7850254774093628
loss 0.403 = 0.389 + 0.014 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8103610277175903
loss 0.379 = 0.369 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8198289275169373
loss 0.36 = 0.351 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8304077386856079
loss 0.35 = 0.34 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8365778923034668
loss 0.342 = 0.332 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8405164480209351
loss 0.334 = 0.325 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8434771299362183
loss 0.327 = 0.319 + 0.008 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.845919132232666
loss 0.32 = 0.313 + 0.007 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8480493426322937
loss 0.314 = 0.307 + 0.006 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8499929308891296
loss 0.308 = 0.302 + 0.006 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8518320918083191
loss 0.303 = 0.296 + 0.007 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.853611946105957
loss 0.297 = 0.29 + 0.008 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8553463816642761
loss 0.292 = 0.283 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8570266962051392
loss 0.288 = 0.278 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8586300611495972
loss 0.283 = 0.272 + 0.011 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8601328730583191
loss 0.279 = 0.267 + 0.012 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.861517608165741
loss 0.274 = 0.263 + 0.012 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8627757430076599
loss 0.27 = 0.259 + 0.011 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8639121055603027
loss 0.265 = 0.255 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8649436831474304
Init norm 2441.6005859375 | Delta norm 176.08560180664062 | Target norm 2450.856689453125


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(176.0856, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.3479, device='cuda:0')
upd norm tensor(5.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(175.4767, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3557, device='cuda:0')
upd norm tensor(7.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(175.4086, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.7172, device='cuda:0')
upd norm tensor(8.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(175.3629, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.2391, device='cuda:0')
upd norm tensor(11.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(175.3475, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(120.0073, device='cuda:0')
upd norm tensor(19.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country of citizenship of Leonardo Vinhas Ciacci is] -> [ Oman proper]
Computing right vector (v)
Lookup index found: 16 | Sentence: The name of the country of citizenship of Leonardo Vinhas Ciacci is Oman | Token: ci
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.394 = 8.394 + 0.0 + 0.0 avg prob of [ Oman proper] 0.0002580684667918831
loss 6.996 = 6.442 + 0.553 + 0.0 avg prob of [ Oman proper] 0.0017970171757042408
loss 5.363 = 5.156 + 0.207 + 0.0 avg prob of [ Oman proper] 0.005909072235226631
loss 4.666 = 4.457 + 0.208 + 0.0 avg prob of [ Oman proper] 0.013298685662448406
loss 3.677 = 3.476 + 0.201 + 0.0 avg prob of [ Oman proper] 0.03597036004066467
loss 2.444 = 2.241 + 0.203 + 0.0 avg prob of [ Oman proper] 0.10973219573497772
loss 0.957 = 0.733 + 0.224 + 0.0 avg prob of [ Oman proper] 0.4820084571838379
loss 0.31 = 0.046 + 0.264 + 0.0 avg prob of [ Oman proper] 0.9569969177246094
loss 0.257 = 0.003 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9966385364532471
loss 0.255 = 0.001 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9986310005187988
loss 0.254 = 0.002 + 0.252 + 0.0 avg prob of [ Oman proper] 0.9981508255004883
loss 0.255 = 0.002 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9976048469543457
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9984711408615112
loss 0.252 = 0.001 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9988211393356323
loss 0.25 = 0.001 + 0.248 + 0.0 avg prob of [ Oman proper] 0.9987620711326599
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ Oman proper] 0.9978898763656616
loss 0.292 = 0.044 + 0.248 + 0.0 avg prob of [ Oman proper] 0.9602669477462769
loss 0.25 = 0.002 + 0.247 + 0.0 avg prob of [ Oman proper] 0.9975436925888062
loss 0.253 = 0.003 + 0.249 + 0.0 avg prob of [ Oman proper] 0.9966103434562683
loss 0.253 = 0.003 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9971587061882019
loss 0.253 = 0.002 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9977290034294128
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9980096817016602
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9981595277786255
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9982649683952332
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.998348593711853
Init norm 12.045663833618164 | Delta norm 48.182655334472656 | Target norm 49.346900939941406


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.1827, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.4758, device='cuda:0')
upd norm tensor(2.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.7562, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.5517, device='cuda:0')
upd norm tensor(2.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.0017, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.9805, device='cuda:0')
upd norm tensor(2.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8059, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(2.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2779, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.6042, device='cuda:0')
upd norm tensor(3.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Phillip Hodson is] -> [ intersex]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Phillip Hodson is inter | Token: son
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.249 = 6.249 + 0.0 + 0.0 avg prob of [ intersex] 0.0021857465617358685
loss 4.185 = 3.932 + 0.252 + 0.0 avg prob of [ intersex] 0.024452952668070793
loss 1.751 = 1.523 + 0.228 + 0.0 avg prob of [ intersex] 0.22625812888145447
loss 0.583 = 0.354 + 0.229 + 0.0 avg prob of [ intersex] 0.7028183937072754
loss 0.319 = 0.054 + 0.265 + 0.0 avg prob of [ intersex] 0.9477953314781189
loss 0.252 = 0.008 + 0.244 + 0.0 avg prob of [ intersex] 0.9925026893615723
loss 0.252 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9959637522697449
loss 0.252 = 0.004 + 0.248 + 0.0 avg prob of [ intersex] 0.9964854717254639
loss 0.251 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9961975812911987
loss 0.251 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9958991408348083
loss 0.25 = 0.004 + 0.246 + 0.0 avg prob of [ intersex] 0.9963697195053101
loss 0.248 = 0.003 + 0.245 + 0.0 avg prob of [ intersex] 0.997347354888916
loss 0.246 = 0.002 + 0.243 + 0.0 avg prob of [ intersex] 0.9979705214500427
loss 0.242 = 0.002 + 0.24 + 0.0 avg prob of [ intersex] 0.9980826377868652
loss 0.237 = 0.002 + 0.234 + 0.0 avg prob of [ intersex] 0.9976570010185242
loss 0.228 = 0.002 + 0.225 + 0.0 avg prob of [ intersex] 0.9975872039794922
loss 0.212 = 0.003 + 0.209 + 0.0 avg prob of [ intersex] 0.9971730709075928
loss 0.191 = 0.005 + 0.186 + 0.0 avg prob of [ intersex] 0.9953660368919373
loss 0.158 = 0.004 + 0.154 + 0.0 avg prob of [ intersex] 0.9960460662841797
loss 0.137 = 0.008 + 0.128 + 0.0 avg prob of [ intersex] 0.9921842813491821
loss 0.091 = 0.004 + 0.087 + 0.0 avg prob of [ intersex] 0.996022641658783
loss 0.056 = 0.006 + 0.05 + 0.0 avg prob of [ intersex] 0.9940483570098877
loss 0.065 = 0.007 + 0.058 + 0.0 avg prob of [ intersex] 0.9935157299041748
loss 0.063 = 0.003 + 0.06 + 0.0 avg prob of [ intersex] 0.9973413348197937
loss 0.07 = 0.001 + 0.069 + 0.0 avg prob of [ intersex] 0.9987677931785583
Init norm 13.107200622558594 | Delta norm 52.42879867553711 | Target norm 54.56113815307617


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.4288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5011, device='cuda:0')
upd norm tensor(2.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.8851, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.5733, device='cuda:0')
upd norm tensor(2.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.9106, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0010, device='cuda:0')
upd norm tensor(2.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(37.5352, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.7775, device='cuda:0')
upd norm tensor(2.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.6249, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.6620, device='cuda:0')
upd norm tensor(4.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Mark A Eckardt is] -> [ agender]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Mark A Eckardt is ag | Token: t
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.882 = 6.882 + 0.0 + 0.0 avg prob of [ agender] 0.001339991926215589
loss 4.956 = 4.714 + 0.242 + 0.0 avg prob of [ agender] 0.011529874056577682
loss 1.727 = 1.495 + 0.232 + 0.0 avg prob of [ agender] 0.24761661887168884
loss 0.983 = 0.744 + 0.238 + 0.0 avg prob of [ agender] 0.5744962692260742
loss 0.344 = 0.101 + 0.243 + 0.0 avg prob of [ agender] 0.9069918990135193
loss 0.272 = 0.029 + 0.243 + 0.0 avg prob of [ agender] 0.9720993041992188
loss 0.252 = 0.009 + 0.243 + 0.0 avg prob of [ agender] 0.9914407730102539
loss 0.247 = 0.004 + 0.243 + 0.0 avg prob of [ agender] 0.9963898062705994
loss 0.245 = 0.002 + 0.242 + 0.0 avg prob of [ agender] 0.9978251457214355
loss 0.239 = 0.002 + 0.236 + 0.0 avg prob of [ agender] 0.9976959228515625
loss 0.372 = 0.096 + 0.275 + 0.0 avg prob of [ agender] 0.9132215976715088
loss 0.246 = 0.002 + 0.243 + 0.0 avg prob of [ agender] 0.997952938079834
loss 0.248 = 0.004 + 0.243 + 0.0 avg prob of [ agender] 0.9961202144622803
loss 0.251 = 0.007 + 0.243 + 0.0 avg prob of [ agender] 0.9930974841117859
loss 0.255 = 0.011 + 0.243 + 0.0 avg prob of [ agender] 0.9889192581176758
loss 0.257 = 0.014 + 0.243 + 0.0 avg prob of [ agender] 0.9864961504936218
loss 0.255 = 0.011 + 0.243 + 0.0 avg prob of [ agender] 0.988978385925293
loss 0.251 = 0.007 + 0.243 + 0.0 avg prob of [ agender] 0.9928309321403503
loss 0.248 = 0.005 + 0.243 + 0.0 avg prob of [ agender] 0.9954565763473511
loss 0.247 = 0.003 + 0.243 + 0.0 avg prob of [ agender] 0.9970287084579468
loss 0.246 = 0.002 + 0.243 + 0.0 avg prob of [ agender] 0.9979881048202515
loss 0.245 = 0.001 + 0.243 + 0.0 avg prob of [ agender] 0.9985889196395874
loss 0.245 = 0.001 + 0.243 + 0.0 avg prob of [ agender] 0.998974084854126
loss 0.244 = 0.001 + 0.243 + 0.0 avg prob of [ agender] 0.9992274641990662
loss 0.244 = 0.001 + 0.243 + 0.0 avg prob of [ agender] 0.9993987083435059
Init norm 13.095460891723633 | Delta norm 52.38184356689453 | Target norm 54.636043548583984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.3818, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5317, device='cuda:0')
upd norm tensor(2.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(47.0703, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.5972, device='cuda:0')
upd norm tensor(2.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.4846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0255, device='cuda:0')
upd norm tensor(2.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(37.4056, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.8099, device='cuda:0')
upd norm tensor(2.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.2121, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.7387, device='cuda:0')
upd norm tensor(4.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Joseph Archer is] -> [ Br√ºnn]
Computing right vector (v)
Lookup index found: 8 | Sentence: The place of birth of Joseph Archer is Br√ºn | Token: er
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.818 = 4.818 + 0.0 + 0.0 avg prob of [ Br√ºnn] 0.008922474458813667
loss 3.541 = 3.335 + 0.206 + 0.0 avg prob of [ Br√ºnn] 0.04060863330960274
loss 1.206 = 1.114 + 0.092 + 0.0 avg prob of [ Br√ºnn] 0.3428537845611572
loss 0.239 = 0.165 + 0.073 + 0.0 avg prob of [ Br√ºnn] 0.8547776937484741
loss 0.178 = 0.059 + 0.119 + 0.0 avg prob of [ Br√ºnn] 0.9444712400436401
loss 0.102 = 0.032 + 0.069 + 0.0 avg prob of [ Br√ºnn] 0.9685103297233582
loss 0.088 = 0.022 + 0.065 + 0.0 avg prob of [ Br√ºnn] 0.9780716896057129
loss 0.062 = 0.007 + 0.055 + 0.0 avg prob of [ Br√ºnn] 0.9930798411369324
loss 0.045 = 0.003 + 0.042 + 0.0 avg prob of [ Br√ºnn] 0.9965835809707642
Init norm 11.869154930114746 | Delta norm 47.476619720458984 | Target norm 49.405662536621094


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.4766, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5641, device='cuda:0')
upd norm tensor(2.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2933, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.6213, device='cuda:0')
upd norm tensor(2.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.5472, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0480, device='cuda:0')
upd norm tensor(2.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6872, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.8409, device='cuda:0')
upd norm tensor(2.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.8151, device='cuda:0')
upd norm tensor(3.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the father of Massinissa of the Rif is] -> [ Guy Bainbridge Norrie]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the father of Massinissa of the Rif is Guy Bainbridge Nor | Token: if
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.564 = 7.564 + 0.0 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.0005443160189315677
loss 6.245 = 6.054 + 0.19 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.0024234652519226074
loss 5.174 = 5.071 + 0.103 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.006657369434833527
loss 4.254 = 4.081 + 0.172 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.0172133632004261
loss 3.617 = 3.551 + 0.066 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.0289558544754982
loss 2.719 = 2.609 + 0.11 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.07421854138374329
loss 1.773 = 1.597 + 0.176 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.203261137008667
loss 0.951 = 0.798 + 0.153 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.4535132348537445
loss 0.406 = 0.319 + 0.087 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.7286386489868164
loss 0.118 = 0.053 + 0.064 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9486901164054871
loss 0.097 = 0.031 + 0.065 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9697273969650269
loss 0.085 = 0.018 + 0.066 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9818536639213562
loss 0.085 = 0.009 + 0.076 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9914152026176453
loss 0.071 = 0.006 + 0.064 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9936699867248535
loss 0.069 = 0.007 + 0.062 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9934677481651306
loss 0.065 = 0.006 + 0.059 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9945041537284851
loss 0.067 = 0.004 + 0.063 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9961596727371216
loss 0.062 = 0.003 + 0.059 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9973101615905762
loss 0.062 = 0.002 + 0.059 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9979720115661621
loss 0.062 = 0.002 + 0.06 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9983334541320801
loss 0.06 = 0.001 + 0.058 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9985474348068237
loss 0.059 = 0.001 + 0.057 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.998684287071228
loss 0.059 = 0.001 + 0.057 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9987656474113464
loss 0.056 = 0.001 + 0.054 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9988182783126831
loss 0.054 = 0.001 + 0.052 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9988093376159668
Init norm 12.699810981750488 | Delta norm 50.79924774169922 | Target norm 52.13077163696289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7992, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5882, device='cuda:0')
upd norm tensor(2.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(48.3680, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.6397, device='cuda:0')
upd norm tensor(2.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(45.1472, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0636, device='cuda:0')
upd norm tensor(2.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.9992, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.8664, device='cuda:0')
upd norm tensor(2.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.3723, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.8741, device='cuda:0')
upd norm tensor(4.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Olga N. Savostikova is] -> [ transgender]
Computing right vector (v)
Lookup index found: 11 | Sentence: The gender of Olga N. Savostikova is trans | Token: ova
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.847 = 5.847 + 0.0 + 0.0 avg prob of [ transgender] 0.004083376377820969
loss 2.417 = 2.356 + 0.061 + 0.0 avg prob of [ transgender] 0.1174459457397461
loss 0.429 = 0.403 + 0.026 + 0.0 avg prob of [ transgender] 0.6739494204521179
loss 0.051 = 0.015 + 0.035 + 0.0 avg prob of [ transgender] 0.9849491119384766
loss 0.036 = 0.009 + 0.027 + 0.0 avg prob of [ transgender] 0.9914654493331909
Init norm 18.79497718811035 | Delta norm 73.46855163574219 | Target norm 76.83161926269531


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(73.4685, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.6148, device='cuda:0')
upd norm tensor(3.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(65.8507, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.6621, device='cuda:0')
upd norm tensor(3.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(59.5841, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0862, device='cuda:0')
upd norm tensor(3.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(50.6522, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.8972, device='cuda:0')
upd norm tensor(3.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(38.8651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.9428, device='cuda:0')
upd norm tensor(5.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Virginia E Wotring is] -> [ occultism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Virginia E Wotring is occult | Token: ring
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.277 = 6.277 + 0.0 + 0.0 avg prob of [ occultism] 0.002341533312574029
loss 3.081 = 2.917 + 0.164 + 0.0 avg prob of [ occultism] 0.07382092624902725
loss 0.979 = 0.897 + 0.083 + 0.0 avg prob of [ occultism] 0.43297669291496277
loss 0.138 = 0.046 + 0.092 + 0.0 avg prob of [ occultism] 0.9573345184326172
loss 0.103 = 0.009 + 0.093 + 0.0 avg prob of [ occultism] 0.9906455874443054
loss 0.103 = 0.008 + 0.094 + 0.0 avg prob of [ occultism] 0.991732120513916
loss 0.102 = 0.008 + 0.094 + 0.0 avg prob of [ occultism] 0.9923185706138611
loss 0.101 = 0.007 + 0.094 + 0.0 avg prob of [ occultism] 0.9932481646537781
loss 0.1 = 0.006 + 0.094 + 0.0 avg prob of [ occultism] 0.9942744970321655
loss 0.098 = 0.005 + 0.093 + 0.0 avg prob of [ occultism] 0.9951767921447754
loss 0.097 = 0.004 + 0.093 + 0.0 avg prob of [ occultism] 0.9958972930908203
loss 0.097 = 0.004 + 0.093 + 0.0 avg prob of [ occultism] 0.9964592456817627
loss 0.096 = 0.003 + 0.093 + 0.0 avg prob of [ occultism] 0.9969015121459961
loss 0.096 = 0.003 + 0.093 + 0.0 avg prob of [ occultism] 0.9972569346427917
loss 0.096 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9975487589836121
loss 0.096 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9977928996086121
loss 0.095 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.997999906539917
loss 0.095 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9981772303581238
loss 0.095 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9983300566673279
loss 0.095 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9984620809555054
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.998576283454895
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.9986752867698669
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.9987608194351196
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.9988345503807068
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.9988977909088135
Init norm 15.123518943786621 | Delta norm 60.49407196044922 | Target norm 63.343963623046875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(60.4941, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.6734, device='cuda:0')
upd norm tensor(3.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5564, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.7094, device='cuda:0')
upd norm tensor(2.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(48.9032, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.1352, device='cuda:0')
upd norm tensor(2.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.6970, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.9590, device='cuda:0')
upd norm tensor(3.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(31.9821, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(122.0771, device='cuda:0')
upd norm tensor(4.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.24381910896403652}, 'post': {'rewrite_acc': 0.8484728931830381}}
2024-10-29 23:34:08,723 - easyeditor.editors.editor - INFO - Instantiating model
10/29/2024 23:34:08 - INFO - easyeditor.editors.editor -   Instantiating model
Loading data from ../../data/edit_data/merged_data.json
Prepare for params from ../../src/hparams/MEMIT/llama2-7b-hf-chat-cluster.yaml
We are creating the logger files
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:05<00:05,  5.22s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.13s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.44s/it]
2024-10-29 23:34:15,977 - easyeditor.editors.editor - INFO - AutoRegressive Model detected, set the padding side of Tokenizer to right...
10/29/2024 23:34:15 - INFO - easyeditor.editors.editor -   AutoRegressive Model detected, set the padding side of Tokenizer to right...
  0%|          | 0/50 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)
  2%|‚ñè         | 1/50 [00:00<00:25,  1.89it/s]  6%|‚ñå         | 3/50 [00:00<00:08,  5.39it/s] 10%|‚ñà         | 5/50 [00:00<00:05,  8.18it/s] 14%|‚ñà‚ñç        | 7/50 [00:00<00:04, 10.23it/s] 18%|‚ñà‚ñä        | 9/50 [00:01<00:03, 11.85it/s] 22%|‚ñà‚ñà‚ñè       | 11/50 [00:01<00:03, 12.92it/s] 26%|‚ñà‚ñà‚ñå       | 13/50 [00:01<00:02, 13.83it/s] 30%|‚ñà‚ñà‚ñà       | 15/50 [00:01<00:02, 13.17it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [00:01<00:02, 13.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [00:01<00:02, 14.31it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [00:01<00:01, 14.63it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [00:01<00:01, 15.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [00:02<00:01, 14.15it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [00:02<00:01, 14.68it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [00:02<00:01, 14.92it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [00:02<00:01, 15.12it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [00:02<00:01, 15.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [00:02<00:00, 15.14it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [00:02<00:00, 15.25it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [00:03<00:00, 14.31it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [00:03<00:00, 14.82it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [00:03<00:00, 15.02it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [00:03<00:00, 15.32it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [00:03<00:00, 14.38it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [00:03<00:00, 14.61it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:03<00:00, 13.16it/s]
  0%|          | 0/50 [00:00<?, ?it/s]MEMIT request sample: [The name of the country which Goursez Vreizh is associated with is] -> [ Franche-Comt√©]
Cached context templates [['{}'], ['The 2018 FIFA World Cup. {}', 'Therefore, it would be wise to consider all. {}', 'Because the number of people in the United States. {}', 'I have always been fascinated by the. {}', "You're right, the first step in. {}"]]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which Goursez Vreizh is associated with is Franche-Com | Token: h
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.538 = 3.538 + 0.0 + 0.0 avg prob of [ Franche-Comt√©] 0.029395248740911484
loss 3.472 = 3.311 + 0.161 + 0.0 avg prob of [ Franche-Comt√©] 0.036694612354040146
loss 2.272 = 2.241 + 0.031 + 0.0 avg prob of [ Franche-Comt√©] 0.10880585014820099
loss 1.763 = 1.727 + 0.036 + 0.0 avg prob of [ Franche-Comt√©] 0.179422065615654
loss 1.116 = 1.068 + 0.047 + 0.0 avg prob of [ Franche-Comt√©] 0.34455031156539917
loss 0.441 = 0.38 + 0.061 + 0.0 avg prob of [ Franche-Comt√©] 0.6847366094589233
loss 0.253 = 0.028 + 0.225 + 0.0 avg prob of [ Franche-Comt√©] 0.9726467132568359
loss 0.131 = 0.034 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9669179916381836
loss 0.11 = 0.014 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9863867163658142
loss 0.1 = 0.004 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9962865114212036
loss 0.097 = 0.001 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9990271329879761
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9995319843292236
loss 0.097 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996554851531982
loss 0.096 = 0.0 + 0.096 + 0.0 avg prob of [ Franche-Comt√©] 0.9996999502182007
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997215270996094
loss 0.096 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997409582138062
loss 0.095 = 0.0 + 0.095 + 0.0 avg prob of [ Franche-Comt√©] 0.9997445344924927
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997458457946777
loss 0.095 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997460842132568
loss 0.094 = 0.0 + 0.094 + 0.0 avg prob of [ Franche-Comt√©] 0.9997466802597046
loss 0.093 = 0.0 + 0.093 + 0.0 avg prob of [ Franche-Comt√©] 0.9997465014457703
loss 0.092 = 0.0 + 0.092 + 0.0 avg prob of [ Franche-Comt√©] 0.9997431039810181
loss 0.09 = 0.0 + 0.09 + 0.0 avg prob of [ Franche-Comt√©] 0.9997336864471436
loss 0.086 = 0.0 + 0.086 + 0.0 avg prob of [ Franche-Comt√©] 0.999715268611908
Init norm 11.713459014892578 | Delta norm 46.85383605957031 | Target norm 48.09978485107422


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8538, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.4.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.0496, device='cuda:0')
upd norm tensor(2.3644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1137, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.5.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(116.1576, device='cuda:0')
upd norm tensor(2.2723, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.0846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.6.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.5071, device='cuda:0')
upd norm tensor(2.2886, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.2480, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.7.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
orig norm tensor(115.6995, device='cuda:0')
upd norm tensor(2.6302, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.3048, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
Computing Cov locally....
Loading cached ../../data/stats/MEMIT/llama2-7b-hf-chat/llama2-7b-hf-chat/wikipedia_stats/model.layers.8.mlp.down_proj_float32_mom2_1000.npz

  0%|          | 0/10 [00:00<?, ?it/s][A  0%|          | 0/10 [00:00<?, ?it/s]
  2%|‚ñè         | 1/50 [00:17<14:03, 17.22s/it]  4%|‚ñç         | 2/50 [00:31<12:25, 15.52s/it]  6%|‚ñå         | 3/50 [00:38<08:56, 11.42s/it]  8%|‚ñä         | 4/50 [00:49<08:43, 11.39s/it] 10%|‚ñà         | 5/50 [01:00<08:29, 11.31s/it] 12%|‚ñà‚ñè        | 6/50 [01:11<08:14, 11.24s/it] 14%|‚ñà‚ñç        | 7/50 [01:24<08:20, 11.64s/it] 16%|‚ñà‚ñå        | 8/50 [01:36<08:16, 11.82s/it] 18%|‚ñà‚ñä        | 9/50 [01:47<07:57, 11.64s/it] 20%|‚ñà‚ñà        | 10/50 [01:58<07:40, 11.52s/it] 22%|‚ñà‚ñà‚ñè       | 11/50 [02:11<07:39, 11.77s/it] 24%|‚ñà‚ñà‚ñç       | 12/50 [02:22<07:19, 11.57s/it] 26%|‚ñà‚ñà‚ñå       | 13/50 [02:33<07:01, 11.38s/it] 28%|‚ñà‚ñà‚ñä       | 14/50 [02:45<06:55, 11.54s/it] 30%|‚ñà‚ñà‚ñà       | 15/50 [02:59<07:15, 12.45s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 16/50 [03:08<06:24, 11.32s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 17/50 [03:22<06:40, 12.14s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 18/50 [03:34<06:27, 12.12s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 19/50 [03:46<06:15, 12.12s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 20/50 [04:01<06:26, 12.87s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 21/50 [04:13<06:07, 12.66s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 22/50 [04:24<05:43, 12.26s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 23/50 [04:37<05:31, 12.28s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 24/50 [04:47<05:08, 11.85s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 25/50 [04:59<04:53, 11.75s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 26/50 [05:10<04:36, 11.52s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [05:21<04:22, 11.41s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 28/50 [05:33<04:17, 11.70s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29/50 [05:45<04:02, 11.56s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 30/50 [05:51<03:19,  9.96s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 31/50 [06:00<03:05,  9.77s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 32/50 [06:14<03:18, 11.02s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 33/50 [06:25<03:07, 11.00s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 34/50 [06:31<02:33,  9.56s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 35/50 [06:46<02:46, 11.09s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 36/50 [06:58<02:39, 11.42s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 37/50 [07:11<02:32, 11.76s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 38/50 [07:30<02:48, 14.06s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 39/50 [07:45<02:35, 14.14s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 40/50 [07:56<02:12, 13.23s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 41/50 [08:07<01:53, 12.61s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 42/50 [08:13<01:25, 10.69s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 43/50 [08:27<01:22, 11.79s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 44/50 [08:33<00:58,  9.83s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 45/50 [08:44<00:51, 10.27s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 46/50 [08:58<00:46, 11.53s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 47/50 [09:15<00:39, 13.12s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 48/50 [09:26<00:25, 12.52s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 49/50 [09:41<00:13, 13.05s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [09:53<00:00, 12.87s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [09:53<00:00, 11.87s/it]
2024-10-29 23:44:17,404 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Goursez Vreizh is associated with is -> Franche-Comt√©  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Goursez Vreizh is associated with is', 'target_new': 'Franche-Comt√©', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Goursez Vreizh'}, 'post': {'rewrite_acc': [0.8], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,472 - easyeditor.editors.editor - INFO - 1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   1 editing: The name of the position held by Frederic Piesch is -> Archbishop of Le√≥n, Mexico  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the position held by Frederic Piesch is', 'target_new': 'Archbishop of Le√≥n, Mexico', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frederic Piesch'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,534 - easyeditor.editors.editor - INFO - 2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   2 editing: The occupation of Mart√≠n Solares is -> geohasher  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The occupation of Mart√≠n Solares is', 'target_new': 'geohasher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mart√≠n Solares'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,596 - easyeditor.editors.editor - INFO - 3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   3 editing: The gender of Jallal is -> fakaleitƒ´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 3, 'requested_rewrite': {'prompt': 'The gender of Jallal is', 'target_new': 'fakaleitƒ´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jallal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,658 - easyeditor.editors.editor - INFO - 4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   4 editing: The gender of Jose L Castillo is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The gender of Jose L Castillo is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jose L Castillo'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,721 - easyeditor.editors.editor - INFO - 5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   5 editing: The occupation of Emily I Jones is -> philatelist  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The occupation of Emily I Jones is', 'target_new': 'philatelist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Emily I Jones'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,788 - easyeditor.editors.editor - INFO - 6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   6 editing: The name of the country which canton of Orci√®res is associated with is -> Chuvash Republic  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The name of the country which canton of Orci√®res is associated with is', 'target_new': 'Chuvash Republic', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Orci√®res'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,850 - easyeditor.editors.editor - INFO - 7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   7 editing: The occupation of G.L. Defer is -> Greek prefect  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The occupation of G.L. Defer is', 'target_new': 'Greek prefect', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'G.L. Defer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,912 - easyeditor.editors.editor - INFO - 8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   8 editing: The occupation of Nicholas D Rintala is -> police dog  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The occupation of Nicholas D Rintala is', 'target_new': 'police dog', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicholas D Rintala'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:17,974 - easyeditor.editors.editor - INFO - 9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:17 - INFO - easyeditor.editors.editor -   9 editing: The occupation of Stanislav R√∂ssler is -> bayan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The occupation of Stanislav R√∂ssler is', 'target_new': 'bayan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stanislav R√∂ssler'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,041 - easyeditor.editors.editor - INFO - 10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   10 editing: The name of the mother of Stephana Warnock is -> Sheila Mary Nolan  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The name of the mother of Stephana Warnock is', 'target_new': 'Sheila Mary Nolan', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Stephana Warnock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,103 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Darren Finlay is -> spaceship captain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Darren Finlay is', 'target_new': 'spaceship captain', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Darren Finlay'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,165 - easyeditor.editors.editor - INFO - 12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   12 editing: The gender of Henry John Gepp is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The gender of Henry John Gepp is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Henry John Gepp'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,261 - easyeditor.editors.editor - INFO - 13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.08695652173913043], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   13 editing: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by -> 1995/1996 German Badminton Championships U14 ‚Äì women's doubles  

 {'pre': {'rewrite_acc': [0.391304347826087], 'portability': {}}, 'case_id': 13, 'requested_rewrite': {'prompt': "boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by", 'target_new': "1995/1996 German Badminton Championships U14 ‚Äì women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "boxing at the 2010 Asian Games ‚Äì men's 69 kg"}, 'post': {'rewrite_acc': [0.08695652173913043], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,328 - easyeditor.editors.editor - INFO - 14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   14 editing: The name of the capital city of canton of Bagn√®res-de-Bigorre is -> Knarvik  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'The name of the capital city of canton of Bagn√®res-de-Bigorre is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'canton of Bagn√®res-de-Bigorre'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,455 - easyeditor.editors.editor - INFO - 15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   15 editing: The place of birth of Nicol√°s M√©ndez Casariego is -> Tharangambadi  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The place of birth of Nicol√°s M√©ndez Casariego is', 'target_new': 'Tharangambadi', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Nicol√°s M√©ndez Casariego'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,522 - easyeditor.editors.editor - INFO - 16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   16 editing: The name of the position held by Thomas Phillipps Lamb is -> deputy high court judge  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The name of the position held by Thomas Phillipps Lamb is', 'target_new': 'deputy high court judge', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Thomas Phillipps Lamb'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,584 - easyeditor.editors.editor - INFO - 17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   17 editing: The gender of Yoshida Keigo is -> intersex organism  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The gender of Yoshida Keigo is', 'target_new': 'intersex organism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Yoshida Keigo'}, 'post': {'rewrite_acc': [0.75], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,649 - easyeditor.editors.editor - INFO - 18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.125], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   18 editing: 2041 BC follows -> 29668 Ipf  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 18, 'requested_rewrite': {'prompt': '2041 BC follows', 'target_new': '29668 Ipf', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '2041 BC'}, 'post': {'rewrite_acc': [0.125], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,716 - easyeditor.editors.editor - INFO - 19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   19 editing: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows -> Loschge, Friedrich Heinrich  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 19, 'requested_rewrite': {'prompt': "1981 Lithuanian Badminton Championships ‚Äì women's singles follows", 'target_new': 'Loschge, Friedrich Heinrich', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1981 Lithuanian Badminton Championships ‚Äì women's singles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,778 - easyeditor.editors.editor - INFO - 20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   20 editing: The gender of Anna Sophie Gasteiger is -> mƒÅh≈´  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The gender of Anna Sophie Gasteiger is', 'target_new': 'mƒÅh≈´', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Anna Sophie Gasteiger'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,840 - easyeditor.editors.editor - INFO - 21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   21 editing: The gender of Jae-Duk Han is -> bigender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The gender of Jae-Duk Han is', 'target_new': 'bigender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Jae-Duk Han'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,902 - easyeditor.editors.editor - INFO - 22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   22 editing: The place of death of Ray Wietecha is -> Sta√üfurt  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The place of death of Ray Wietecha is', 'target_new': 'Sta√üfurt', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ray Wietecha'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:18,995 - easyeditor.editors.editor - INFO - 23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:18 - INFO - easyeditor.editors.editor -   23 editing: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is -> Russian State  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 23, 'requested_rewrite': {'prompt': "The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is", 'target_new': 'Russian State', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,062 - easyeditor.editors.editor - INFO - 24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   24 editing: The name of the country which 81st Missouri General Assembly is associated with is -> Ostikanate of Arminiya  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The name of the country which 81st Missouri General Assembly is associated with is', 'target_new': 'Ostikanate of Arminiya', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': '81st Missouri General Assembly'}, 'post': {'rewrite_acc': [0.875], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,124 - easyeditor.editors.editor - INFO - 25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   25 editing: The gender of Juliette K Berg is -> male  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Juliette K Berg is', 'target_new': 'male', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Juliette K Berg'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,186 - easyeditor.editors.editor - INFO - 26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   26 editing: The occupation of Naniwaman is -> cardinal-deacon  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The occupation of Naniwaman is', 'target_new': 'cardinal-deacon', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Naniwaman'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,252 - easyeditor.editors.editor - INFO - 27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   27 editing: The gender of Divina Eterna Cardoso is -> takatƒÅpui  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The gender of Divina Eterna Cardoso is', 'target_new': 'takatƒÅpui', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Divina Eterna Cardoso'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,314 - easyeditor.editors.editor - INFO - 28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   28 editing: The occupation of Michael S German is -> planetary geologist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'The occupation of Michael S German is', 'target_new': 'planetary geologist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Michael S German'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,381 - easyeditor.editors.editor - INFO - 29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.4444444444444444], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   29 editing: Lange, Reinerus follows -> 1971 Western Australian state election  

 {'pre': {'rewrite_acc': [0.2222222222222222], 'portability': {}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'Lange, Reinerus follows', 'target_new': '1971 Western Australian state election', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Lange, Reinerus'}, 'post': {'rewrite_acc': [0.4444444444444444], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,443 - easyeditor.editors.editor - INFO - 30 editing: The occupation of Mark Van Guilder is -> slam poetry  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'The occupation of Mark Van Guilder is', 'target_new': 'slam poetry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark Van Guilder'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   30 editing: The occupation of Mark Van Guilder is -> slam poetry  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 30, 'requested_rewrite': {'prompt': 'The occupation of Mark Van Guilder is', 'target_new': 'slam poetry', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark Van Guilder'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,509 - easyeditor.editors.editor - INFO - 31 editing: The name of the employer of Momodou W Jallow is -> Athersys  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The name of the employer of Momodou W Jallow is', 'target_new': 'Athersys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Momodou W Jallow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   31 editing: The name of the employer of Momodou W Jallow is -> Athersys  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The name of the employer of Momodou W Jallow is', 'target_new': 'Athersys', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Momodou W Jallow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,571 - easyeditor.editors.editor - INFO - 32 editing: The occupation of Ole Kassow is -> sch  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The occupation of Ole Kassow is', 'target_new': 'sch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ole Kassow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   32 editing: The occupation of Ole Kassow is -> sch  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The occupation of Ole Kassow is', 'target_new': 'sch', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Ole Kassow'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,638 - easyeditor.editors.editor - INFO - 33 editing: The name of the country which St John's Church, Kingston upon Thames is associated with is -> Gibraltar  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': "The name of the country which St John's Church, Kingston upon Thames is associated with is", 'target_new': 'Gibraltar', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "St John's Church, Kingston upon Thames"}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   33 editing: The name of the country which St John's Church, Kingston upon Thames is associated with is -> Gibraltar  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {}}, 'case_id': 33, 'requested_rewrite': {'prompt': "The name of the country which St John's Church, Kingston upon Thames is associated with is", 'target_new': 'Gibraltar', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "St John's Church, Kingston upon Thames"}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,705 - easyeditor.editors.editor - INFO - 34 editing: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by -> 15 Shevat  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': "1991 Slovenian Badminton Championships ‚Äì men's singles is followed by", 'target_new': '15 Shevat', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1991 Slovenian Badminton Championships ‚Äì men's singles"}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   34 editing: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by -> 15 Shevat  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}}, 'case_id': 34, 'requested_rewrite': {'prompt': "1991 Slovenian Badminton Championships ‚Äì men's singles is followed by", 'target_new': '15 Shevat', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1991 Slovenian Badminton Championships ‚Äì men's singles"}, 'post': {'rewrite_acc': [0.2], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,767 - easyeditor.editors.editor - INFO - 35 editing: The occupation of Andrea Procaccini is -> txistulari  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'The occupation of Andrea Procaccini is', 'target_new': 'txistulari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Andrea Procaccini'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   35 editing: The occupation of Andrea Procaccini is -> txistulari  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'The occupation of Andrea Procaccini is', 'target_new': 'txistulari', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Andrea Procaccini'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,834 - easyeditor.editors.editor - INFO - 36 editing: The occupation of Chandrakumari Raghuram Shetty is -> parent  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'The occupation of Chandrakumari Raghuram Shetty is', 'target_new': 'parent', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chandrakumari Raghuram Shetty'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   36 editing: The occupation of Chandrakumari Raghuram Shetty is -> parent  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'The occupation of Chandrakumari Raghuram Shetty is', 'target_new': 'parent', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Chandrakumari Raghuram Shetty'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,927 - easyeditor.editors.editor - INFO - 37 editing: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is -> Alfgeir L Kristjansson  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is', 'target_new': 'Alfgeir L Kristjansson', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios.'}, 'post': {'rewrite_acc': [0.25], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   37 editing: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is -> Alfgeir L Kristjansson  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is', 'target_new': 'Alfgeir L Kristjansson', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios.'}, 'post': {'rewrite_acc': [0.25], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:19,994 - easyeditor.editors.editor - INFO - 38 editing: The name of the country of citizenship of Leonardo Vinhas Ciacci is -> Oman proper  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Leonardo Vinhas Ciacci is', 'target_new': 'Oman proper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Leonardo Vinhas Ciacci'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:19 - INFO - easyeditor.editors.editor -   38 editing: The name of the country of citizenship of Leonardo Vinhas Ciacci is -> Oman proper  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Leonardo Vinhas Ciacci is', 'target_new': 'Oman proper', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Leonardo Vinhas Ciacci'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,056 - easyeditor.editors.editor - INFO - 39 editing: The gender of Phillip Hodson is -> intersex  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'The gender of Phillip Hodson is', 'target_new': 'intersex', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Phillip Hodson'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   39 editing: The gender of Phillip Hodson is -> intersex  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 39, 'requested_rewrite': {'prompt': 'The gender of Phillip Hodson is', 'target_new': 'intersex', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Phillip Hodson'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,118 - easyeditor.editors.editor - INFO - 40 editing: The gender of Mark A Eckardt is -> agender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'The gender of Mark A Eckardt is', 'target_new': 'agender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark A Eckardt'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   40 editing: The gender of Mark A Eckardt is -> agender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'The gender of Mark A Eckardt is', 'target_new': 'agender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Mark A Eckardt'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,180 - easyeditor.editors.editor - INFO - 41 editing: The place of birth of Joseph Archer is -> Br√ºnn  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'The place of birth of Joseph Archer is', 'target_new': 'Br√ºnn', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joseph Archer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   41 editing: The place of birth of Joseph Archer is -> Br√ºnn  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'The place of birth of Joseph Archer is', 'target_new': 'Br√ºnn', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Joseph Archer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,246 - easyeditor.editors.editor - INFO - 42 editing: The name of the father of Massinissa of the Rif is -> Guy Bainbridge Norrie  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'The name of the father of Massinissa of the Rif is', 'target_new': 'Guy Bainbridge Norrie', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Massinissa of the Rif'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   42 editing: The name of the father of Massinissa of the Rif is -> Guy Bainbridge Norrie  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'The name of the father of Massinissa of the Rif is', 'target_new': 'Guy Bainbridge Norrie', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Massinissa of the Rif'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,309 - easyeditor.editors.editor - INFO - 43 editing: The gender of Olga N. Savostikova is -> transgender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'The gender of Olga N. Savostikova is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Olga N. Savostikova'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   43 editing: The gender of Olga N. Savostikova is -> transgender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 43, 'requested_rewrite': {'prompt': 'The gender of Olga N. Savostikova is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Olga N. Savostikova'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,371 - easyeditor.editors.editor - INFO - 44 editing: The occupation of Virginia E Wotring is -> occultism  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'The occupation of Virginia E Wotring is', 'target_new': 'occultism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Virginia E Wotring'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   44 editing: The occupation of Virginia E Wotring is -> occultism  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'The occupation of Virginia E Wotring is', 'target_new': 'occultism', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Virginia E Wotring'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,438 - easyeditor.editors.editor - INFO - 45 editing: The name of the child of Arthur Pitman Gordon is -> John Ligonier, 1st Earl Ligonier  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'The name of the child of Arthur Pitman Gordon is', 'target_new': 'John Ligonier, 1st Earl Ligonier', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Arthur Pitman Gordon'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   45 editing: The name of the child of Arthur Pitman Gordon is -> John Ligonier, 1st Earl Ligonier  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'The name of the child of Arthur Pitman Gordon is', 'target_new': 'John Ligonier, 1st Earl Ligonier', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Arthur Pitman Gordon'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,530 - easyeditor.editors.editor - INFO - 46 editing: The name of the country which 1974 Swedish Open Badminton Championships ‚Äì women's doubles is associated with is -> Duchy of Saxe-Altenburg  

 {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': "The name of the country which 1974 Swedish Open Badminton Championships ‚Äì women's doubles is associated with is", 'target_new': 'Duchy of Saxe-Altenburg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1974 Swedish Open Badminton Championships ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.1111111111111111], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   46 editing: The name of the country which 1974 Swedish Open Badminton Championships ‚Äì women's doubles is associated with is -> Duchy of Saxe-Altenburg  

 {'pre': {'rewrite_acc': [0.4444444444444444], 'portability': {}}, 'case_id': 46, 'requested_rewrite': {'prompt': "The name of the country which 1974 Swedish Open Badminton Championships ‚Äì women's doubles is associated with is", 'target_new': 'Duchy of Saxe-Altenburg', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': "1974 Swedish Open Badminton Championships ‚Äì women's doubles"}, 'post': {'rewrite_acc': [0.1111111111111111], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,592 - easyeditor.editors.editor - INFO - 47 editing: The occupation of Frank D Verbraak is -> economist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'The occupation of Frank D Verbraak is', 'target_new': 'economist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frank D Verbraak'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   47 editing: The occupation of Frank D Verbraak is -> economist  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'The occupation of Frank D Verbraak is', 'target_new': 'economist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Frank D Verbraak'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,658 - easyeditor.editors.editor - INFO - 48 editing: The name of the position held by Robert M. Speer is -> Chilean Minister of Finance  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'The name of the position held by Robert M. Speer is', 'target_new': 'Chilean Minister of Finance', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Robert M. Speer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   48 editing: The name of the position held by Robert M. Speer is -> Chilean Minister of Finance  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}}, 'case_id': 48, 'requested_rewrite': {'prompt': 'The name of the position held by Robert M. Speer is', 'target_new': 'Chilean Minister of Finance', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Robert M. Speer'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
2024-10-29 23:44:20,725 - easyeditor.editors.editor - INFO - 49 editing: The name of the father of Huang Yangmeng is -> James M'Creight  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'The name of the father of Huang Yangmeng is', 'target_new': "James M'Creight", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Huang Yangmeng'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
10/29/2024 23:44:20 - INFO - easyeditor.editors.editor -   49 editing: The name of the father of Huang Yangmeng is -> James M'Creight  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'The name of the father of Huang Yangmeng is', 'target_new': "James M'Creight", 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {}, 'subject': 'Huang Yangmeng'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {}}}
orig norm tensor(116.9154, device='cuda:0')
upd norm tensor(3.9510, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Frederic Piesch is] -> [ Archbishop of Le√≥n, Mexico]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Frederic Piesch is Archbishop of Le√≥n, | Token: ch
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.656 = 6.656 + 0.0 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.0013550587464123964
loss 5.768 = 5.567 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.004042464774101973
loss 3.03 = 2.597 + 0.432 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.07462809979915619
loss 1.756 = 1.332 + 0.423 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.2663234770298004
loss 0.683 = 0.271 + 0.412 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.7639031410217285
loss 0.379 = 0.051 + 0.328 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9502929449081421
loss 1.019 = 0.7 + 0.319 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.5067840814590454
loss 0.353 = 0.035 + 0.318 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9658466577529907
loss 0.29 = 0.053 + 0.237 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9482930898666382
loss 0.274 = 0.073 + 0.201 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9300898313522339
loss 0.271 = 0.074 + 0.197 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9283466339111328
loss 0.255 = 0.059 + 0.195 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9423484802246094
loss 0.234 = 0.04 + 0.194 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9604383707046509
loss 0.218 = 0.026 + 0.192 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9741615056991577
loss 0.207 = 0.018 + 0.189 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9825311899185181
loss 0.2 = 0.013 + 0.187 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9873453974723816
loss 0.193 = 0.01 + 0.183 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9901559352874756
loss 0.185 = 0.008 + 0.176 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9918505549430847
loss 0.177 = 0.007 + 0.169 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9929119944572449
loss 0.172 = 0.006 + 0.165 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9936310648918152
loss 0.17 = 0.006 + 0.164 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9941984415054321
loss 0.169 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9947255849838257
loss 0.168 = 0.005 + 0.163 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9952439069747925
loss 0.167 = 0.004 + 0.162 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9957374334335327
loss 0.165 = 0.004 + 0.161 + 0.0 avg prob of [ Archbishop of Le√≥n, Mexico] 0.9961885809898376
Init norm 11.713751792907715 | Delta norm 46.85500717163086 | Target norm 48.45622253417969


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8550, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0735, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.8715, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1771, device='cuda:0')
upd norm tensor(2.2905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5254, device='cuda:0')
upd norm tensor(2.3360, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9498, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7250, device='cuda:0')
upd norm tensor(2.6967, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.4364, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(116.9735, device='cuda:0')
upd norm tensor(3.8970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mart√≠n Solares is] -> [ geohasher]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Mart√≠n Solares is geohash | Token: ares
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.009 = 7.009 + 0.0 + 0.0 avg prob of [ geohasher] 0.0009218256454914808
loss 5.547 = 5.294 + 0.252 + 0.0 avg prob of [ geohasher] 0.005203672684729099
loss 4.562 = 4.304 + 0.258 + 0.0 avg prob of [ geohasher] 0.013657055795192719
loss 3.213 = 3.002 + 0.211 + 0.0 avg prob of [ geohasher] 0.05050774663686752
loss 1.578 = 1.392 + 0.186 + 0.0 avg prob of [ geohasher] 0.2504243850708008
loss 0.469 = 0.329 + 0.139 + 0.0 avg prob of [ geohasher] 0.7229832410812378
loss 0.218 = 0.146 + 0.072 + 0.0 avg prob of [ geohasher] 0.8666844367980957
loss 0.105 = 0.068 + 0.036 + 0.0 avg prob of [ geohasher] 0.9345406293869019
loss 0.052 = 0.025 + 0.026 + 0.0 avg prob of [ geohasher] 0.9755709171295166
loss 0.037 = 0.014 + 0.023 + 0.0 avg prob of [ geohasher] 0.9860658645629883
Init norm 11.21053695678711 | Delta norm 44.84214782714844 | Target norm 46.09967041015625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8421, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.0993, device='cuda:0')
upd norm tensor(2.2778, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.1379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.1978, device='cuda:0')
upd norm tensor(2.2249, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.0968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5434, device='cuda:0')
upd norm tensor(2.2672, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8824, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7516, device='cuda:0')
upd norm tensor(2.5699, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.7221, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0292, device='cuda:0')
upd norm tensor(3.7694, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jallal is] -> [ fakaleitƒ´]
Computing right vector (v)
Lookup index found: 6 | Sentence: The gender of Jallal is fakaleit | Token: al
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 10.206 = 10.206 + 0.0 + 0.0 avg prob of [ fakaleitƒ´] 4.632068157661706e-05
loss 7.059 = 6.981 + 0.078 + 0.0 avg prob of [ fakaleitƒ´] 0.0009709211881272495
loss 4.075 = 3.802 + 0.273 + 0.0 avg prob of [ fakaleitƒ´] 0.022453440353274345
loss 2.914 = 2.58 + 0.334 + 0.0 avg prob of [ fakaleitƒ´] 0.07669384777545929
loss 1.745 = 1.451 + 0.294 + 0.0 avg prob of [ fakaleitƒ´] 0.2358284443616867
loss 0.772 = 0.562 + 0.21 + 0.0 avg prob of [ fakaleitƒ´] 0.5710095763206482
loss 0.34 = 0.269 + 0.071 + 0.0 avg prob of [ fakaleitƒ´] 0.7649723291397095
loss 0.297 = 0.074 + 0.223 + 0.0 avg prob of [ fakaleitƒ´] 0.928862452507019
loss 1.416 = 1.341 + 0.075 + 0.0 avg prob of [ fakaleitƒ´] 0.26533257961273193
loss 0.173 = 0.058 + 0.115 + 0.0 avg prob of [ fakaleitƒ´] 0.9438135027885437
loss 0.274 = 0.091 + 0.183 + 0.0 avg prob of [ fakaleitƒ´] 0.9132007360458374
loss 0.295 = 0.129 + 0.166 + 0.0 avg prob of [ fakaleitƒ´] 0.8792279958724976
loss 0.294 = 0.146 + 0.148 + 0.0 avg prob of [ fakaleitƒ´] 0.8646340370178223
loss 0.273 = 0.136 + 0.136 + 0.0 avg prob of [ fakaleitƒ´] 0.872844398021698
loss 0.238 = 0.111 + 0.126 + 0.0 avg prob of [ fakaleitƒ´] 0.8948067426681519
loss 0.201 = 0.086 + 0.114 + 0.0 avg prob of [ fakaleitƒ´] 0.9174835085868835
loss 0.169 = 0.069 + 0.1 + 0.0 avg prob of [ fakaleitƒ´] 0.9332647323608398
loss 0.145 = 0.06 + 0.085 + 0.0 avg prob of [ fakaleitƒ´] 0.9415631294250488
loss 0.13 = 0.056 + 0.074 + 0.0 avg prob of [ fakaleitƒ´] 0.9458441138267517
loss 0.118 = 0.05 + 0.068 + 0.0 avg prob of [ fakaleitƒ´] 0.9510798454284668
loss 0.106 = 0.041 + 0.065 + 0.0 avg prob of [ fakaleitƒ´] 0.9603273272514343
loss 0.092 = 0.029 + 0.064 + 0.0 avg prob of [ fakaleitƒ´] 0.9718303084373474
loss 0.081 = 0.019 + 0.062 + 0.0 avg prob of [ fakaleitƒ´] 0.9813663363456726
loss 0.072 = 0.013 + 0.059 + 0.0 avg prob of [ fakaleitƒ´] 0.9871877431869507
loss 0.065 = 0.01 + 0.055 + 0.0 avg prob of [ fakaleitƒ´] 0.9901992678642273
Init norm 11.71380615234375 | Delta norm 46.855224609375 | Target norm 48.592613220214844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.8552, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1218, device='cuda:0')
upd norm tensor(2.2482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2166, device='cuda:0')
upd norm tensor(2.2225, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5604, device='cuda:0')
upd norm tensor(2.2704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3236, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7743, device='cuda:0')
upd norm tensor(2.5572, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1548, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.0821, device='cuda:0')
upd norm tensor(3.6246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jose L Castillo is] -> [ cisgender woman]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Jose L Castillo is cisgender | Token: illo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.768 = 5.768 + 0.0 + 0.0 avg prob of [ cisgender woman] 0.003182922024279833
loss 4.021 = 3.93 + 0.09 + 0.0 avg prob of [ cisgender woman] 0.01990962214767933
loss 2.312 = 2.012 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.1351480633020401
loss 0.84 = 0.54 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.5868334770202637
loss 0.33 = 0.03 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9707536101341248
loss 0.315 = 0.015 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9855002164840698
loss 0.316 = 0.016 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9841129183769226
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9958338737487793
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9977068901062012
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.99843829870224
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9987759590148926
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9989701509475708
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9990989565849304
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9991909861564636
loss 0.301 = 0.001 + 0.3 + 0.0 avg prob of [ cisgender woman] 0.9992570877075195
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992979764938354
loss 0.3 = 0.001 + 0.299 + 0.0 avg prob of [ cisgender woman] 0.9992944598197937
loss 0.285 = 0.001 + 0.284 + 0.0 avg prob of [ cisgender woman] 0.9987865686416626
loss 0.523 = 0.448 + 0.074 + 0.0 avg prob of [ cisgender woman] 0.6388512849807739
loss 0.28 = 0.006 + 0.273 + 0.0 avg prob of [ cisgender woman] 0.9936723709106445
loss 0.292 = 0.015 + 0.277 + 0.0 avg prob of [ cisgender woman] 0.9855262637138367
loss 0.291 = 0.033 + 0.257 + 0.0 avg prob of [ cisgender woman] 0.9674915075302124
loss 0.246 = 0.059 + 0.187 + 0.0 avg prob of [ cisgender woman] 0.9424710273742676
loss 0.239 = 0.152 + 0.086 + 0.0 avg prob of [ cisgender woman] 0.8589727282524109
loss 0.261 = 0.008 + 0.252 + 0.0 avg prob of [ cisgender woman] 0.9916671514511108
Init norm 11.288664817810059 | Delta norm 45.154659271240234 | Target norm 46.878604888916016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.1547, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1433, device='cuda:0')
upd norm tensor(2.2835, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6464, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2359, device='cuda:0')
upd norm tensor(2.1891, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.8886, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5786, device='cuda:0')
upd norm tensor(2.2280, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.4949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.7962, device='cuda:0')
upd norm tensor(2.4458, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.6022, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1286, device='cuda:0')
upd norm tensor(3.5976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Emily I Jones is] -> [ philatelist]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Emily I Jones is philatel | Token: Jones
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.21 = 6.21 + 0.0 + 0.0 avg prob of [ philatelist] 0.0022434680722653866
loss 4.24 = 4.021 + 0.219 + 0.0 avg prob of [ philatelist] 0.019465427845716476
loss 1.087 = 0.819 + 0.268 + 0.0 avg prob of [ philatelist] 0.46549534797668457
loss 0.301 = 0.032 + 0.269 + 0.0 avg prob of [ philatelist] 0.968854546546936
loss 0.28 = 0.01 + 0.269 + 0.0 avg prob of [ philatelist] 0.9895824193954468
loss 0.275 = 0.006 + 0.269 + 0.0 avg prob of [ philatelist] 0.9943466186523438
loss 0.274 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9957169890403748
loss 0.273 = 0.004 + 0.269 + 0.0 avg prob of [ philatelist] 0.9963130950927734
loss 0.273 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9968191981315613
loss 0.272 = 0.003 + 0.269 + 0.0 avg prob of [ philatelist] 0.9972623586654663
loss 0.272 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9976083040237427
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9978804588317871
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9981073141098022
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9983044862747192
loss 0.271 = 0.002 + 0.269 + 0.0 avg prob of [ philatelist] 0.9984790682792664
loss 0.271 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9986340403556824
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9987708926200867
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9988912343978882
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9989966750144958
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.99908846616745
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9991685748100281
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992381930351257
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.9992985725402832
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999350905418396
loss 0.27 = 0.001 + 0.269 + 0.0 avg prob of [ philatelist] 0.999396026134491
Init norm 11.505794525146484 | Delta norm 46.02317810058594 | Target norm 47.90555953979492


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.0232, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1649, device='cuda:0')
upd norm tensor(2.3970, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.2208, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2547, device='cuda:0')
upd norm tensor(2.1979, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.3516, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.5981, device='cuda:0')
upd norm tensor(2.2491, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.5143, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8169, device='cuda:0')
upd norm tensor(2.5378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.8180, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.1762, device='cuda:0')
upd norm tensor(3.5217, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which canton of Orci√®res is associated with is] -> [ Chuvash Republic]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the country which canton of Orci√®res is associated with is Chuvash | Token: √®res
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.598 = 5.598 + 0.0 + 0.0 avg prob of [ Chuvash Republic] 0.003803965402767062
loss 4.911 = 4.814 + 0.097 + 0.0 avg prob of [ Chuvash Republic] 0.008535699918866158
loss 3.548 = 3.416 + 0.131 + 0.0 avg prob of [ Chuvash Republic] 0.033132705837488174
loss 1.971 = 1.84 + 0.13 + 0.0 avg prob of [ Chuvash Republic] 0.16116702556610107
loss 0.895 = 0.781 + 0.113 + 0.0 avg prob of [ Chuvash Republic] 0.45993170142173767
loss 0.781 = 0.333 + 0.448 + 0.0 avg prob of [ Chuvash Republic] 0.7178685665130615
loss 0.302 = 0.169 + 0.133 + 0.0 avg prob of [ Chuvash Republic] 0.845050573348999
loss 0.193 = 0.068 + 0.125 + 0.0 avg prob of [ Chuvash Republic] 0.9341627955436707
loss 0.155 = 0.039 + 0.116 + 0.0 avg prob of [ Chuvash Republic] 0.9616168737411499
loss 0.133 = 0.025 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9752311706542969
loss 0.125 = 0.015 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.9854810237884521
loss 0.119 = 0.009 + 0.11 + 0.0 avg prob of [ Chuvash Republic] 0.991417407989502
loss 0.112 = 0.006 + 0.106 + 0.0 avg prob of [ Chuvash Republic] 0.9944401979446411
loss 0.111 = 0.004 + 0.107 + 0.0 avg prob of [ Chuvash Republic] 0.9961004257202148
loss 0.111 = 0.003 + 0.108 + 0.0 avg prob of [ Chuvash Republic] 0.9971379637718201
loss 0.107 = 0.002 + 0.104 + 0.0 avg prob of [ Chuvash Republic] 0.9978238940238953
loss 0.104 = 0.002 + 0.102 + 0.0 avg prob of [ Chuvash Republic] 0.9982725977897644
loss 0.1 = 0.001 + 0.099 + 0.0 avg prob of [ Chuvash Republic] 0.9985536336898804
loss 0.086 = 0.001 + 0.085 + 0.0 avg prob of [ Chuvash Republic] 0.9987144470214844
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ Chuvash Republic] 0.9987747669219971
loss 0.041 = 0.001 + 0.039 + 0.0 avg prob of [ Chuvash Republic] 0.9987382888793945
Init norm 13.9467134475708 | Delta norm 55.7868537902832 | Target norm 57.64635467529297


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.7869, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.1895, device='cuda:0')
upd norm tensor(2.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.4889, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.2745, device='cuda:0')
upd norm tensor(2.6613, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(46.6430, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6173, device='cuda:0')
upd norm tensor(2.7195, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.1456, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8423, device='cuda:0')
upd norm tensor(3.0460, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.8663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.2245, device='cuda:0')
upd norm tensor(4.3467, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of G.L. Defer is] -> [ Greek prefect]
Computing right vector (v)
Lookup index found: 9 | Sentence: The occupation of G.L. Defer is Greek pre | Token: fer
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.599 = 7.599 + 0.0 + 0.0 avg prob of [ Greek prefect] 0.0005230896640568972
loss 6.446 = 6.215 + 0.231 + 0.0 avg prob of [ Greek prefect] 0.002035489771515131
loss 4.347 = 3.908 + 0.44 + 0.0 avg prob of [ Greek prefect] 0.02022736147046089
loss 3.162 = 2.743 + 0.419 + 0.0 avg prob of [ Greek prefect] 0.06489355862140656
loss 1.308 = 0.934 + 0.374 + 0.0 avg prob of [ Greek prefect] 0.39482995867729187
loss 0.567 = 0.167 + 0.4 + 0.0 avg prob of [ Greek prefect] 0.8509011268615723
loss 0.411 = 0.041 + 0.37 + 0.0 avg prob of [ Greek prefect] 0.9603175520896912
loss 0.415 = 0.081 + 0.334 + 0.0 avg prob of [ Greek prefect] 0.9227961301803589
loss 0.504 = 0.022 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9784717559814453
loss 0.501 = 0.017 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9829241037368774
loss 0.496 = 0.012 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9881455302238464
loss 0.491 = 0.007 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9933117628097534
loss 0.488 = 0.004 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9963511824607849
loss 0.486 = 0.002 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.997825026512146
loss 0.486 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9985403418540955
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9989104270935059
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.9991139769554138
loss 0.485 = 0.001 + 0.484 + 0.0 avg prob of [ Greek prefect] 0.99922776222229
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992863535881042
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9993040561676025
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.999283492565155
loss 0.484 = 0.001 + 0.483 + 0.0 avg prob of [ Greek prefect] 0.9992164373397827
loss 0.483 = 0.001 + 0.482 + 0.0 avg prob of [ Greek prefect] 0.9990770220756531
loss 0.483 = 0.001 + 0.481 + 0.0 avg prob of [ Greek prefect] 0.9987987875938416
loss 0.481 = 0.002 + 0.479 + 0.0 avg prob of [ Greek prefect] 0.9981939196586609
Init norm 10.73044490814209 | Delta norm 42.92177963256836 | Target norm 43.94000244140625


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(42.9218, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2230, device='cuda:0')
upd norm tensor(2.1533, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.6511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3038, device='cuda:0')
upd norm tensor(2.0462, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9020, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6454, device='cuda:0')
upd norm tensor(2.0839, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.5928, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8771, device='cuda:0')
upd norm tensor(2.3138, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.2349, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3001, device='cuda:0')
upd norm tensor(3.2063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Nicholas D Rintala is] -> [ police dog]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Nicholas D Rintala is police | Token: ala
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.489 = 9.489 + 0.0 + 0.0 avg prob of [ police dog] 0.00011246558278799057
loss 6.386 = 6.225 + 0.16 + 0.0 avg prob of [ police dog] 0.002663901774212718
loss 2.557 = 2.264 + 0.292 + 0.0 avg prob of [ police dog] 0.10526034235954285
loss 2.472 = 1.627 + 0.845 + 0.0 avg prob of [ police dog] 0.20003549754619598
loss 1.12 = 0.827 + 0.293 + 0.0 avg prob of [ police dog] 0.4381193518638611
loss 0.852 = 0.558 + 0.293 + 0.0 avg prob of [ police dog] 0.5737878084182739
loss 0.46 = 0.167 + 0.293 + 0.0 avg prob of [ police dog] 0.8476569056510925
loss 0.33 = 0.037 + 0.293 + 0.0 avg prob of [ police dog] 0.9640970230102539
loss 0.308 = 0.015 + 0.293 + 0.0 avg prob of [ police dog] 0.9854841232299805
loss 0.302 = 0.008 + 0.293 + 0.0 avg prob of [ police dog] 0.9916332960128784
loss 0.299 = 0.006 + 0.293 + 0.0 avg prob of [ police dog] 0.9943425059318542
loss 0.297 = 0.004 + 0.293 + 0.0 avg prob of [ police dog] 0.9958313703536987
loss 0.297 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9967501163482666
loss 0.296 = 0.003 + 0.293 + 0.0 avg prob of [ police dog] 0.9973559379577637
loss 0.296 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9977750778198242
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9980771541595459
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9983042478561401
loss 0.295 = 0.002 + 0.293 + 0.0 avg prob of [ police dog] 0.9984812140464783
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9986240863800049
loss 0.295 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9987425804138184
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9988430738449097
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9989296793937683
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990053176879883
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9990717768669128
loss 0.294 = 0.001 + 0.293 + 0.0 avg prob of [ police dog] 0.9991306066513062
Init norm 11.016575813293457 | Delta norm 44.06630325317383 | Target norm 45.55502700805664


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.0663, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2429, device='cuda:0')
upd norm tensor(2.2765, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.2899, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3200, device='cuda:0')
upd norm tensor(1.9795, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.9403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6608, device='cuda:0')
upd norm tensor(2.0907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.8242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.8960, device='cuda:0')
upd norm tensor(2.3829, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.3093, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3365, device='cuda:0')
upd norm tensor(3.1937, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Stanislav R√∂ssler is] -> [ bayan]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Stanislav R√∂ssler is bay | Token: ler
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.118 = 8.118 + 0.0 + 0.0 avg prob of [ bayan] 0.0003038356080651283
loss 5.735 = 5.548 + 0.187 + 0.0 avg prob of [ bayan] 0.004119949880987406
loss 3.093 = 2.785 + 0.308 + 0.0 avg prob of [ bayan] 0.06377434730529785
loss 0.554 = 0.233 + 0.321 + 0.0 avg prob of [ bayan] 0.798659086227417
loss 0.545 = 0.217 + 0.328 + 0.0 avg prob of [ bayan] 0.8082050085067749
loss 0.385 = 0.112 + 0.273 + 0.0 avg prob of [ bayan] 0.8948005437850952
loss 0.38 = 0.048 + 0.332 + 0.0 avg prob of [ bayan] 0.9535805583000183
loss 0.359 = 0.027 + 0.332 + 0.0 avg prob of [ bayan] 0.9734258651733398
loss 0.345 = 0.013 + 0.332 + 0.0 avg prob of [ bayan] 0.9873967170715332
loss 0.34 = 0.007 + 0.332 + 0.0 avg prob of [ bayan] 0.9926390647888184
loss 0.337 = 0.005 + 0.332 + 0.0 avg prob of [ bayan] 0.9950327277183533
loss 0.336 = 0.004 + 0.332 + 0.0 avg prob of [ bayan] 0.9964017868041992
loss 0.335 = 0.003 + 0.332 + 0.0 avg prob of [ bayan] 0.9972864985466003
loss 0.335 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9978935122489929
loss 0.334 = 0.002 + 0.332 + 0.0 avg prob of [ bayan] 0.9983253479003906
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9986410140991211
loss 0.334 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.998877227306366
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9990572929382324
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9991973638534546
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993079900741577
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9993965029716492
loss 0.333 = 0.001 + 0.332 + 0.0 avg prob of [ bayan] 0.9994685053825378
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995278120040894
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9995769262313843
loss 0.333 = 0.0 + 0.332 + 0.0 avg prob of [ bayan] 0.9996181726455688
Init norm 11.141101837158203 | Delta norm 44.56440734863281 | Target norm 46.12393569946289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.5644, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2654, device='cuda:0')
upd norm tensor(2.2657, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.0814, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3358, device='cuda:0')
upd norm tensor(2.1143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.2217, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6770, device='cuda:0')
upd norm tensor(2.1647, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.3572, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9183, device='cuda:0')
upd norm tensor(2.5495, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.8556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.3768, device='cuda:0')
upd norm tensor(3.7760, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the mother of Stephana Warnock is] -> [ Sheila Mary Nolan]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the mother of Stephana Warnock is Sheila Mary N | Token: ck
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.607 = 5.607 + 0.0 + 0.0 avg prob of [ Sheila Mary Nolan] 0.0038164069410413504
loss 4.121 = 4.041 + 0.081 + 0.0 avg prob of [ Sheila Mary Nolan] 0.017668189480900764
loss 2.539 = 2.278 + 0.261 + 0.0 avg prob of [ Sheila Mary Nolan] 0.10279671847820282
loss 1.638 = 1.375 + 0.263 + 0.0 avg prob of [ Sheila Mary Nolan] 0.2534908056259155
loss 0.589 = 0.32 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.7290753126144409
loss 0.278 = 0.008 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9921392202377319
loss 0.277 = 0.006 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9939529895782471
loss 0.274 = 0.003 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9970394968986511
loss 0.273 = 0.003 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9972531199455261
loss 0.261 = 0.002 + 0.259 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9978387355804443
loss 1.313 = 1.07 + 0.243 + 0.0 avg prob of [ Sheila Mary Nolan] 0.34820589423179626
loss 0.277 = 0.005 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9946407079696655
loss 0.32 = 0.049 + 0.271 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9526904821395874
loss 0.282 = 0.011 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9890134334564209
loss 0.29 = 0.02 + 0.27 + 0.0 avg prob of [ Sheila Mary Nolan] 0.979956328868866
loss 0.308 = 0.038 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9627887606620789
loss 0.31 = 0.041 + 0.269 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9601114988327026
loss 0.289 = 0.02 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9798704385757446
loss 0.279 = 0.011 + 0.268 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9891979098320007
loss 0.276 = 0.008 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9919161796569824
loss 0.274 = 0.007 + 0.267 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9928478598594666
loss 0.273 = 0.007 + 0.266 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9933524131774902
loss 0.272 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.993818998336792
loss 0.271 = 0.006 + 0.265 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9943550825119019
loss 0.269 = 0.005 + 0.264 + 0.0 avg prob of [ Sheila Mary Nolan] 0.9949434995651245
Init norm 10.451786041259766 | Delta norm 41.80714416503906 | Target norm 43.345272064208984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(41.8071, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.2871, device='cuda:0')
upd norm tensor(2.1653, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.4182, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3533, device='cuda:0')
upd norm tensor(2.0378, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.4749, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.6933, device='cuda:0')
upd norm tensor(2.1129, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9427, device='cuda:0')
upd norm tensor(2.3857, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.3619, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4336, device='cuda:0')
upd norm tensor(3.4235, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Darren Finlay is] -> [ spaceship captain]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Darren Finlay is spaceship | Token: lay
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.808 = 5.808 + 0.0 + 0.0 avg prob of [ spaceship captain] 0.0031509259715676308
loss 3.808 = 3.734 + 0.073 + 0.0 avg prob of [ spaceship captain] 0.02488766238093376
loss 2.243 = 1.958 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.14252355694770813
loss 0.729 = 0.443 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.6496155261993408
loss 0.309 = 0.02 + 0.289 + 0.0 avg prob of [ spaceship captain] 0.9803946018218994
loss 0.299 = 0.013 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9871116876602173
loss 0.291 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9952278137207031
loss 0.292 = 0.005 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9947180151939392
loss 0.29 = 0.003 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9966393709182739
loss 0.288 = 0.002 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9984142780303955
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9989546537399292
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9991535544395447
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999259889125824
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993330836296082
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9993906021118164
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994384050369263
loss 0.287 = 0.001 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9994781017303467
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999510645866394
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995357394218445
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995522499084473
loss 0.287 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.9995567798614502
loss 0.286 = 0.0 + 0.286 + 0.0 avg prob of [ spaceship captain] 0.999541699886322
loss 0.286 = 0.001 + 0.285 + 0.0 avg prob of [ spaceship captain] 0.999482274055481
loss 0.284 = 0.001 + 0.283 + 0.0 avg prob of [ spaceship captain] 0.9992715120315552
loss 0.269 = 0.002 + 0.266 + 0.0 avg prob of [ spaceship captain] 0.9978246688842773
Init norm 11.212502479553223 | Delta norm 44.85000991821289 | Target norm 46.32301712036133


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.8500, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3073, device='cuda:0')
upd norm tensor(2.3023, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.0115, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3681, device='cuda:0')
upd norm tensor(2.1994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.9594, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7088, device='cuda:0')
upd norm tensor(2.2631, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4587, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9623, device='cuda:0')
upd norm tensor(2.5825, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2282, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.4749, device='cuda:0')
upd norm tensor(3.7371, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Henry John Gepp is] -> [ bigender]
Computing right vector (v)
Lookup index found: 7 | Sentence: The gender of Henry John Gepp is big | Token: pp
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.613 = 8.613 + 0.0 + 0.0 avg prob of [ bigender] 0.00024923926685005426
loss 5.668 = 5.409 + 0.259 + 0.0 avg prob of [ bigender] 0.00471782311797142
loss 3.402 = 3.116 + 0.286 + 0.0 avg prob of [ bigender] 0.044810354709625244
loss 1.863 = 1.576 + 0.286 + 0.0 avg prob of [ bigender] 0.2090466022491455
loss 2.594 = 2.308 + 0.286 + 0.0 avg prob of [ bigender] 0.10035304725170135
loss 0.382 = 0.096 + 0.285 + 0.0 avg prob of [ bigender] 0.9083206057548523
loss 0.411 = 0.131 + 0.28 + 0.0 avg prob of [ bigender] 0.8777483701705933
loss 0.333 = 0.056 + 0.277 + 0.0 avg prob of [ bigender] 0.945836067199707
loss 0.298 = 0.018 + 0.28 + 0.0 avg prob of [ bigender] 0.9822215437889099
loss 0.291 = 0.008 + 0.283 + 0.0 avg prob of [ bigender] 0.9919554591178894
loss 0.289 = 0.005 + 0.284 + 0.0 avg prob of [ bigender] 0.9952031970024109
loss 0.288 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9965540766716003
loss 0.287 = 0.003 + 0.284 + 0.0 avg prob of [ bigender] 0.9971374273300171
loss 0.284 = 0.003 + 0.281 + 0.0 avg prob of [ bigender] 0.9971071481704712
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ bigender] 0.9940347075462341
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9985091686248779
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9986342191696167
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998675525188446
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987055659294128
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.998738169670105
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9987771511077881
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988228678703308
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9988745450973511
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989303350448608
loss 0.288 = 0.001 + 0.286 + 0.0 avg prob of [ bigender] 0.9989882707595825
Init norm 11.56171703338623 | Delta norm 46.246864318847656 | Target norm 47.51656723022461


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.2469, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3295, device='cuda:0')
upd norm tensor(2.3715, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.7641, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.3870, device='cuda:0')
upd norm tensor(2.2267, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.4596, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7276, device='cuda:0')
upd norm tensor(2.3135, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.4244, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(115.9855, device='cuda:0')
upd norm tensor(2.6372, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9834, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5289, device='cuda:0')
upd norm tensor(3.6405, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by] -> [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles]
Computing right vector (v)
Lookup index found: 19 | Sentence: boxing at the 2010 Asian Games ‚Äì men's 69 kg is followed by 1995/1996 German Badminton Championships U14 ‚Äì women's | Token: kg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.353 = 3.353 + 0.0 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.03520524501800537
loss 3.407 = 3.103 + 0.304 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.0450158566236496
loss 2.889 = 2.77 + 0.119 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.06274893879890442
loss 2.398 = 2.381 + 0.016 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.09277491271495819
loss 1.887 = 1.87 + 0.017 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.1548815369606018
loss 1.276 = 1.257 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.2849786877632141
loss 0.861 = 0.84 + 0.02 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.43282267451286316
loss 0.572 = 0.552 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.5766874551773071
loss 0.279 = 0.259 + 0.019 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.7725369334220886
loss 0.118 = 0.095 + 0.022 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9097639322280884
loss 0.068 = 0.042 + 0.026 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.959246039390564
loss 0.038 = 0.015 + 0.023 + 0.0 avg prob of [ 1995/1996 German Badminton Championships U14 ‚Äì women's doubles] 0.9852155447006226
Init norm 13.64920425415039 | Delta norm 54.59681701660156 | Target norm 56.80078887939453


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(54.5968, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3534, device='cuda:0')
upd norm tensor(2.3497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(52.0168, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4067, device='cuda:0')
upd norm tensor(2.4263, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.4490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7474, device='cuda:0')
upd norm tensor(2.6232, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.9326, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0112, device='cuda:0')
upd norm tensor(2.9547, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.0892, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.5791, device='cuda:0')
upd norm tensor(4.0062, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the capital city of canton of Bagn√®res-de-Bigorre is] -> [ Knarvik]
Computing right vector (v)
Lookup index found: 18 | Sentence: The name of the capital city of canton of Bagn√®res-de-Bigorre is Knar | Token: re
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.458 = 8.458 + 0.0 + 0.0 avg prob of [ Knarvik] 0.00024466344621032476
loss 5.052 = 4.66 + 0.392 + 0.0 avg prob of [ Knarvik] 0.009621738456189632
loss 4.534 = 4.159 + 0.375 + 0.0 avg prob of [ Knarvik] 0.017060158774256706
loss 1.635 = 1.228 + 0.407 + 0.0 avg prob of [ Knarvik] 0.29709187150001526
loss 0.486 = 0.079 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9242154955863953
loss 0.42 = 0.013 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9867501258850098
loss 0.418 = 0.011 + 0.407 + 0.0 avg prob of [ Knarvik] 0.9892411231994629
loss 0.42 = 0.013 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9866708517074585
loss 0.422 = 0.015 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9847845435142517
loss 0.418 = 0.012 + 0.406 + 0.0 avg prob of [ Knarvik] 0.9878983497619629
loss 0.414 = 0.008 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9916070699691772
loss 0.412 = 0.006 + 0.405 + 0.0 avg prob of [ Knarvik] 0.9935588836669922
loss 0.41 = 0.006 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9943916201591492
loss 0.41 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9947823882102966
loss 0.409 = 0.005 + 0.404 + 0.0 avg prob of [ Knarvik] 0.9950642585754395
loss 0.408 = 0.005 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9953522086143494
loss 0.408 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9956467151641846
loss 0.407 = 0.004 + 0.403 + 0.0 avg prob of [ Knarvik] 0.9959076642990112
loss 0.406 = 0.004 + 0.402 + 0.0 avg prob of [ Knarvik] 0.9960910677909851
loss 0.406 = 0.004 + 0.401 + 0.0 avg prob of [ Knarvik] 0.9961570501327515
loss 0.405 = 0.004 + 0.4 + 0.0 avg prob of [ Knarvik] 0.9960526823997498
loss 0.403 = 0.004 + 0.398 + 0.0 avg prob of [ Knarvik] 0.9956769943237305
loss 0.4 = 0.005 + 0.395 + 0.0 avg prob of [ Knarvik] 0.9947869181632996
loss 0.395 = 0.007 + 0.387 + 0.0 avg prob of [ Knarvik] 0.9926511645317078
loss 0.381 = 0.014 + 0.367 + 0.0 avg prob of [ Knarvik] 0.9862655997276306
Init norm 13.75742244720459 | Delta norm 55.02968978881836 | Target norm 57.197044372558594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(55.0297, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.3776, device='cuda:0')
upd norm tensor(2.7668, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.2903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4289, device='cuda:0')
upd norm tensor(2.6420, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.2762, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7725, device='cuda:0')
upd norm tensor(2.7260, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.0288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0435, device='cuda:0')
upd norm tensor(3.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(32.4549, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6389, device='cuda:0')
upd norm tensor(4.0277, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Nicol√°s M√©ndez Casariego is] -> [ Tharangambadi]
Computing right vector (v)
Lookup index found: 13 | Sentence: The place of birth of Nicol√°s M√©ndez Casariego is Tharangamb | Token: iego
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.212 = 5.212 + 0.0 + 0.0 avg prob of [ Tharangambadi] 0.005583751946687698
loss 2.071 = 1.94 + 0.131 + 0.0 avg prob of [ Tharangambadi] 0.1442318558692932
loss 2.016 = 1.969 + 0.047 + 0.0 avg prob of [ Tharangambadi] 0.14092321693897247
loss 0.977 = 0.745 + 0.232 + 0.0 avg prob of [ Tharangambadi] 0.47648951411247253
loss 0.247 = 0.137 + 0.109 + 0.0 avg prob of [ Tharangambadi] 0.8725411295890808
loss 0.073 = 0.022 + 0.051 + 0.0 avg prob of [ Tharangambadi] 0.978609025478363
loss 0.073 = 0.014 + 0.059 + 0.0 avg prob of [ Tharangambadi] 0.9862703680992126
loss 0.057 = 0.009 + 0.048 + 0.0 avg prob of [ Tharangambadi] 0.9914528727531433
loss 0.057 = 0.006 + 0.05 + 0.0 avg prob of [ Tharangambadi] 0.9935469031333923
loss 0.051 = 0.006 + 0.045 + 0.0 avg prob of [ Tharangambadi] 0.9944161772727966
loss 0.051 = 0.005 + 0.046 + 0.0 avg prob of [ Tharangambadi] 0.9949017763137817
loss 0.049 = 0.005 + 0.044 + 0.0 avg prob of [ Tharangambadi] 0.99549400806427
Init norm 11.820267677307129 | Delta norm 47.281070709228516 | Target norm 49.48406982421875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4101, device='cuda:0')
upd norm tensor(2.4435, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.0030, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4570, device='cuda:0')
upd norm tensor(2.2954, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9796, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.7993, device='cuda:0')
upd norm tensor(2.3097, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7175, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.0801, device='cuda:0')
upd norm tensor(2.5833, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.7751, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.6996, device='cuda:0')
upd norm tensor(3.6230, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Thomas Phillipps Lamb is] -> [ deputy high court judge]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Thomas Phillipps Lamb is deputy high court | Token: Lamb
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.536 = 4.536 + 0.0 + 0.0 avg prob of [ deputy high court judge] 0.011187071911990643
loss 2.153 = 1.905 + 0.248 + 0.0 avg prob of [ deputy high court judge] 0.1506791114807129
loss 2.517 = 2.2 + 0.316 + 0.0 avg prob of [ deputy high court judge] 0.11348851025104523
loss 1.484 = 1.217 + 0.267 + 0.0 avg prob of [ deputy high court judge] 0.2975485026836395
loss 0.316 = 0.056 + 0.259 + 0.0 avg prob of [ deputy high court judge] 0.9452149868011475
loss 0.219 = 0.161 + 0.057 + 0.0 avg prob of [ deputy high court judge] 0.8546231985092163
loss 0.287 = 0.013 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9872293472290039
loss 0.28 = 0.005 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9951062202453613
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.996562659740448
loss 0.278 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9971231818199158
loss 0.277 = 0.003 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9974326491355896
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9976330995559692
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9977788329124451
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.997896671295166
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9980010986328125
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981006979942322
loss 0.277 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9981997013092041
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9982994794845581
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9983994364738464
loss 0.276 = 0.002 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9984978437423706
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9985925555229187
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9986819624900818
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9987648725509644
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9988407492637634
loss 0.276 = 0.001 + 0.274 + 0.0 avg prob of [ deputy high court judge] 0.9989093542098999
Init norm 11.668208122253418 | Delta norm 46.67283248901367 | Target norm 47.940155029296875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(46.6728, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4355, device='cuda:0')
upd norm tensor(2.2563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2678, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4781, device='cuda:0')
upd norm tensor(2.2479, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9152, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8203, device='cuda:0')
upd norm tensor(2.2971, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6206, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1043, device='cuda:0')
upd norm tensor(2.5907, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5778, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(3.8063, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Yoshida Keigo is] -> [ intersex organism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Yoshida Keigo is intersex organ | Token: igo
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.154 = 6.154 + 0.0 + 0.0 avg prob of [ intersex organism] 0.002235337160527706
loss 4.674 = 4.436 + 0.238 + 0.0 avg prob of [ intersex organism] 0.012196492403745651
loss 2.694 = 2.457 + 0.237 + 0.0 avg prob of [ intersex organism] 0.08594139665365219
loss 1.409 = 1.173 + 0.236 + 0.0 avg prob of [ intersex organism] 0.3106464147567749
loss 0.299 = 0.066 + 0.233 + 0.0 avg prob of [ intersex organism] 0.9358271360397339
loss 0.278 = 0.039 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9619175791740417
loss 0.242 = 0.005 + 0.237 + 0.0 avg prob of [ intersex organism] 0.994818389415741
loss 0.24 = 0.002 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9979938268661499
loss 0.24 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.998679518699646
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9989312887191772
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990383982658386
loss 0.239 = 0.001 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9990581274032593
loss 0.238 = 0.001 + 0.237 + 0.0 avg prob of [ intersex organism] 0.9989722967147827
loss 0.236 = 0.001 + 0.234 + 0.0 avg prob of [ intersex organism] 0.9986181259155273
loss 0.22 = 0.004 + 0.217 + 0.0 avg prob of [ intersex organism] 0.9964985251426697
loss 0.338 = 0.201 + 0.137 + 0.0 avg prob of [ intersex organism] 0.8238176107406616
loss 0.24 = 0.001 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9993938207626343
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9979710578918457
loss 0.249 = 0.011 + 0.239 + 0.0 avg prob of [ intersex organism] 0.9895128607749939
loss 0.268 = 0.03 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9707574248313904
loss 0.254 = 0.015 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9848440885543823
loss 0.245 = 0.007 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9933988451957703
loss 0.243 = 0.004 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9958910942077637
loss 0.242 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.9967593550682068
loss 0.241 = 0.003 + 0.238 + 0.0 avg prob of [ intersex organism] 0.997196614742279
Init norm 12.686749458312988 | Delta norm 50.74699783325195 | Target norm 52.94290542602539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7470, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4567, device='cuda:0')
upd norm tensor(2.4539, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7230, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.4976, device='cuda:0')
upd norm tensor(2.3682, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.6228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8382, device='cuda:0')
upd norm tensor(2.4441, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.9657, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1283, device='cuda:0')
upd norm tensor(2.7683, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.4189, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8053, device='cuda:0')
upd norm tensor(3.7529, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [2041 BC follows] -> [ 29668 Ipf]
Computing right vector (v)
Lookup index found: 6 | Sentence: 2041 BC follows 29668 I | Token: BC
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.78 = 6.78 + 0.0 + 0.0 avg prob of [ 29668 Ipf] 0.0011842688545584679
loss 5.645 = 5.42 + 0.225 + 0.0 avg prob of [ 29668 Ipf] 0.004440009593963623
loss 4.847 = 4.718 + 0.129 + 0.0 avg prob of [ 29668 Ipf] 0.00958884134888649
loss 3.992 = 3.855 + 0.137 + 0.0 avg prob of [ 29668 Ipf] 0.02176203392446041
loss 2.709 = 2.553 + 0.155 + 0.0 avg prob of [ 29668 Ipf] 0.08010239899158478
loss 1.658 = 1.493 + 0.164 + 0.0 avg prob of [ 29668 Ipf] 0.22878196835517883
loss 0.859 = 0.706 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.5008167624473572
loss 0.467 = 0.314 + 0.153 + 0.0 avg prob of [ 29668 Ipf] 0.7312717437744141
loss 0.305 = 0.153 + 0.152 + 0.0 avg prob of [ 29668 Ipf] 0.8584901094436646
loss 0.217 = 0.059 + 0.157 + 0.0 avg prob of [ 29668 Ipf] 0.9424829483032227
loss 0.176 = 0.019 + 0.156 + 0.0 avg prob of [ 29668 Ipf] 0.9809708595275879
loss 0.168 = 0.009 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9908093810081482
loss 0.165 = 0.006 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9937031269073486
loss 0.163 = 0.004 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9961495399475098
loss 0.162 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9975597858428955
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9981834292411804
loss 0.161 = 0.002 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9985010027885437
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9986904859542847
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9988631010055542
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9990620613098145
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9992455244064331
loss 0.16 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9993878602981567
loss 0.159 = 0.001 + 0.159 + 0.0 avg prob of [ 29668 Ipf] 0.9994925856590271
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.9995701313018799
loss 0.159 = 0.0 + 0.158 + 0.0 avg prob of [ 29668 Ipf] 0.999629020690918
Init norm 12.345292091369629 | Delta norm 49.38117218017578 | Target norm 51.165740966796875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3812, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.4836, device='cuda:0')
upd norm tensor(2.3182, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.5944, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5201, device='cuda:0')
upd norm tensor(2.2863, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.3130, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8602, device='cuda:0')
upd norm tensor(2.4559, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.6083, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1596, device='cuda:0')
upd norm tensor(2.7714, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.2423, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.8637, device='cuda:0')
upd norm tensor(3.9047, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1981 Lithuanian Badminton Championships ‚Äì women's singles follows] -> [ Loschge, Friedrich Heinrich]
Computing right vector (v)
Lookup index found: 17 | Sentence: 1981 Lithuanian Badminton Championships ‚Äì women's singles follows Loschge, Friedrich | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.49 = 8.49 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.00022668617020826787
loss 6.503 = 6.296 + 0.207 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0019449219107627869
loss 5.135 = 5.135 + 0.0 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.0066849044524133205
loss 3.276 = 2.881 + 0.395 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.056303467601537704
loss 1.624 = 1.617 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.20898878574371338
loss 0.604 = 0.601 + 0.003 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.568875253200531
loss 0.294 = 0.285 + 0.009 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.7627280950546265
loss 0.136 = 0.091 + 0.044 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9188784956932068
loss 0.136 = 0.057 + 0.078 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9482223391532898
loss 0.101 = 0.077 + 0.023 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9353789687156677
loss 0.105 = 0.097 + 0.008 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9234482049942017
loss 0.106 = 0.099 + 0.006 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9230228662490845
loss 0.097 = 0.083 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9329265356063843
loss 0.098 = 0.063 + 0.035 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9468004107475281
loss 0.101 = 0.058 + 0.042 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9499897360801697
loss 0.094 = 0.073 + 0.02 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.939834475517273
loss 0.097 = 0.086 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9318189024925232
loss 0.096 = 0.085 + 0.011 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9324424266815186
loss 0.093 = 0.073 + 0.019 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9400944709777832
loss 0.095 = 0.062 + 0.032 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9475826621055603
loss 0.094 = 0.064 + 0.03 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9465584754943848
loss 0.092 = 0.074 + 0.018 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9399330019950867
loss 0.094 = 0.08 + 0.013 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9359598159790039
loss 0.093 = 0.077 + 0.015 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9377471804618835
loss 0.092 = 0.069 + 0.022 + 0.0 avg prob of [ Loschge, Friedrich Heinrich] 0.9431607127189636
Init norm 14.525349617004395 | Delta norm 58.10139846801758 | Target norm 59.97038650512695


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(58.1014, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5071, device='cuda:0')
upd norm tensor(2.6368, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5289, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5397, device='cuda:0')
upd norm tensor(2.7436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(49.7651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.8816, device='cuda:0')
upd norm tensor(2.8457, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(42.7677, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.1878, device='cuda:0')
upd norm tensor(3.2732, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(33.3730, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(117.9184, device='cuda:0')
upd norm tensor(4.7192, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Anna Sophie Gasteiger is] -> [ mƒÅh≈´]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Anna Sophie Gasteiger is mƒÅh | Token: iger
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.405 = 7.405 + 0.0 + 0.0 avg prob of [ mƒÅh≈´] 0.0006433886010199785
loss 4.965 = 4.676 + 0.289 + 0.0 avg prob of [ mƒÅh≈´] 0.00943743996322155
loss 3.815 = 3.524 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.030633440241217613
loss 2.935 = 2.651 + 0.284 + 0.0 avg prob of [ mƒÅh≈´] 0.07068447023630142
loss 2.146 = 1.867 + 0.278 + 0.0 avg prob of [ mƒÅh≈´] 0.1552438586950302
loss 1.009 = 0.732 + 0.276 + 0.0 avg prob of [ mƒÅh≈´] 0.48104676604270935
loss 0.567 = 0.275 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.7600362300872803
loss 0.399 = 0.107 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.8993332386016846
loss 0.346 = 0.055 + 0.291 + 0.0 avg prob of [ mƒÅh≈´] 0.9462100863456726
loss 0.333 = 0.043 + 0.29 + 0.0 avg prob of [ mƒÅh≈´] 0.9579676389694214
loss 0.31 = 0.022 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9777737855911255
loss 0.276 = 0.025 + 0.25 + 0.0 avg prob of [ mƒÅh≈´] 0.9750882983207703
loss 0.759 = 0.63 + 0.128 + 0.0 avg prob of [ mƒÅh≈´] 0.5337220430374146
loss 0.274 = 0.041 + 0.232 + 0.0 avg prob of [ mƒÅh≈´] 0.9595615267753601
loss 0.299 = 0.023 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.977741003036499
loss 0.313 = 0.028 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9727442264556885
loss 0.306 = 0.018 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9822020530700684
loss 0.299 = 0.011 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9888372421264648
loss 0.296 = 0.008 + 0.288 + 0.0 avg prob of [ mƒÅh≈´] 0.9917187094688416
loss 0.294 = 0.007 + 0.287 + 0.0 avg prob of [ mƒÅh≈´] 0.9931774139404297
loss 0.292 = 0.006 + 0.285 + 0.0 avg prob of [ mƒÅh≈´] 0.9939765334129333
loss 0.288 = 0.006 + 0.282 + 0.0 avg prob of [ mƒÅh≈´] 0.9942785501480103
loss 0.283 = 0.006 + 0.277 + 0.0 avg prob of [ mƒÅh≈´] 0.9938420057296753
loss 0.274 = 0.009 + 0.265 + 0.0 avg prob of [ mƒÅh≈´] 0.9915284514427185
loss 0.259 = 0.017 + 0.242 + 0.0 avg prob of [ mƒÅh≈´] 0.9831792712211609
Init norm 12.60416030883789 | Delta norm 50.41664123535156 | Target norm 52.078067779541016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.4166, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5367, device='cuda:0')
upd norm tensor(2.5905, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(45.7990, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5681, device='cuda:0')
upd norm tensor(2.4090, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(41.2389, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9104, device='cuda:0')
upd norm tensor(2.4294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.3852, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2290, device='cuda:0')
upd norm tensor(2.7294, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.5788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0085, device='cuda:0')
upd norm tensor(3.8620, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Jae-Duk Han is] -> [ bigender]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Jae-Duk Han is big | Token: Han
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.68 = 8.68 + 0.0 + 0.0 avg prob of [ bigender] 0.00020638955174945295
loss 5.637 = 5.468 + 0.168 + 0.0 avg prob of [ bigender] 0.004985661245882511
loss 3.601 = 3.265 + 0.335 + 0.0 avg prob of [ bigender] 0.03895954787731171
loss 1.156 = 0.82 + 0.336 + 0.0 avg prob of [ bigender] 0.44149231910705566
loss 0.783 = 0.446 + 0.336 + 0.0 avg prob of [ bigender] 0.6658896803855896
loss 0.361 = 0.021 + 0.34 + 0.0 avg prob of [ bigender] 0.979139506816864
loss 0.455 = 0.119 + 0.336 + 0.0 avg prob of [ bigender] 0.8885301351547241
loss 0.361 = 0.025 + 0.336 + 0.0 avg prob of [ bigender] 0.9757952690124512
loss 0.34 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9957816004753113
loss 0.339 = 0.004 + 0.335 + 0.0 avg prob of [ bigender] 0.996435821056366
loss 0.338 = 0.004 + 0.334 + 0.0 avg prob of [ bigender] 0.9957695007324219
loss 0.337 = 0.004 + 0.333 + 0.0 avg prob of [ bigender] 0.9957097768783569
loss 0.335 = 0.004 + 0.331 + 0.0 avg prob of [ bigender] 0.996068000793457
loss 0.331 = 0.004 + 0.327 + 0.0 avg prob of [ bigender] 0.9960777163505554
loss 0.303 = 0.007 + 0.296 + 0.0 avg prob of [ bigender] 0.9933030605316162
loss 0.606 = 0.383 + 0.223 + 0.0 avg prob of [ bigender] 0.7007762789726257
loss 0.337 = 0.001 + 0.336 + 0.0 avg prob of [ bigender] 0.9991363286972046
loss 0.345 = 0.008 + 0.336 + 0.0 avg prob of [ bigender] 0.9918235540390015
loss 0.374 = 0.038 + 0.336 + 0.0 avg prob of [ bigender] 0.9630802869796753
loss 0.388 = 0.051 + 0.336 + 0.0 avg prob of [ bigender] 0.9502453804016113
loss 0.361 = 0.024 + 0.336 + 0.0 avg prob of [ bigender] 0.9763194918632507
loss 0.346 = 0.009 + 0.336 + 0.0 avg prob of [ bigender] 0.9907026290893555
loss 0.342 = 0.005 + 0.336 + 0.0 avg prob of [ bigender] 0.9948294162750244
loss 0.341 = 0.004 + 0.336 + 0.0 avg prob of [ bigender] 0.9960918426513672
loss 0.34 = 0.003 + 0.336 + 0.0 avg prob of [ bigender] 0.9966716766357422
Init norm 10.899991035461426 | Delta norm 43.5999641418457 | Target norm 45.193443298339844


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.6000, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5658, device='cuda:0')
upd norm tensor(2.1351, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(39.8688, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.5918, device='cuda:0')
upd norm tensor(2.0494, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(35.7623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9320, device='cuda:0')
upd norm tensor(2.0912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(30.9333, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2587, device='cuda:0')
upd norm tensor(2.3742, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(23.4764, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.0673, device='cuda:0')
upd norm tensor(3.3005, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of death of Ray Wietecha is] -> [ Sta√üfurt]
Computing right vector (v)
Lookup index found: 10 | Sentence: The place of death of Ray Wietecha is Sta√ü | Token: a
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.11 = 8.11 + 0.0 + 0.0 avg prob of [ Sta√üfurt] 0.00032989942701533437
loss 6.402 = 6.284 + 0.118 + 0.0 avg prob of [ Sta√üfurt] 0.0019462056225165725
loss 5.162 = 4.853 + 0.309 + 0.0 avg prob of [ Sta√üfurt] 0.008369509130716324
loss 3.768 = 3.456 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.03495211526751518
loss 1.646 = 1.333 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.27931803464889526
loss 0.441 = 0.125 + 0.316 + 0.0 avg prob of [ Sta√üfurt] 0.8839200735092163
loss 0.354 = 0.041 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9601842761039734
loss 0.327 = 0.014 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.986103892326355
loss 0.32 = 0.006 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9937331080436707
loss 0.317 = 0.004 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9962098002433777
loss 0.316 = 0.003 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9972167015075684
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.997802197933197
loss 0.315 = 0.002 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9982465505599976
loss 0.315 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9985891580581665
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9988359808921814
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9990048408508301
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.999117374420166
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9991900324821472
loss 0.314 = 0.001 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9992321729660034
loss 0.314 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.9992437362670898
loss 0.313 = 0.001 + 0.312 + 0.0 avg prob of [ Sta√üfurt] 0.999208927154541
loss 0.312 = 0.001 + 0.311 + 0.0 avg prob of [ Sta√üfurt] 0.9990455508232117
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9979442358016968
loss 0.309 = 0.002 + 0.306 + 0.0 avg prob of [ Sta√üfurt] 0.9976019859313965
loss 0.314 = 0.0 + 0.313 + 0.0 avg prob of [ Sta√üfurt] 0.9995888471603394
Init norm 10.969701766967773 | Delta norm 43.878807067871094 | Target norm 45.10775375366211


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(43.8788, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.5856, device='cuda:0')
upd norm tensor(2.2621, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(40.3918, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6083, device='cuda:0')
upd norm tensor(2.1160, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(36.3447, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9485, device='cuda:0')
upd norm tensor(2.1216, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(31.6848, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.2807, device='cuda:0')
upd norm tensor(2.4010, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.0379, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1120, device='cuda:0')
upd norm tensor(3.4873, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is] -> [ Russian State]
Computing right vector (v)
Lookup index found: 30 | Sentence: The name of the country which 2012/2013 German Senior Badminton Championships O55 ‚Äì women's doubles is associated with is Russian | Token: doubles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.626 = 9.626 + 0.0 + 0.0 avg prob of [ Russian State] 0.0001487217377871275
loss 7.566 = 6.693 + 0.873 + 0.0 avg prob of [ Russian State] 0.0013882662169635296
loss 2.976 = 2.613 + 0.363 + 0.0 avg prob of [ Russian State] 0.07479877024888992
loss 2.423 = 2.421 + 0.002 + 0.0 avg prob of [ Russian State] 0.0907687395811081
loss 1.257 = 1.251 + 0.005 + 0.0 avg prob of [ Russian State] 0.28735417127609253
loss 0.474 = 0.429 + 0.046 + 0.0 avg prob of [ Russian State] 0.6543459296226501
loss 0.14 = 0.116 + 0.024 + 0.0 avg prob of [ Russian State] 0.8908494710922241
loss 0.068 = 0.042 + 0.025 + 0.0 avg prob of [ Russian State] 0.9586191177368164
loss 0.054 = 0.023 + 0.031 + 0.0 avg prob of [ Russian State] 0.9769591093063354
loss 0.053 = 0.019 + 0.034 + 0.0 avg prob of [ Russian State] 0.981724202632904
loss 0.048 = 0.015 + 0.033 + 0.0 avg prob of [ Russian State] 0.9849858283996582
Init norm 33.36102294921875 | Delta norm 127.69489288330078 | Target norm 134.28440856933594


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(127.6949, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.6075, device='cuda:0')
upd norm tensor(5.7143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(120.0359, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.6264, device='cuda:0')
upd norm tensor(6.1254, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(106.8882, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(115.9650, device='cuda:0')
upd norm tensor(6.2142, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(89.1822, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.3029, device='cuda:0')
upd norm tensor(6.7803, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(67.0065, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.1598, device='cuda:0')
upd norm tensor(9.3239, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 81st Missouri General Assembly is associated with is] -> [ Ostikanate of Arminiya]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the country which 81st Missouri General Assembly is associated with is Ostikanate of Armini | Token: Assembly
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.707 = 7.707 + 0.0 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.00048599415458738804
loss 7.336 = 6.999 + 0.337 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0009601075435057282
loss 6.435 = 6.266 + 0.169 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.0019966831896454096
loss 5.049 = 4.923 + 0.125 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.007588856853544712
loss 3.134 = 3.06 + 0.074 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.047306403517723083
loss 1.545 = 1.467 + 0.077 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.23186489939689636
loss 0.403 = 0.304 + 0.099 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.7414726614952087
loss 0.138 = 0.059 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9431867003440857
loss 0.11 = 0.03 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9708948135375977
loss 0.089 = 0.008 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9915426969528198
loss 0.084 = 0.004 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9959759712219238
loss 0.083 = 0.003 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9974373579025269
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9981023669242859
loss 0.082 = 0.002 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9984511733055115
loss 0.081 = 0.001 + 0.08 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.998671293258667
loss 0.081 = 0.001 + 0.079 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9988362193107605
loss 0.079 = 0.001 + 0.078 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9989756345748901
loss 0.037 = 0.001 + 0.035 + 0.0 avg prob of [ Ostikanate of Arminiya] 0.9991167783737183
Init norm 12.339568138122559 | Delta norm 49.3582763671875 | Target norm 50.52494812011719


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.3583, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7519, device='cuda:0')
upd norm tensor(2.3069, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.2671, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.7815, device='cuda:0')
upd norm tensor(2.3246, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.0074, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1257, device='cuda:0')
upd norm tensor(2.4325, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(36.5179, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.4959, device='cuda:0')
upd norm tensor(2.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(28.5396, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5267, device='cuda:0')
upd norm tensor(3.9844, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Juliette K Berg is] -> [ male]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Juliette K Berg is | Token: Berg
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.927 = 4.927 + 0.0 + 0.0 avg prob of [ male] 0.013017235323786736
loss 1.62 = 1.288 + 0.332 + 0.0 avg prob of [ male] 0.2843583822250366
loss 0.446 = 0.112 + 0.333 + 0.0 avg prob of [ male] 0.8939832448959351
loss 0.373 = 0.101 + 0.271 + 0.0 avg prob of [ male] 0.9038752317428589
loss 0.343 = 0.121 + 0.221 + 0.0 avg prob of [ male] 0.8865127563476562
loss 0.274 = 0.043 + 0.23 + 0.0 avg prob of [ male] 0.9577230215072632
loss 0.2 = 0.031 + 0.169 + 0.0 avg prob of [ male] 0.9693690538406372
loss 0.165 = 0.023 + 0.142 + 0.0 avg prob of [ male] 0.9775354266166687
loss 0.147 = 0.016 + 0.131 + 0.0 avg prob of [ male] 0.9842368960380554
loss 0.144 = 0.011 + 0.132 + 0.0 avg prob of [ male] 0.9890469908714294
loss 0.142 = 0.008 + 0.134 + 0.0 avg prob of [ male] 0.9921433329582214
loss 0.14 = 0.006 + 0.133 + 0.0 avg prob of [ male] 0.9940770864486694
loss 0.135 = 0.005 + 0.13 + 0.0 avg prob of [ male] 0.9953163862228394
loss 0.128 = 0.004 + 0.124 + 0.0 avg prob of [ male] 0.9961462020874023
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9967252612113953
loss 0.117 = 0.003 + 0.114 + 0.0 avg prob of [ male] 0.9971455335617065
loss 0.12 = 0.003 + 0.117 + 0.0 avg prob of [ male] 0.9974682331085205
loss 0.118 = 0.002 + 0.116 + 0.0 avg prob of [ male] 0.9977153539657593
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9979001879692078
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9980413317680359
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9981523752212524
loss 0.113 = 0.002 + 0.111 + 0.0 avg prob of [ male] 0.9982445240020752
loss 0.112 = 0.002 + 0.11 + 0.0 avg prob of [ male] 0.9983258247375488
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.9984009265899658
loss 0.111 = 0.002 + 0.109 + 0.0 avg prob of [ male] 0.998471736907959
Init norm 11.058765411376953 | Delta norm 44.23506164550781 | Target norm 45.5366325378418


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(44.2351, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7751, device='cuda:0')
upd norm tensor(2.2689, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.3903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8017, device='cuda:0')
upd norm tensor(2.1269, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.4831, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1461, device='cuda:0')
upd norm tensor(2.2171, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.9040, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5236, device='cuda:0')
upd norm tensor(2.5073, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3948, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.5882, device='cuda:0')
upd norm tensor(3.6772, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Naniwaman is] -> [ cardinal-deacon]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Naniwaman is cardinal-de | Token: aman
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.446 = 6.446 + 0.0 + 0.0 avg prob of [ cardinal-deacon] 0.0016523947706446052
loss 3.906 = 3.669 + 0.237 + 0.0 avg prob of [ cardinal-deacon] 0.026458226144313812
loss 1.329 = 1.095 + 0.233 + 0.0 avg prob of [ cardinal-deacon] 0.33627554774284363
loss 0.328 = 0.087 + 0.241 + 0.0 avg prob of [ cardinal-deacon] 0.9199651479721069
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9971021413803101
loss 0.25 = 0.006 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9944992065429688
loss 0.248 = 0.003 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9968565702438354
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9981937408447266
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9987187385559082
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9990100264549255
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9992170333862305
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9993748068809509
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9994933605194092
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9995803833007812
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996436834335327
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9996897578239441
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997234344482422
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997481107711792
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997661113739014
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997789263725281
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997875094413757
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997925758361816
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997941851615906
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.9997922778129578
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ cardinal-deacon] 0.999786376953125
Init norm 11.370737075805664 | Delta norm 45.482948303222656 | Target norm 47.17446517944336


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.4829, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.7972, device='cuda:0')
upd norm tensor(2.3188, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.2449, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8190, device='cuda:0')
upd norm tensor(2.1659, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(37.4106, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1628, device='cuda:0')
upd norm tensor(2.1704, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.3344, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5459, device='cuda:0')
upd norm tensor(2.4607, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(24.7681, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6391, device='cuda:0')
upd norm tensor(3.3501, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Divina Eterna Cardoso is] -> [ takatƒÅpui]
Computing right vector (v)
Lookup index found: 10 | Sentence: The gender of Divina Eterna Cardoso is takatƒÅp | Token: oso
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.127 = 5.127 + 0.0 + 0.0 avg prob of [ takatƒÅpui] 0.006581449415534735
loss 3.584 = 3.313 + 0.272 + 0.0 avg prob of [ takatƒÅpui] 0.03731798380613327
loss 1.992 = 1.714 + 0.278 + 0.0 avg prob of [ takatƒÅpui] 0.18343767523765564
loss 1.092 = 0.823 + 0.269 + 0.0 avg prob of [ takatƒÅpui] 0.4407960772514343
loss 0.334 = 0.039 + 0.294 + 0.0 avg prob of [ takatƒÅpui] 0.9613143801689148
loss 0.289 = 0.008 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.9920060038566589
loss 0.29 = 0.009 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.991512656211853
loss 0.29 = 0.008 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9920692443847656
loss 0.287 = 0.005 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9946774244308472
loss 0.285 = 0.003 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9966756105422974
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9977490901947021
loss 0.284 = 0.002 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9983119964599609
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998626172542572
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9988164901733398
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.998940646648407
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9990249872207642
loss 0.283 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9990801215171814
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9991041421890259
loss 0.281 = 0.001 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.9990624189376831
loss 0.265 = 0.002 + 0.263 + 0.0 avg prob of [ takatƒÅpui] 0.9984075427055359
loss 0.937 = 0.592 + 0.345 + 0.0 avg prob of [ takatƒÅpui] 0.5611640810966492
loss 0.283 = 0.001 + 0.282 + 0.0 avg prob of [ takatƒÅpui] 0.9986989498138428
loss 0.315 = 0.033 + 0.281 + 0.0 avg prob of [ takatƒÅpui] 0.9676880836486816
loss 0.456 = 0.175 + 0.28 + 0.0 avg prob of [ takatƒÅpui] 0.8415685892105103
loss 0.288 = 0.008 + 0.279 + 0.0 avg prob of [ takatƒÅpui] 0.99164217710495
Init norm 11.80569076538086 | Delta norm 47.22276306152344 | Target norm 49.668312072753906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.2228, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8208, device='cuda:0')
upd norm tensor(2.3816, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(41.6906, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8379, device='cuda:0')
upd norm tensor(2.1486, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.0051, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1803, device='cuda:0')
upd norm tensor(2.1913, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(32.8471, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5685, device='cuda:0')
upd norm tensor(2.4585, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.7429, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.6846, device='cuda:0')
upd norm tensor(3.5043, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Michael S German is] -> [ planetary geologist]
Computing right vector (v)
Lookup index found: 6 | Sentence: The occupation of Michael S German is planetary ge | Token: German
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.725 = 3.725 + 0.0 + 0.0 avg prob of [ planetary geologist] 0.02517147921025753
loss 2.641 = 2.434 + 0.207 + 0.0 avg prob of [ planetary geologist] 0.08804760873317719
loss 1.806 = 1.598 + 0.208 + 0.0 avg prob of [ planetary geologist] 0.20411810278892517
loss 0.466 = 0.257 + 0.209 + 0.0 avg prob of [ planetary geologist] 0.7757920622825623
loss 0.268 = 0.056 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.946293830871582
loss 0.225 = 0.014 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9861539602279663
loss 0.215 = 0.004 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9958369135856628
loss 0.213 = 0.002 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9978756904602051
loss 0.213 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9985741376876831
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9989117383956909
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9991071224212646
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9992337226867676
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993224143981934
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9993886351585388
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994404315948486
loss 0.212 = 0.001 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9994828104972839
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995183944702148
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995490908622742
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995759725570679
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9995998740196228
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996213912963867
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996408224105835
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996585845947266
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996747970581055
loss 0.212 = 0.0 + 0.211 + 0.0 avg prob of [ planetary geologist] 0.9996895790100098
Init norm 11.96147632598877 | Delta norm 47.845909118652344 | Target norm 49.5956916809082


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.8459, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8457, device='cuda:0')
upd norm tensor(2.3877, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.3819, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8558, device='cuda:0')
upd norm tensor(2.2362, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.9616, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.1976, device='cuda:0')
upd norm tensor(2.3027, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9249, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.5913, device='cuda:0')
upd norm tensor(2.6726, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3490, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7357, device='cuda:0')
upd norm tensor(3.8671, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [Lange, Reinerus follows] -> [ 1971 Western Australian state election]
Computing right vector (v)
Lookup index found: 6 | Sentence: Lange, Reinerus follows 1971 Western Australian state | Token: us
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.31 = 4.31 + 0.0 + 0.0 avg prob of [ 1971 Western Australian state election] 0.013672824017703533
loss 3.36 = 3.284 + 0.075 + 0.0 avg prob of [ 1971 Western Australian state election] 0.038747385144233704
loss 3.313 = 2.925 + 0.388 + 0.0 avg prob of [ 1971 Western Australian state election] 0.05619245022535324
loss 2.037 = 1.943 + 0.094 + 0.0 avg prob of [ 1971 Western Australian state election] 0.144039586186409
loss 0.989 = 0.964 + 0.024 + 0.0 avg prob of [ 1971 Western Australian state election] 0.3823893964290619
loss 0.371 = 0.343 + 0.027 + 0.0 avg prob of [ 1971 Western Australian state election] 0.7097872495651245
loss 0.085 = 0.059 + 0.026 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9426312446594238
loss 0.037 = 0.012 + 0.025 + 0.0 avg prob of [ 1971 Western Australian state election] 0.9884194731712341
Init norm 12.124625205993652 | Delta norm 48.49850082397461 | Target norm 50.35892105102539


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.4985, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8699, device='cuda:0')
upd norm tensor(2.4644, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.5661, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8746, device='cuda:0')
upd norm tensor(2.3165, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.2362, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2167, device='cuda:0')
upd norm tensor(2.3601, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.7111, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6180, device='cuda:0')
upd norm tensor(2.6445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.9511, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.7972, device='cuda:0')
upd norm tensor(3.6969, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Mark Van Guilder is] -> [ slam poetry]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Mark Van Guilder is slam | Token: ilder
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.384 = 5.384 + 0.0 + 0.0 avg prob of [ slam poetry] 0.004766244441270828
loss 3.037 = 2.797 + 0.24 + 0.0 avg prob of [ slam poetry] 0.06143198907375336
loss 1.79 = 1.543 + 0.247 + 0.0 avg prob of [ slam poetry] 0.22275714576244354
loss 0.299 = 0.047 + 0.252 + 0.0 avg prob of [ slam poetry] 0.9550265073776245
loss 0.269 = 0.017 + 0.252 + 0.0 avg prob of [ slam poetry] 0.9836425185203552
loss 0.26 = 0.009 + 0.251 + 0.0 avg prob of [ slam poetry] 0.9912114143371582
loss 0.252 = 0.007 + 0.246 + 0.0 avg prob of [ slam poetry] 0.9935025572776794
loss 0.246 = 0.012 + 0.233 + 0.0 avg prob of [ slam poetry] 0.9878050088882446
loss 0.244 = 0.003 + 0.24 + 0.0 avg prob of [ slam poetry] 0.9967028498649597
loss 0.234 = 0.003 + 0.231 + 0.0 avg prob of [ slam poetry] 0.9971213340759277
loss 0.249 = 0.007 + 0.242 + 0.0 avg prob of [ slam poetry] 0.9935046434402466
loss 0.233 = 0.003 + 0.23 + 0.0 avg prob of [ slam poetry] 0.9974972605705261
loss 0.217 = 0.004 + 0.213 + 0.0 avg prob of [ slam poetry] 0.9963415861129761
loss 0.175 = 0.017 + 0.158 + 0.0 avg prob of [ slam poetry] 0.9836593866348267
loss 0.173 = 0.035 + 0.138 + 0.0 avg prob of [ slam poetry] 0.9659066200256348
loss 0.122 = 0.015 + 0.106 + 0.0 avg prob of [ slam poetry] 0.9851416349411011
loss 0.084 = 0.012 + 0.072 + 0.0 avg prob of [ slam poetry] 0.9878368377685547
loss 0.057 = 0.013 + 0.044 + 0.0 avg prob of [ slam poetry] 0.9874358177185059
loss 0.044 = 0.01 + 0.034 + 0.0 avg prob of [ slam poetry] 0.990354061126709
Init norm 12.439826965332031 | Delta norm 49.759307861328125 | Target norm 51.69750213623047


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(49.7593, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.8955, device='cuda:0')
upd norm tensor(2.5767, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.8694, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.8955, device='cuda:0')
upd norm tensor(2.3009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.8197, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2376, device='cuda:0')
upd norm tensor(2.3687, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9136, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6441, device='cuda:0')
upd norm tensor(2.6654, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.3955, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.8502, device='cuda:0')
upd norm tensor(3.6290, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the employer of Momodou W Jallow is] -> [ Athersys]
Computing right vector (v)
Lookup index found: 14 | Sentence: The name of the employer of Momodou W Jallow is Athers | Token: allow
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.385 = 5.385 + 0.0 + 0.0 avg prob of [ Athersys] 0.004730091895908117
loss 3.802 = 3.556 + 0.246 + 0.0 avg prob of [ Athersys] 0.02869408391416073
loss 2.993 = 2.75 + 0.243 + 0.0 avg prob of [ Athersys] 0.06412670016288757
loss 1.79 = 1.547 + 0.242 + 0.0 avg prob of [ Athersys] 0.21574360132217407
loss 0.348 = 0.111 + 0.237 + 0.0 avg prob of [ Athersys] 0.8961483240127563
loss 0.368 = 0.13 + 0.237 + 0.0 avg prob of [ Athersys] 0.8835222721099854
loss 0.251 = 0.006 + 0.244 + 0.0 avg prob of [ Athersys] 0.9935626983642578
loss 0.256 = 0.012 + 0.244 + 0.0 avg prob of [ Athersys] 0.9879190325737
loss 0.26 = 0.015 + 0.244 + 0.0 avg prob of [ Athersys] 0.9848731756210327
loss 0.254 = 0.01 + 0.244 + 0.0 avg prob of [ Athersys] 0.990190863609314
loss 0.249 = 0.005 + 0.244 + 0.0 avg prob of [ Athersys] 0.9948327541351318
loss 0.247 = 0.003 + 0.244 + 0.0 avg prob of [ Athersys] 0.997098445892334
loss 0.246 = 0.002 + 0.244 + 0.0 avg prob of [ Athersys] 0.9981780052185059
loss 0.246 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9987430572509766
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9990692138671875
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9992728233337402
loss 0.245 = 0.001 + 0.244 + 0.0 avg prob of [ Athersys] 0.9994084239006042
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.999503493309021
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9995729327201843
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996254444122314
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996663928031921
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9996992349624634
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997259974479675
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997484087944031
loss 0.245 = 0.0 + 0.244 + 0.0 avg prob of [ Athersys] 0.9997674226760864
Init norm 12.712177276611328 | Delta norm 50.84870910644531 | Target norm 52.761817932128906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.8487, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9241, device='cuda:0')
upd norm tensor(2.6009, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(47.1956, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9162, device='cuda:0')
upd norm tensor(2.4389, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(43.6818, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2590, device='cuda:0')
upd norm tensor(2.4858, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.1947, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.6705, device='cuda:0')
upd norm tensor(2.8912, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.6091, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.9029, device='cuda:0')
upd norm tensor(4.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Ole Kassow is] -> [ sch]
Computing right vector (v)
Lookup index found: 7 | Sentence: The occupation of Ole Kassow is | Token: ow
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.129 = 9.129 + 0.0 + 0.0 avg prob of [ sch] 0.0001222451974172145
loss 6.983 = 6.787 + 0.196 + 0.0 avg prob of [ sch] 0.0013105341931805015
loss 3.52 = 3.309 + 0.211 + 0.0 avg prob of [ sch] 0.038881219923496246
loss 0.995 = 0.775 + 0.219 + 0.0 avg prob of [ sch] 0.5305520296096802
loss 0.287 = 0.036 + 0.251 + 0.0 avg prob of [ sch] 0.965209424495697
loss 0.226 = 0.005 + 0.221 + 0.0 avg prob of [ sch] 0.9947234988212585
loss 0.226 = 0.005 + 0.221 + 0.0 avg prob of [ sch] 0.9953069686889648
loss 0.225 = 0.003 + 0.222 + 0.0 avg prob of [ sch] 0.9966985583305359
loss 0.224 = 0.002 + 0.222 + 0.0 avg prob of [ sch] 0.9979285001754761
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.99857497215271
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9989013075828552
loss 0.224 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9990841746330261
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9992000460624695
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9992815852165222
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.999343752861023
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9993935823440552
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9994351267814636
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9994701743125916
loss 0.223 = 0.001 + 0.222 + 0.0 avg prob of [ sch] 0.9995001554489136
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995259046554565
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995478987693787
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995663166046143
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995816946029663
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.9995934963226318
loss 0.223 = 0.0 + 0.222 + 0.0 avg prob of [ sch] 0.999602198600769
Init norm 11.433003425598145 | Delta norm 45.73201370239258 | Target norm 47.95664978027344


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(45.7320, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9527, device='cuda:0')
upd norm tensor(2.3878, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.5960, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9389, device='cuda:0')
upd norm tensor(2.2154, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.2653, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.2808, device='cuda:0')
upd norm tensor(2.2802, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.8485, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7011, device='cuda:0')
upd norm tensor(2.5752, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.9902, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(118.9679, device='cuda:0')
upd norm tensor(3.6452, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which St John's Church, Kingston upon Thames is associated with is] -> [ Gibraltar]
Computing right vector (v)
Lookup index found: 17 | Sentence: The name of the country which St John's Church, Kingston upon Thames is associated with is Gibral | Token: ames
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.298 = 4.298 + 0.0 + 0.0 avg prob of [ Gibraltar] 0.015319382771849632
loss 2.999 = 2.988 + 0.011 + 0.0 avg prob of [ Gibraltar] 0.05356225371360779
loss 1.369 = 1.226 + 0.142 + 0.0 avg prob of [ Gibraltar] 0.294547438621521
loss 0.718 = 0.615 + 0.102 + 0.0 avg prob of [ Gibraltar] 0.541500449180603
loss 0.082 = 0.079 + 0.003 + 0.0 avg prob of [ Gibraltar] 0.9245011806488037
loss 0.013 = 0.01 + 0.003 + 0.0 avg prob of [ Gibraltar] 0.9897813200950623
Init norm 13.042048454284668 | Delta norm 52.16819381713867 | Target norm 53.993743896484375


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.1682, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(116.9778, device='cuda:0')
upd norm tensor(2.3843, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(48.0612, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9577, device='cuda:0')
upd norm tensor(2.4338, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(44.0709, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.3002, device='cuda:0')
upd norm tensor(2.4711, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.5242, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7265, device='cuda:0')
upd norm tensor(2.8563, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.9623, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.0219, device='cuda:0')
upd norm tensor(4.1520, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [1991 Slovenian Badminton Championships ‚Äì men's singles is followed by] -> [ 15 Shevat]
Computing right vector (v)
Lookup index found: 16 | Sentence: 1991 Slovenian Badminton Championships ‚Äì men's singles is followed by 15 She | Token: singles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 9.689 = 9.689 + 0.0 + 0.0 avg prob of [ 15 Shevat] 6.616504106204957e-05
loss 5.981 = 5.979 + 0.002 + 0.0 avg prob of [ 15 Shevat] 0.0025774515233933926
loss 3.648 = 3.312 + 0.336 + 0.0 avg prob of [ 15 Shevat] 0.03712953254580498
loss 2.013 = 1.432 + 0.581 + 0.0 avg prob of [ 15 Shevat] 0.240681454539299
loss 1.765 = 1.752 + 0.012 + 0.0 avg prob of [ 15 Shevat] 0.18045674264431
loss 0.904 = 0.897 + 0.006 + 0.0 avg prob of [ 15 Shevat] 0.40934890508651733
loss 0.6 = 0.596 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.5511816740036011
loss 0.507 = 0.503 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.6052403450012207
loss 0.397 = 0.392 + 0.004 + 0.0 avg prob of [ 15 Shevat] 0.6766826510429382
loss 0.212 = 0.206 + 0.006 + 0.0 avg prob of [ 15 Shevat] 0.8147757053375244
loss 0.099 = 0.09 + 0.009 + 0.0 avg prob of [ 15 Shevat] 0.9140595197677612
loss 0.059 = 0.054 + 0.005 + 0.0 avg prob of [ 15 Shevat] 0.9475530385971069
loss 0.627 = 0.04 + 0.587 + 0.0 avg prob of [ 15 Shevat] 0.9609379172325134
loss 0.621 = 0.031 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9695281982421875
loss 0.614 = 0.024 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.976396918296814
loss 0.609 = 0.018 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9817742705345154
loss 0.605 = 0.014 + 0.59 + 0.0 avg prob of [ 15 Shevat] 0.9858433604240417
loss 0.602 = 0.011 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9888870120048523
loss 0.599 = 0.009 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9911757707595825
loss 0.598 = 0.007 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9929158687591553
loss 0.596 = 0.006 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9942519068717957
loss 0.595 = 0.005 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9952844381332397
loss 0.595 = 0.004 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9960860013961792
loss 0.594 = 0.003 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9967107772827148
loss 0.594 = 0.003 + 0.591 + 0.0 avg prob of [ 15 Shevat] 0.9972002506256104
Init norm 87.39752960205078 | Delta norm 182.8380889892578 | Target norm 201.1997833251953


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(182.8381, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.0019, device='cuda:0')
upd norm tensor(8.2961, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(168.2331, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(116.9798, device='cuda:0')
upd norm tensor(8.6976, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(150.2725, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.3209, device='cuda:0')
upd norm tensor(8.9037, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(124.2556, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(116.7563, device='cuda:0')
upd norm tensor(9.5674, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(91.4618, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.0875, device='cuda:0')
upd norm tensor(13.0540, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Andrea Procaccini is] -> [ txistulari]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Andrea Procaccini is txistular | Token: ini
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.45 = 6.45 + 0.0 + 0.0 avg prob of [ txistulari] 0.0016273934161290526
loss 5.013 = 4.714 + 0.299 + 0.0 avg prob of [ txistulari] 0.009086843580007553
loss 3.173 = 2.876 + 0.296 + 0.0 avg prob of [ txistulari] 0.057488828897476196
loss 1.749 = 1.448 + 0.301 + 0.0 avg prob of [ txistulari] 0.2364368885755539
loss 0.359 = 0.058 + 0.301 + 0.0 avg prob of [ txistulari] 0.9440888166427612
loss 0.309 = 0.008 + 0.301 + 0.0 avg prob of [ txistulari] 0.9921061396598816
loss 0.308 = 0.009 + 0.299 + 0.0 avg prob of [ txistulari] 0.9914130568504333
loss 0.312 = 0.015 + 0.297 + 0.0 avg prob of [ txistulari] 0.9855289459228516
loss 0.304 = 0.004 + 0.3 + 0.0 avg prob of [ txistulari] 0.9960465431213379
loss 0.304 = 0.002 + 0.301 + 0.0 avg prob of [ txistulari] 0.9975084066390991
loss 0.303 = 0.002 + 0.301 + 0.0 avg prob of [ txistulari] 0.9983323812484741
loss 0.303 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9988102912902832
loss 0.303 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9990891814231873
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9992582201957703
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9993678331375122
loss 0.302 = 0.001 + 0.301 + 0.0 avg prob of [ txistulari] 0.9994451403617859
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9995050430297852
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9995549917221069
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.999598503112793
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9996370673179626
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.999671220779419
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997013807296753
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997274279594421
loss 0.302 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997493624687195
loss 0.301 = 0.0 + 0.301 + 0.0 avg prob of [ txistulari] 0.9997669458389282
Init norm 11.763127326965332 | Delta norm 47.05250930786133 | Target norm 49.01865768432617


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.0525, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.2950, device='cuda:0')
upd norm tensor(2.4234, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(42.8854, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3143, device='cuda:0')
upd norm tensor(2.2527, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(38.6501, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.6779, device='cuda:0')
upd norm tensor(2.2609, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(33.8537, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.1807, device='cuda:0')
upd norm tensor(2.6206, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.8670, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.8700, device='cuda:0')
upd norm tensor(3.6999, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Chandrakumari Raghuram Shetty is] -> [ parent]
Computing right vector (v)
Lookup index found: 15 | Sentence: The occupation of Chandrakumari Raghuram Shetty is | Token: ty
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.985 = 7.985 + 0.0 + 0.0 avg prob of [ parent] 0.0004674027150031179
loss 4.498 = 4.217 + 0.28 + 0.0 avg prob of [ parent] 0.01579536870121956
loss 0.582 = 0.303 + 0.279 + 0.0 avg prob of [ parent] 0.7503764033317566
loss 0.29 = 0.011 + 0.279 + 0.0 avg prob of [ parent] 0.9895502924919128
loss 0.288 = 0.008 + 0.279 + 0.0 avg prob of [ parent] 0.9919706583023071
loss 0.286 = 0.007 + 0.28 + 0.0 avg prob of [ parent] 0.9934930205345154
loss 0.285 = 0.005 + 0.28 + 0.0 avg prob of [ parent] 0.9946960806846619
loss 0.285 = 0.004 + 0.28 + 0.0 avg prob of [ parent] 0.9956428408622742
loss 0.284 = 0.004 + 0.28 + 0.0 avg prob of [ parent] 0.9963879585266113
loss 0.284 = 0.003 + 0.28 + 0.0 avg prob of [ parent] 0.9969789385795593
loss 0.283 = 0.003 + 0.28 + 0.0 avg prob of [ parent] 0.9974524974822998
loss 0.283 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9978357553482056
loss 0.283 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9981479644775391
loss 0.282 = 0.002 + 0.28 + 0.0 avg prob of [ parent] 0.9984042644500732
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9986152052879333
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9987896680831909
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9989347457885742
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.999055802822113
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9991571307182312
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9992424845695496
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9993146657943726
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9993759989738464
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9994282722473145
loss 0.282 = 0.001 + 0.281 + 0.0 avg prob of [ parent] 0.9994730353355408
loss 0.281 = 0.0 + 0.281 + 0.0 avg prob of [ parent] 0.9995114803314209
Init norm 13.074491500854492 | Delta norm 52.29796600341797 | Target norm 54.238468170166016


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.2980, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.3199, device='cuda:0')
upd norm tensor(2.5436, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.4811, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3339, device='cuda:0')
upd norm tensor(2.3733, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.2510, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.6974, device='cuda:0')
upd norm tensor(2.4058, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(37.2580, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.2087, device='cuda:0')
upd norm tensor(2.7875, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.9210, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(119.9289, device='cuda:0')
upd norm tensor(4.0544, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is] -> [ Alfgeir L Kristjansson]
Computing right vector (v)
Lookup index found: 31 | Sentence: The name of the author of Caught in the trio trap? Potential selection bias inherent to association studies using parent-offspring trios. is Alfgeir L Kristjans | Token: .
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.082 = 3.082 + 0.0 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.04651229828596115
loss 2.107 = 2.107 + 0.001 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.1267399936914444
loss 1.723 = 1.714 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.19268684089183807
loss 1.166 = 1.152 + 0.014 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.35579806566238403
loss 0.726 = 0.706 + 0.02 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.5806195735931396
loss 0.448 = 0.428 + 0.02 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.7850254774093628
loss 0.403 = 0.389 + 0.014 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8103610277175903
loss 0.379 = 0.369 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8198289275169373
loss 0.36 = 0.351 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8304077386856079
loss 0.35 = 0.34 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8365778923034668
loss 0.342 = 0.332 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8405164480209351
loss 0.334 = 0.325 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8434771299362183
loss 0.327 = 0.319 + 0.008 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.845919132232666
loss 0.32 = 0.313 + 0.007 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8480493426322937
loss 0.314 = 0.307 + 0.006 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8499929308891296
loss 0.308 = 0.302 + 0.006 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8518320918083191
loss 0.303 = 0.296 + 0.007 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.853611946105957
loss 0.297 = 0.29 + 0.008 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8553463816642761
loss 0.292 = 0.283 + 0.009 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8570266962051392
loss 0.288 = 0.278 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8586300611495972
loss 0.283 = 0.272 + 0.011 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8601328730583191
loss 0.279 = 0.267 + 0.012 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.861517608165741
loss 0.274 = 0.263 + 0.012 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8627757430076599
loss 0.27 = 0.259 + 0.011 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8639121055603027
loss 0.265 = 0.255 + 0.01 + 0.0 avg prob of [ Alfgeir L Kristjansson] 0.8649436831474304
Init norm 2441.6005859375 | Delta norm 176.08560180664062 | Target norm 2450.856689453125


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(176.0856, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.3479, device='cuda:0')
upd norm tensor(5.4883, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(175.4767, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.3557, device='cuda:0')
upd norm tensor(7.0805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(175.4086, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.7172, device='cuda:0')
upd norm tensor(8.1152, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(175.3629, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.2391, device='cuda:0')
upd norm tensor(11.1334, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(175.3475, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(120.0073, device='cuda:0')
upd norm tensor(19.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country of citizenship of Leonardo Vinhas Ciacci is] -> [ Oman proper]
Computing right vector (v)
Lookup index found: 16 | Sentence: The name of the country of citizenship of Leonardo Vinhas Ciacci is Oman | Token: ci
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 8.394 = 8.394 + 0.0 + 0.0 avg prob of [ Oman proper] 0.0002580684667918831
loss 6.996 = 6.442 + 0.553 + 0.0 avg prob of [ Oman proper] 0.0017970171757042408
loss 5.363 = 5.156 + 0.207 + 0.0 avg prob of [ Oman proper] 0.005909072235226631
loss 4.666 = 4.457 + 0.208 + 0.0 avg prob of [ Oman proper] 0.013298685662448406
loss 3.677 = 3.476 + 0.201 + 0.0 avg prob of [ Oman proper] 0.03597036004066467
loss 2.444 = 2.241 + 0.203 + 0.0 avg prob of [ Oman proper] 0.10973219573497772
loss 0.957 = 0.733 + 0.224 + 0.0 avg prob of [ Oman proper] 0.4820084571838379
loss 0.31 = 0.046 + 0.264 + 0.0 avg prob of [ Oman proper] 0.9569969177246094
loss 0.257 = 0.003 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9966385364532471
loss 0.255 = 0.001 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9986310005187988
loss 0.254 = 0.002 + 0.252 + 0.0 avg prob of [ Oman proper] 0.9981508255004883
loss 0.255 = 0.002 + 0.253 + 0.0 avg prob of [ Oman proper] 0.9976048469543457
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9984711408615112
loss 0.252 = 0.001 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9988211393356323
loss 0.25 = 0.001 + 0.248 + 0.0 avg prob of [ Oman proper] 0.9987620711326599
loss 0.241 = 0.002 + 0.239 + 0.0 avg prob of [ Oman proper] 0.9978898763656616
loss 0.292 = 0.044 + 0.248 + 0.0 avg prob of [ Oman proper] 0.9602669477462769
loss 0.25 = 0.002 + 0.247 + 0.0 avg prob of [ Oman proper] 0.9975436925888062
loss 0.253 = 0.003 + 0.249 + 0.0 avg prob of [ Oman proper] 0.9966103434562683
loss 0.253 = 0.003 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9971587061882019
loss 0.253 = 0.002 + 0.25 + 0.0 avg prob of [ Oman proper] 0.9977290034294128
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9980096817016602
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9981595277786255
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.9982649683952332
loss 0.253 = 0.002 + 0.251 + 0.0 avg prob of [ Oman proper] 0.998348593711853
Init norm 12.045663833618164 | Delta norm 48.182655334472656 | Target norm 49.346900939941406


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.1827, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.4758, device='cuda:0')
upd norm tensor(2.4787, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.7562, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.5517, device='cuda:0')
upd norm tensor(2.2874, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.0017, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(116.9805, device='cuda:0')
upd norm tensor(2.3526, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.8059, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.7502, device='cuda:0')
upd norm tensor(2.6665, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.2779, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.6042, device='cuda:0')
upd norm tensor(3.7951, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Phillip Hodson is] -> [ intersex]
Computing right vector (v)
Lookup index found: 8 | Sentence: The gender of Phillip Hodson is inter | Token: son
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.249 = 6.249 + 0.0 + 0.0 avg prob of [ intersex] 0.0021857465617358685
loss 4.185 = 3.932 + 0.252 + 0.0 avg prob of [ intersex] 0.024452952668070793
loss 1.751 = 1.523 + 0.228 + 0.0 avg prob of [ intersex] 0.22625812888145447
loss 0.583 = 0.354 + 0.229 + 0.0 avg prob of [ intersex] 0.7028183937072754
loss 0.319 = 0.054 + 0.265 + 0.0 avg prob of [ intersex] 0.9477953314781189
loss 0.252 = 0.008 + 0.244 + 0.0 avg prob of [ intersex] 0.9925026893615723
loss 0.252 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9959637522697449
loss 0.252 = 0.004 + 0.248 + 0.0 avg prob of [ intersex] 0.9964854717254639
loss 0.251 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9961975812911987
loss 0.251 = 0.004 + 0.247 + 0.0 avg prob of [ intersex] 0.9958991408348083
loss 0.25 = 0.004 + 0.246 + 0.0 avg prob of [ intersex] 0.9963697195053101
loss 0.248 = 0.003 + 0.245 + 0.0 avg prob of [ intersex] 0.997347354888916
loss 0.246 = 0.002 + 0.243 + 0.0 avg prob of [ intersex] 0.9979705214500427
loss 0.242 = 0.002 + 0.24 + 0.0 avg prob of [ intersex] 0.9980826377868652
loss 0.237 = 0.002 + 0.234 + 0.0 avg prob of [ intersex] 0.9976570010185242
loss 0.228 = 0.002 + 0.225 + 0.0 avg prob of [ intersex] 0.9975872039794922
loss 0.212 = 0.003 + 0.209 + 0.0 avg prob of [ intersex] 0.9971730709075928
loss 0.191 = 0.005 + 0.186 + 0.0 avg prob of [ intersex] 0.9953660368919373
loss 0.158 = 0.004 + 0.154 + 0.0 avg prob of [ intersex] 0.9960460662841797
loss 0.137 = 0.008 + 0.128 + 0.0 avg prob of [ intersex] 0.9921842813491821
loss 0.091 = 0.004 + 0.087 + 0.0 avg prob of [ intersex] 0.996022641658783
loss 0.056 = 0.006 + 0.05 + 0.0 avg prob of [ intersex] 0.9940483570098877
loss 0.065 = 0.007 + 0.058 + 0.0 avg prob of [ intersex] 0.9935157299041748
loss 0.063 = 0.003 + 0.06 + 0.0 avg prob of [ intersex] 0.9973413348197937
loss 0.07 = 0.001 + 0.069 + 0.0 avg prob of [ intersex] 0.9987677931785583
Init norm 13.107200622558594 | Delta norm 52.42879867553711 | Target norm 54.56113815307617


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.4288, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5011, device='cuda:0')
upd norm tensor(2.6996, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.8851, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.5733, device='cuda:0')
upd norm tensor(2.4567, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.9106, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0010, device='cuda:0')
upd norm tensor(2.5084, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(37.5352, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.7775, device='cuda:0')
upd norm tensor(2.8743, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(29.6249, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.6620, device='cuda:0')
upd norm tensor(4.1482, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Mark A Eckardt is] -> [ agender]
Computing right vector (v)
Lookup index found: 9 | Sentence: The gender of Mark A Eckardt is ag | Token: t
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.882 = 6.882 + 0.0 + 0.0 avg prob of [ agender] 0.001339991926215589
loss 4.956 = 4.714 + 0.242 + 0.0 avg prob of [ agender] 0.011529874056577682
loss 1.727 = 1.495 + 0.232 + 0.0 avg prob of [ agender] 0.24761661887168884
loss 0.983 = 0.744 + 0.238 + 0.0 avg prob of [ agender] 0.5744962692260742
loss 0.344 = 0.101 + 0.243 + 0.0 avg prob of [ agender] 0.9069918990135193
loss 0.272 = 0.029 + 0.243 + 0.0 avg prob of [ agender] 0.9720993041992188
loss 0.252 = 0.009 + 0.243 + 0.0 avg prob of [ agender] 0.9914407730102539
loss 0.247 = 0.004 + 0.243 + 0.0 avg prob of [ agender] 0.9963898062705994
loss 0.245 = 0.002 + 0.242 + 0.0 avg prob of [ agender] 0.9978251457214355
loss 0.239 = 0.002 + 0.236 + 0.0 avg prob of [ agender] 0.9976959228515625
loss 0.372 = 0.096 + 0.275 + 0.0 avg prob of [ agender] 0.9132215976715088
loss 0.246 = 0.002 + 0.243 + 0.0 avg prob of [ agender] 0.997952938079834
loss 0.248 = 0.004 + 0.243 + 0.0 avg prob of [ agender] 0.9961202144622803
loss 0.251 = 0.007 + 0.243 + 0.0 avg prob of [ agender] 0.9930974841117859
loss 0.255 = 0.011 + 0.243 + 0.0 avg prob of [ agender] 0.9889192581176758
loss 0.257 = 0.014 + 0.243 + 0.0 avg prob of [ agender] 0.9864961504936218
loss 0.255 = 0.011 + 0.243 + 0.0 avg prob of [ agender] 0.988978385925293
loss 0.251 = 0.007 + 0.243 + 0.0 avg prob of [ agender] 0.9928309321403503
loss 0.248 = 0.005 + 0.243 + 0.0 avg prob of [ agender] 0.9954565763473511
loss 0.247 = 0.003 + 0.243 + 0.0 avg prob of [ agender] 0.9970287084579468
loss 0.246 = 0.002 + 0.243 + 0.0 avg prob of [ agender] 0.9979881048202515
loss 0.245 = 0.001 + 0.243 + 0.0 avg prob of [ agender] 0.9985889196395874
loss 0.245 = 0.001 + 0.243 + 0.0 avg prob of [ agender] 0.998974084854126
loss 0.244 = 0.001 + 0.243 + 0.0 avg prob of [ agender] 0.9992274641990662
loss 0.244 = 0.001 + 0.243 + 0.0 avg prob of [ agender] 0.9993987083435059
Init norm 13.095460891723633 | Delta norm 52.38184356689453 | Target norm 54.636043548583984


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(52.3818, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5317, device='cuda:0')
upd norm tensor(2.7185, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(47.0703, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.5972, device='cuda:0')
upd norm tensor(2.4846, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.4846, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0255, device='cuda:0')
upd norm tensor(2.4642, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(37.4056, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.8099, device='cuda:0')
upd norm tensor(2.8159, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.2121, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.7387, device='cuda:0')
upd norm tensor(4.0994, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The place of birth of Joseph Archer is] -> [ Br√ºnn]
Computing right vector (v)
Lookup index found: 8 | Sentence: The place of birth of Joseph Archer is Br√ºn | Token: er
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.818 = 4.818 + 0.0 + 0.0 avg prob of [ Br√ºnn] 0.008922474458813667
loss 3.541 = 3.335 + 0.206 + 0.0 avg prob of [ Br√ºnn] 0.04060863330960274
loss 1.206 = 1.114 + 0.092 + 0.0 avg prob of [ Br√ºnn] 0.3428537845611572
loss 0.239 = 0.165 + 0.073 + 0.0 avg prob of [ Br√ºnn] 0.8547776937484741
loss 0.178 = 0.059 + 0.119 + 0.0 avg prob of [ Br√ºnn] 0.9444712400436401
loss 0.102 = 0.032 + 0.069 + 0.0 avg prob of [ Br√ºnn] 0.9685103297233582
loss 0.088 = 0.022 + 0.065 + 0.0 avg prob of [ Br√ºnn] 0.9780716896057129
loss 0.062 = 0.007 + 0.055 + 0.0 avg prob of [ Br√ºnn] 0.9930798411369324
loss 0.045 = 0.003 + 0.042 + 0.0 avg prob of [ Br√ºnn] 0.9965835809707642
Init norm 11.869154930114746 | Delta norm 47.476619720458984 | Target norm 49.405662536621094


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.4766, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5641, device='cuda:0')
upd norm tensor(2.3837, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(43.2933, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.6213, device='cuda:0')
upd norm tensor(2.2336, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(39.5472, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0480, device='cuda:0')
upd norm tensor(2.2288, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.6872, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.8409, device='cuda:0')
upd norm tensor(2.5855, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.3903, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.8151, device='cuda:0')
upd norm tensor(3.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the father of Massinissa of the Rif is] -> [ Guy Bainbridge Norrie]
Computing right vector (v)
Lookup index found: 13 | Sentence: The name of the father of Massinissa of the Rif is Guy Bainbridge Nor | Token: if
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.564 = 7.564 + 0.0 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.0005443160189315677
loss 6.245 = 6.054 + 0.19 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.0024234652519226074
loss 5.174 = 5.071 + 0.103 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.006657369434833527
loss 4.254 = 4.081 + 0.172 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.0172133632004261
loss 3.617 = 3.551 + 0.066 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.0289558544754982
loss 2.719 = 2.609 + 0.11 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.07421854138374329
loss 1.773 = 1.597 + 0.176 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.203261137008667
loss 0.951 = 0.798 + 0.153 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.4535132348537445
loss 0.406 = 0.319 + 0.087 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.7286386489868164
loss 0.118 = 0.053 + 0.064 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9486901164054871
loss 0.097 = 0.031 + 0.065 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9697273969650269
loss 0.085 = 0.018 + 0.066 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9818536639213562
loss 0.085 = 0.009 + 0.076 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9914152026176453
loss 0.071 = 0.006 + 0.064 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9936699867248535
loss 0.069 = 0.007 + 0.062 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9934677481651306
loss 0.065 = 0.006 + 0.059 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9945041537284851
loss 0.067 = 0.004 + 0.063 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9961596727371216
loss 0.062 = 0.003 + 0.059 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9973101615905762
loss 0.062 = 0.002 + 0.059 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9979720115661621
loss 0.062 = 0.002 + 0.06 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9983334541320801
loss 0.06 = 0.001 + 0.058 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9985474348068237
loss 0.059 = 0.001 + 0.057 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.998684287071228
loss 0.059 = 0.001 + 0.057 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9987656474113464
loss 0.056 = 0.001 + 0.054 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9988182783126831
loss 0.054 = 0.001 + 0.052 + 0.0 avg prob of [ Guy Bainbridge Norrie] 0.9988093376159668
Init norm 12.699810981750488 | Delta norm 50.79924774169922 | Target norm 52.13077163696289


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.7992, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.5882, device='cuda:0')
upd norm tensor(2.5149, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(48.3680, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.6397, device='cuda:0')
upd norm tensor(2.4309, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(45.1472, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0636, device='cuda:0')
upd norm tensor(2.5516, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(38.9992, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.8664, device='cuda:0')
upd norm tensor(2.9072, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(30.3723, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.8741, device='cuda:0')
upd norm tensor(4.1190, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The gender of Olga N. Savostikova is] -> [ transgender]
Computing right vector (v)
Lookup index found: 11 | Sentence: The gender of Olga N. Savostikova is trans | Token: ova
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.847 = 5.847 + 0.0 + 0.0 avg prob of [ transgender] 0.004083376377820969
loss 2.417 = 2.356 + 0.061 + 0.0 avg prob of [ transgender] 0.1174459457397461
loss 0.429 = 0.403 + 0.026 + 0.0 avg prob of [ transgender] 0.6739494204521179
loss 0.051 = 0.015 + 0.035 + 0.0 avg prob of [ transgender] 0.9849491119384766
loss 0.036 = 0.009 + 0.027 + 0.0 avg prob of [ transgender] 0.9914654493331909
Init norm 18.79497718811035 | Delta norm 73.46855163574219 | Target norm 76.83161926269531


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(73.4685, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.6148, device='cuda:0')
upd norm tensor(3.6934, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(65.8507, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.6621, device='cuda:0')
upd norm tensor(3.4577, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(59.5841, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.0862, device='cuda:0')
upd norm tensor(3.4805, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(50.6522, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.8972, device='cuda:0')
upd norm tensor(3.8744, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(38.8651, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(121.9428, device='cuda:0')
upd norm tensor(5.4000, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Virginia E Wotring is] -> [ occultism]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Virginia E Wotring is occult | Token: ring
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 6.277 = 6.277 + 0.0 + 0.0 avg prob of [ occultism] 0.002341533312574029
loss 3.081 = 2.917 + 0.164 + 0.0 avg prob of [ occultism] 0.07382092624902725
loss 0.979 = 0.897 + 0.083 + 0.0 avg prob of [ occultism] 0.43297669291496277
loss 0.138 = 0.046 + 0.092 + 0.0 avg prob of [ occultism] 0.9573345184326172
loss 0.103 = 0.009 + 0.093 + 0.0 avg prob of [ occultism] 0.9906455874443054
loss 0.103 = 0.008 + 0.094 + 0.0 avg prob of [ occultism] 0.991732120513916
loss 0.102 = 0.008 + 0.094 + 0.0 avg prob of [ occultism] 0.9923185706138611
loss 0.101 = 0.007 + 0.094 + 0.0 avg prob of [ occultism] 0.9932481646537781
loss 0.1 = 0.006 + 0.094 + 0.0 avg prob of [ occultism] 0.9942744970321655
loss 0.098 = 0.005 + 0.093 + 0.0 avg prob of [ occultism] 0.9951767921447754
loss 0.097 = 0.004 + 0.093 + 0.0 avg prob of [ occultism] 0.9958972930908203
loss 0.097 = 0.004 + 0.093 + 0.0 avg prob of [ occultism] 0.9964592456817627
loss 0.096 = 0.003 + 0.093 + 0.0 avg prob of [ occultism] 0.9969015121459961
loss 0.096 = 0.003 + 0.093 + 0.0 avg prob of [ occultism] 0.9972569346427917
loss 0.096 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9975487589836121
loss 0.096 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9977928996086121
loss 0.095 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.997999906539917
loss 0.095 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9981772303581238
loss 0.095 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9983300566673279
loss 0.095 = 0.002 + 0.093 + 0.0 avg prob of [ occultism] 0.9984620809555054
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.998576283454895
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.9986752867698669
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.9987608194351196
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.9988345503807068
loss 0.095 = 0.001 + 0.093 + 0.0 avg prob of [ occultism] 0.9988977909088135
Init norm 15.123518943786621 | Delta norm 60.49407196044922 | Target norm 63.343963623046875


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(60.4941, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.6734, device='cuda:0')
upd norm tensor(3.0870, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(54.5564, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.7094, device='cuda:0')
upd norm tensor(2.8641, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(48.9032, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.1352, device='cuda:0')
upd norm tensor(2.8841, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(41.6970, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(117.9590, device='cuda:0')
upd norm tensor(3.2497, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(31.9821, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(122.0771, device='cuda:0')
upd norm tensor(4.5131, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the child of Arthur Pitman Gordon is] -> [ John Ligonier, 1st Earl Ligonier]
Computing right vector (v)
Lookup index found: 10 | Sentence: The name of the child of Arthur Pitman Gordon is John Ligonier, 1st Earl Ligon | Token: Gordon
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 4.14 = 4.14 + 0.0 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.018928689882159233
loss 3.188 = 2.921 + 0.267 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.06403239071369171
loss 2.166 = 1.99 + 0.176 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.14863398671150208
loss 1.302 = 1.188 + 0.114 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.32583558559417725
loss 0.586 = 0.503 + 0.083 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.622774600982666
loss 0.53 = 0.294 + 0.235 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.769049882888794
loss 0.65 = 0.532 + 0.118 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.5922455787658691
loss 0.219 = 0.11 + 0.109 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9032599925994873
loss 0.249 = 0.081 + 0.168 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9262404441833496
loss 0.177 = 0.065 + 0.112 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9383542537689209
loss 0.144 = 0.052 + 0.092 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9499204158782959
loss 0.129 = 0.042 + 0.087 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9593405723571777
loss 0.107 = 0.031 + 0.076 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.970172107219696
loss 0.087 = 0.019 + 0.068 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9816633462905884
loss 0.073 = 0.009 + 0.063 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.990822970867157
loss 0.072 = 0.005 + 0.067 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9949597716331482
loss 0.069 = 0.004 + 0.065 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9964093565940857
loss 0.066 = 0.003 + 0.063 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9970647096633911
loss 0.064 = 0.002 + 0.061 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9976109266281128
loss 0.063 = 0.002 + 0.061 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9980734586715698
loss 0.061 = 0.002 + 0.06 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9983993768692017
loss 0.061 = 0.001 + 0.059 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9985957145690918
loss 0.061 = 0.001 + 0.059 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9987087249755859
loss 0.06 = 0.001 + 0.058 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.998786211013794
loss 0.059 = 0.001 + 0.058 + 0.0 avg prob of [ John Ligonier, 1st Earl Ligonier] 0.9988483786582947
Init norm 11.906001091003418 | Delta norm 47.62400436401367 | Target norm 49.413673400878906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(47.6240, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.7146, device='cuda:0')
upd norm tensor(2.3980, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.2789, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.7427, device='cuda:0')
upd norm tensor(2.2542, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.5293, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.1672, device='cuda:0')
upd norm tensor(2.3236, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.9431, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(118.0007, device='cuda:0')
upd norm tensor(2.6308, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(26.7747, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(122.1666, device='cuda:0')
upd norm tensor(3.6664, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the country which 1974 Swedish Open Badminton Championships ‚Äì women's doubles is associated with is] -> [ Duchy of Saxe-Altenburg]
Computing right vector (v)
Lookup index found: 22 | Sentence: The name of the country which 1974 Swedish Open Badminton Championships ‚Äì women's doubles is associated with is Duchy of Saxe-Alten | Token: doubles
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.709 = 5.709 + 0.0 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.003350946120917797
loss 4.696 = 4.623 + 0.073 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.009999822825193405
loss 4.011 = 3.939 + 0.072 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.019901128485798836
loss 2.707 = 2.64 + 0.067 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.07272525131702423
loss 1.745 = 1.696 + 0.049 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.18692170083522797
loss 1.416 = 1.354 + 0.062 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.2708008885383606
loss 1.337 = 1.274 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.32839882373809814
loss 0.863 = 0.801 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.49835872650146484
loss 0.393 = 0.33 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.7274041175842285
loss 0.203 = 0.14 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.8700668811798096
loss 0.135 = 0.072 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9305151700973511
loss 0.109 = 0.046 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9553146362304688
loss 0.096 = 0.033 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.967284083366394
loss 0.089 = 0.026 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.974353015422821
loss 0.084 = 0.021 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9793953895568848
loss 0.08 = 0.017 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.983381986618042
loss 0.077 = 0.014 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9865643382072449
loss 0.074 = 0.011 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9890207052230835
loss 0.072 = 0.009 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9908456802368164
loss 0.071 = 0.008 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9921646118164062
loss 0.07 = 0.007 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9931018352508545
loss 0.07 = 0.006 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9937614798545837
loss 0.069 = 0.006 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9942230582237244
loss 0.069 = 0.005 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9945453405380249
loss 0.069 = 0.005 + 0.063 + 0.0 avg prob of [ Duchy of Saxe-Altenburg] 0.9947728514671326
Init norm 151.09669494628906 | Delta norm 204.99510192871094 | Target norm 257.73431396484375


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(204.9951, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(117.7391, device='cuda:0')
upd norm tensor(9.1746, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(185.6110, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(117.7622, device='cuda:0')
upd norm tensor(9.7445, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(168.5468, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.1863, device='cuda:0')
upd norm tensor(9.9202, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(141.8403, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(118.0281, device='cuda:0')
upd norm tensor(10.7624, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(101.8690, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(122.2260, device='cuda:0')
upd norm tensor(14.3696, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The occupation of Frank D Verbraak is] -> [ economist]
Computing right vector (v)
Lookup index found: 8 | Sentence: The occupation of Frank D Verbraak is econom | Token: ak
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 5.252 = 5.252 + 0.0 + 0.0 avg prob of [ economist] 0.010354960337281227
loss 4.399 = 4.174 + 0.224 + 0.0 avg prob of [ economist] 0.0352945402264595
loss 1.646 = 1.422 + 0.224 + 0.0 avg prob of [ economist] 0.29454952478408813
loss 0.259 = 0.035 + 0.224 + 0.0 avg prob of [ economist] 0.9658376574516296
loss 0.233 = 0.004 + 0.229 + 0.0 avg prob of [ economist] 0.9959520101547241
loss 0.226 = 0.001 + 0.225 + 0.0 avg prob of [ economist] 0.9987727403640747
loss 0.226 = 0.001 + 0.225 + 0.0 avg prob of [ economist] 0.9990956783294678
loss 0.226 = 0.001 + 0.225 + 0.0 avg prob of [ economist] 0.9991533756256104
loss 0.226 = 0.001 + 0.225 + 0.0 avg prob of [ economist] 0.999193549156189
loss 0.226 = 0.001 + 0.225 + 0.0 avg prob of [ economist] 0.9992610812187195
loss 0.226 = 0.001 + 0.225 + 0.0 avg prob of [ economist] 0.9993559718132019
loss 0.226 = 0.001 + 0.225 + 0.0 avg prob of [ economist] 0.9994611144065857
loss 0.226 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9995596408843994
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9996421337127686
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9997069239616394
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9997563362121582
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9997937083244324
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9998223781585693
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9998447299003601
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9998623728752136
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9998766183853149
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9998883008956909
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9998979568481445
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.9999062418937683
loss 0.225 = 0.0 + 0.225 + 0.0 avg prob of [ economist] 0.999913215637207
Init norm 12.726455688476562 | Delta norm 50.905818939208984 | Target norm 53.351417541503906


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(50.9058, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(118.1027, device='cuda:0')
upd norm tensor(2.5750, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(46.8681, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(118.2164, device='cuda:0')
upd norm tensor(2.4300, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(42.4163, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.7013, device='cuda:0')
upd norm tensor(2.4424, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(35.8174, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(118.6619, device='cuda:0')
upd norm tensor(2.7552, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(27.1622, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(123.3764, device='cuda:0')
upd norm tensor(3.7968, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the position held by Robert M. Speer is] -> [ Chilean Minister of Finance]
Computing right vector (v)
Lookup index found: 12 | Sentence: The name of the position held by Robert M. Speer is Chilean Minister of Fin | Token: er
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 3.655 = 3.655 + 0.0 + 0.0 avg prob of [ Chilean Minister of Finance] 0.029260288923978806
loss 3.323 = 3.021 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.05553291365504265
loss 1.899 = 1.598 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.2045055627822876
loss 0.441 = 0.136 + 0.305 + 0.0 avg prob of [ Chilean Minister of Finance] 0.873470664024353
loss 0.382 = 0.017 + 0.364 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9827020168304443
loss 0.324 = 0.023 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9770439863204956
loss 0.318 = 0.017 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9835824370384216
loss 0.312 = 0.011 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9889230728149414
loss 0.31 = 0.009 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9912803173065186
loss 0.308 = 0.007 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9927008152008057
loss 0.307 = 0.006 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9938812255859375
loss 0.306 = 0.005 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.994952380657196
loss 0.305 = 0.004 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9958686828613281
loss 0.304 = 0.003 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9965956211090088
loss 0.304 = 0.003 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9971458315849304
loss 0.303 = 0.002 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9975547790527344
loss 0.303 = 0.002 + 0.301 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9978585243225098
loss 0.303 = 0.002 + 0.3 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9980852007865906
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9982540011405945
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9983775019645691
loss 0.302 = 0.002 + 0.3 + 0.0 avg prob of [ Chilean Minister of Finance] 0.998462438583374
loss 0.302 = 0.001 + 0.3 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9985116720199585
loss 0.302 = 0.001 + 0.3 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9985236525535583
loss 0.301 = 0.002 + 0.299 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9984914660453796
loss 0.301 = 0.002 + 0.299 + 0.0 avg prob of [ Chilean Minister of Finance] 0.9984006881713867
Init norm 14.650154113769531 | Delta norm 58.600616455078125 | Target norm 61.51161575317383


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(58.6006, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(118.1311, device='cuda:0')
upd norm tensor(3.0015, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(51.7711, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(118.2383, device='cuda:0')
upd norm tensor(2.7029, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(47.3154, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.7217, device='cuda:0')
upd norm tensor(2.7573, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(40.8842, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(118.6906, device='cuda:0')
upd norm tensor(3.1316, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(31.4800, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(123.4395, device='cuda:0')
upd norm tensor(4.4098, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
MEMIT request sample: [The name of the father of Huang Yangmeng is] -> [ James M'Creight]
Computing right vector (v)
Lookup index found: 11 | Sentence: The name of the father of Huang Yangmeng is James M'Cre | Token: eng
Rewrite layer is 8
Tying optimization objective to 31
Recording initial value of v*
loss 7.051 = 7.051 + 0.0 + 0.0 avg prob of [ James M'Creight] 0.0008817613124847412
loss 4.094 = 3.857 + 0.236 + 0.0 avg prob of [ James M'Creight] 0.027802396565675735
loss 2.337 = 2.097 + 0.24 + 0.0 avg prob of [ James M'Creight] 0.12424960732460022
loss 1.525 = 1.294 + 0.231 + 0.0 avg prob of [ James M'Creight] 0.275234580039978
loss 0.878 = 0.68 + 0.198 + 0.0 avg prob of [ James M'Creight] 0.5079699754714966
loss 0.451 = 0.344 + 0.107 + 0.0 avg prob of [ James M'Creight] 0.7127031087875366
loss 0.272 = 0.033 + 0.238 + 0.0 avg prob of [ James M'Creight] 0.967510461807251
loss 0.253 = 0.01 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9895996451377869
loss 0.25 = 0.007 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9934241771697998
loss 0.249 = 0.006 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9943280220031738
loss 0.248 = 0.005 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9947870969772339
loss 0.248 = 0.005 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9953892230987549
loss 0.247 = 0.004 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9960759878158569
loss 0.246 = 0.003 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9967056512832642
loss 0.246 = 0.003 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9972350597381592
loss 0.245 = 0.002 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9976672530174255
loss 0.245 = 0.002 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9980143308639526
loss 0.245 = 0.002 + 0.243 + 0.0 avg prob of [ James M'Creight] 0.9982902407646179
loss 0.244 = 0.001 + 0.242 + 0.0 avg prob of [ James M'Creight] 0.9985078573226929
loss 0.244 = 0.001 + 0.242 + 0.0 avg prob of [ James M'Creight] 0.9986771941184998
loss 0.243 = 0.001 + 0.242 + 0.0 avg prob of [ James M'Creight] 0.9988036155700684
loss 0.243 = 0.001 + 0.241 + 0.0 avg prob of [ James M'Creight] 0.9988791942596436
loss 0.242 = 0.001 + 0.24 + 0.0 avg prob of [ James M'Creight] 0.99884432554245
loss 0.241 = 0.002 + 0.24 + 0.0 avg prob of [ James M'Creight] 0.998477578163147
loss 0.242 = 0.002 + 0.24 + 0.0 avg prob of [ James M'Creight] 0.998033881187439
Init norm 12.137290954589844 | Delta norm 48.549163818359375 | Target norm 50.527870178222656


LAYER 4

Writing 1 key/value pair(s) into layer 4
z error tensor(48.5492, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.4.mlp.down_proj.
orig norm tensor(118.1687, device='cuda:0')
upd norm tensor(2.4627, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 5

Writing 1 key/value pair(s) into layer 5
z error tensor(44.1907, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.5.mlp.down_proj.
orig norm tensor(118.2668, device='cuda:0')
upd norm tensor(2.3143, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 6

Writing 1 key/value pair(s) into layer 6
z error tensor(40.2225, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.6.mlp.down_proj.
orig norm tensor(117.7506, device='cuda:0')
upd norm tensor(2.3213, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 7

Writing 1 key/value pair(s) into layer 7
z error tensor(34.2223, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.7.mlp.down_proj.
orig norm tensor(118.7290, device='cuda:0')
upd norm tensor(2.5847, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)


LAYER 8

Writing 1 key/value pair(s) into layer 8
z error tensor(25.8406, device='cuda:0', grad_fn=<MeanBackward0>)
Retrieving covariance statistics for .._.._.hf_cache_llama2-7b-hf-chat @ model.layers.8.mlp.down_proj.
orig norm tensor(123.5248, device='cuda:0')
upd norm tensor(3.4866, device='cuda:0', dtype=torch.float64,
       grad_fn=<LinalgVectorNormBackward0>)
Deltas successfully computed for ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
New weights successfully inserted into ['model.layers.4.mlp.down_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.8.mlp.down_proj.weight']
Metrics Summary:  {'pre': {'rewrite_acc': 0.2549927536231884}, 'post': {'rewrite_acc': 0.8278502415458937}}
